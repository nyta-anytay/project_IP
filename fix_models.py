"""
–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ –æ–±–ª–∞–∫–µ (Streamlit Cloud —Å Keras 3)
"""
import pickle
import os
import sys
import numpy as np
import traceback

print("="*70)
print("–ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –î–õ–Ø STREAMLIT CLOUD")
print("="*70)

# ===== –ú–û–î–ï–õ–¨ 2: –ü–æ–ª–Ω–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ pickle =====
print("\n[1/2] –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ú–æ–¥–µ–ª—å 2 (Haar + RF)...")
MODEL2_ORIGINAL = 'trained_models/model2_haar_rf.pkl'
MODEL2_FIXED = 'trained_models/model2_haar_rf_fixed.pkl'

try:
    if not os.path.exists(MODEL2_ORIGINAL):
        print(f"  ‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {MODEL2_ORIGINAL}")
        print("  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ Model 2.")
    else:
        print("  –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
        with open(MODEL2_ORIGINAL, 'rb') as f:
            model2 = pickle.load(f)
        print("  ‚úì –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        fixed_attrs = []
        # –ü–æ–ø—ã—Ç–∫–∞ —É–¥–∞–ª–∏—Ç—å –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã —Å –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è –º–æ–¥–µ–ª–∏
        for attr in ['monotonic_cst', 'n_features_in_', 'feature_names_in_']:
            if hasattr(model2, attr):
                try:
                    delattr(model2, attr)
                    fixed_attrs.append(attr)
                except:
                    pass
        
        if fixed_attrs:
            print(f"  ‚úì –£–¥–∞–ª–µ–Ω—ã –∞—Ç—Ä–∏–±—É—Ç—ã: {', '.join(fixed_attrs)}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
        print("  –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...")
        with open(MODEL2_FIXED, 'wb') as f:
            pickle.dump(model2, f, protocol=4)
        print(f"  ‚úì –ú–æ–¥–µ–ª—å 2 –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞: {MODEL2_FIXED}")
        
except Exception as e:
    print(f"  ‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ Model 2: {e}")
    traceback.print_exc()

# ===== –ú–û–î–ï–õ–¨ 3: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–ª—è Keras 3 =====
print("\n" + "="*70)
print("[2/2] –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –ú–æ–¥–µ–ª—å 3 (CNN) –¥–ª—è Keras 3...")
print("="*70)

MODEL3_H5 = 'trained_models/model3_cnn.h5'
MODEL3_KERAS = 'trained_models/model3_cnn_keras3.keras'
MODEL3_WEIGHTS = 'trained_models/model3_cnn_weights.h5'

try:
    import tensorflow as tf
    
    # 1. –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä—Å–∏—é TensorFlow –±–µ–∑–æ–ø–∞—Å–Ω—ã–º —Å–ø–æ—Å–æ–±–æ–º
    tf_version = tf.__version__
    print(f"  TensorFlow –≤–µ—Ä—Å–∏—è: {tf_version}")
    
    # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –≤–µ—Ä—Å–∏—é Keras, –Ω–æ –Ω–µ –ø–∞–¥–∞–µ–º –µ—Å–ª–∏ –Ω–µ –≤—ã—Ö–æ–¥–∏—Ç
    keras_version = "–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞"
    try:
        # –°–ø–æ—Å–æ–± –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π (TF < 2.13)
        if hasattr(tf.keras, '__version__'):
            keras_version = tf.keras.__version__
        # –°–ø–æ—Å–æ–± –¥–ª—è –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏–π (Keras 3 –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø–∞–∫–µ—Ç)
        elif hasattr(tf.keras, 'version'):
            keras_version = tf.keras.version()
        # –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç keras
        else:
            import keras
            keras_version = keras.__version__
    except Exception:
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å - –Ω–µ —Å—Ç—Ä–∞—à–Ω–æ, —Ä–∞–±–æ—Ç–∞–µ–º –¥–∞–ª—å—à–µ
        pass
    
    print(f"  Keras –≤–µ—Ä—Å–∏—è: {keras_version}")
    
    # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–æ–π –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –µ—Å—Ç—å
    source_file = None
    if os.path.exists(MODEL3_H5):
        source_file = MODEL3_H5
        print(f"  ‚úì –ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª: {MODEL3_H5}")
    else:
        print(f"  ‚ö†Ô∏è –§–∞–π–ª {MODEL3_H5} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        print(f"  –ò—â—É –¥—Ä—É–≥–∏–µ —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–∏ –≤ trained_models/...")
        
        # –ü–æ–∏—Å–∫ –ª—é–±—ã—Ö —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–µ–π
        for file in os.listdir('trained_models'):
            if 'model3' in file.lower() and ('h5' in file or 'keras' in file):
                possible_source = os.path.join('trained_models', file)
                print(f"  –ù–∞–π–¥–µ–Ω –≤–æ–∑–º–æ–∂–Ω—ã–π –∏—Å—Ö–æ–¥–Ω–∏–∫: {possible_source}")
                source_file = possible_source
                break
    
    if not source_file:
        print("  ‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏ 3 –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏.")
        print("  –°–æ–∑–¥–∞—é –ø—Ä–æ—Å—Ç—É—é –¥–µ–º–æ-–º–æ–¥–µ–ª—å...")
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        model3 = tf.keras.Sequential([
            tf.keras.layers.Input(shape=(128, 128, 3)),
            tf.keras.layers.Conv2D(32, 3, activation='relu'),
            tf.keras.layers.MaxPooling2D(),
            tf.keras.layers.Conv2D(64, 3, activation='relu'),
            tf.keras.layers.MaxPooling2D(),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(1, activation='sigmoid')
        ])
        print("  ‚úì –°–æ–∑–¥–∞–Ω–∞ –ø—Ä–æ—Å—Ç–∞—è –¥–µ–º–æ-–º–æ–¥–µ–ª—å")
    else:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å
        print(f"  –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ {source_file}...")
        try:
            model3 = tf.keras.models.load_model(source_file, compile=False)
            print(f"  ‚úì –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            print(f"  ‚úó –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            print("  –°–æ–∑–¥–∞—é –¥–µ–º–æ-–º–æ–¥–µ–ª—å...")
            model3 = tf.keras.Sequential([
                tf.keras.layers.Input(shape=(128, 128, 3)),
                tf.keras.layers.Conv2D(32, 3, activation='relu'),
                tf.keras.layers.MaxPooling2D(),
                tf.keras.layers.Conv2D(64, 3, activation='relu'),
                tf.keras.layers.MaxPooling2D(),
                tf.keras.layers.Flatten(),
                tf.keras.layers.Dense(1, activation='sigmoid')
            ])
    
    print(f"  –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {len(model3.layers)} —Å–ª–æ–µ–≤")
    print(f"  –í—Ö–æ–¥: {model3.input_shape}, –í—ã—Ö–æ–¥: {model3.output_shape}")
    
    # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ .keras —Ñ–æ—Ä–º–∞—Ç–µ (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è Keras 3)
    print(f"  –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ .keras (Keras 3)...")
    model3.save(MODEL3_KERAS, save_format='keras')
    
    print(f"  ‚úì –ú–æ–¥–µ–ª—å 3 —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {MODEL3_KERAS}")
    print(f"  –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {os.path.getsize(MODEL3_KERAS) / (1024 * 1024):.1f} MB")
    
    # 4. –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç
    print("  –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    if model3.input_shape[1:] == (128, 128, 3):
        test_input = np.random.randn(1, 128, 128, 3).astype(np.float32)
    else:
        input_shape = list(model3.input_shape[1:])
        input_shape.insert(0, 1)
        test_input = np.random.randn(*input_shape).astype(np.float32)
    
    prediction = model3.predict(test_input, verbose=0)
    print(f"  ‚úì –¢–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω, –≤—ã—Ö–æ–¥: {prediction.shape}, –∑–Ω–∞—á–µ–Ω–∏—è: {prediction.flatten()[:3]}")
    
    # 5. –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤–µ—Å–∞ –æ—Ç–¥–µ–ª—å–Ω–æ (–∫–∞–∫ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç)
    model3.save_weights(MODEL3_WEIGHTS)
    print(f"  ‚úì –í–µ—Å–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –æ—Ç–¥–µ–ª—å–Ω–æ: {MODEL3_WEIGHTS}")
    
except ImportError:
    print("  ‚úó TensorFlow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    print("  –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install tensorflow")
except Exception as e:
    print(f"  ‚úó –û–±—â–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ Model 3: {e}")
    traceback.print_exc()

print("\n" + "="*70)
print("‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
print("="*70)

print("\nüìÅ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ trained_models/ –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π:")
if os.path.exists('trained_models'):
    for item in sorted(os.listdir('trained_models')):
        item_path = os.path.join('trained_models', item)
        if os.path.isdir(item_path):
            # –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ä–∞–∑–º–µ—Ä–∞ –ø–∞–ø–∫–∏
            def get_folder_size(path):
                total = 0
                for dirpath, dirnames, filenames in os.walk(path):
                    for f in filenames:
                        fp = os.path.join(dirpath, f)
                        total += os.path.getsize(fp)
                return total / (1024 * 1024)
            
            size = get_folder_size(item_path)
            print(f"üìÅ {item}/ ({size:.1f} MB)")
        else:
            size_kb = os.path.getsize(item_path) / 1024
            print(f"üìÑ {item} ({size_kb:.1f} KB)")

print("\nüöÄ –¢–µ–ø–µ—Ä—å –≤—ã–ø–æ–ª–Ω–∏—Ç–µ:")
print("1. git add trained_models/")
print("2. git commit -m 'Fixed models for cloud'")
print("3. git push")
print("\nüì¶ Streamlit Cloud –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–∏—Ç—Å—è —á–µ—Ä–µ–∑ 2-3 –º–∏–Ω—É—Ç—ã!")
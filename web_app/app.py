"""
Streamlit –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫
"""
import streamlit as st
import cv2
import numpy as np
from PIL import Image
import pickle
from tensorflow.keras.models import load_model
from tensorflow.keras.layers import BatchNormalization
import json
import os
import warnings
warnings.filterwarnings('ignore')

# ===== –ü–£–¢–ò –ö –§–ê–ô–õ–ê–ú (–û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ï –ò–ú–ï–ù–ê) =====
MODEL1_PATH = 'model1_hog_svm.pkl'    # –í–∞—à –ø–µ—Ä–≤—ã–π .pkl —Ñ–∞–π–ª
MODEL2_PATH = 'model2_haar_rf.pkl'    # –í–∞—à –≤—Ç–æ—Ä–æ–π .pkl —Ñ–∞–π–ª  
MODEL3_PATH = 'model3_cnn.h5'         # –í–∞—à .h5 —Ñ–∞–π–ª
LABELS_MAP_PATH = 'labels_map.json'   # JSON —Å –º–µ—Ç–∫–∞–º–∏

# ===== –ù–ê–°–¢–†–û–ô–ö–ê –°–¢–†–ê–ù–ò–¶–´ =====
st.set_page_config(
    page_title="Mask Detection System",
    page_icon="üò∑",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===== –ö–ê–°–¢–û–ú–ù–´–ï –°–¢–ò–õ–ò =====
st.markdown("""
    <style>
    .main-header {
        font-size: 3.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .stProgress > div > div > div > div {
        background-color: #1f77b4;
    }
    div[data-testid="stMetricValue"] {
        font-size: 1.5rem;
    }
    </style>
""", unsafe_allow_html=True)

# ===== –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –§–ê–ô–õ–û–í =====
def check_files_exist():
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–µ–π –∏ labels_map"""
    files_needed = [MODEL1_PATH, MODEL2_PATH, MODEL3_PATH, LABELS_MAP_PATH]
    existing_files = []
    missing_files = []
    
    for file in files_needed:
        if os.path.exists(file):
            existing_files.append(file)
        else:
            missing_files.append(file)
    
    return existing_files, missing_files

# ===== –§–£–ù–ö–¶–ò–Ø –ü–û–ò–°–ö–ê –§–ê–ô–õ–û–í –í –ü–û–î–ü–ê–ü–ö–ê–• =====
def find_files_in_subfolders():
    """–ò—â–µ–º —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π –≤ —Ä–∞–∑–Ω—ã—Ö –ø–æ–¥–ø–∞–ø–∫–∞—Ö"""
    possible_locations = [
        '.',  # —Ç–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
        'web_app',
        'Trained_models',
        'models',
        'data',
        'src'
    ]
    
    found_files = {}
    
    # –ò—â–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª –≤–æ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
    target_files = [
        ('model1_hog_svm.pkl', MODEL1_PATH),
        ('model2_haar_rf.pkl', MODEL2_PATH),
        ('model3_cnn.h5', MODEL3_PATH),
        ('labels_map.json', LABELS_MAP_PATH)
    ]
    
    for filename, path_key in target_files:
        found = False
        for location in possible_locations:
            full_path = os.path.join(location, filename)
            if os.path.exists(full_path):
                found_files[path_key] = full_path
                found = True
                break
        
        if not found:
            found_files[path_key] = None
    
    return found_files

# ===== –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô –° –û–ë–†–ê–ë–û–¢–ö–û–ô –û–®–ò–ë–û–ö =====
@st.cache_resource
def load_all_models():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∏ labels_map"""
    # –ò—â–µ–º —Ñ–∞–π–ª—ã –≤ –ø–æ–¥–ø–∞–ø–∫–∞—Ö
    file_locations = find_files_in_subfolders()
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≥–¥–µ –Ω–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã
    st.sidebar.subheader("üîç –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤")
    
    for file_key, found_path in file_locations.items():
        if found_path:
            st.sidebar.success(f"‚úÖ {os.path.basename(file_key)}: {found_path}")
        else:
            st.sidebar.error(f"‚ùå {os.path.basename(file_key)}: –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    try:
        # ===== labels_map =====
        labels_map_path = file_locations[LABELS_MAP_PATH] or LABELS_MAP_PATH
        if os.path.exists(labels_map_path):
            with open(labels_map_path, 'r') as f:
                labels_dict = json.load(f)
                labels_map = {int(k): v for k, v in labels_dict.items()}
        else:
            # –°–æ–∑–¥–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π labels_map
            labels_map = {0: "–ë–µ–∑ –º–∞—Å–∫–∏", 1: "–° –º–∞—Å–∫–æ–π"}
            st.sidebar.info("‚ÑπÔ∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π labels_map")

        models_loaded = []
        model1, model2, model3 = None, None, None

        # ===== –ú–æ–¥–µ–ª—å 1: HOG + SVM =====
        model1_path = file_locations[MODEL1_PATH] or MODEL1_PATH
        if os.path.exists(model1_path):
            try:
                with open(model1_path, 'rb') as f:
                    model1 = pickle.load(f)
                models_loaded.append(("model1_hog_svm", True, ""))
            except Exception as e:
                models_loaded.append(("model1_hog_svm", False, str(e)))
                st.sidebar.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ model1: {str(e)[:50]}")
        else:
            models_loaded.append(("model1_hog_svm", False, f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {model1_path}"))

        # ===== –ú–æ–¥–µ–ª—å 2: Haar + RF =====
        model2_path = file_locations[MODEL2_PATH] or MODEL2_PATH
        if os.path.exists(model2_path):
            try:
                with open(model2_path, 'rb') as f:
                    model2 = pickle.load(f)
                models_loaded.append(("model2_haar_rf", True, ""))
            except Exception as e:
                models_loaded.append(("model2_haar_rf", False, str(e)))
                st.sidebar.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ model2: {str(e)[:50]}")
        else:
            models_loaded.append(("model2_haar_rf", False, f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {model2_path}"))

        # ===== –ú–æ–¥–µ–ª—å 3: CNN =====
        model3_path = file_locations[MODEL3_PATH] or MODEL3_PATH
        if os.path.exists(model3_path):
            try:
                model3_keras = load_model(
                    model3_path,
                    compile=False,
                    custom_objects={'BatchNormalization': BatchNormalization}
                )
                
                class CNNWrapper:
                    def __init__(self, model):
                        self.model = model
                    def predict_proba(self, X):
                        return self.model.predict(X, verbose=0)
                
                model3 = CNNWrapper(model3_keras)
                models_loaded.append(("model3_cnn", True, ""))
            except Exception as e:
                models_loaded.append(("model3_cnn", False, str(e)))
                st.sidebar.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ model3: {str(e)[:50]}")
        else:
            models_loaded.append(("model3_cnn", False, f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {model3_path}"))

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å
        any_loaded = any(status for _, status, _ in models_loaded)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–∞—Ö
        error_msg = ""
        if not any_loaded:
            error_details = [f"{name}: {msg}" for name, status, msg in models_loaded if not status and msg]
            error_msg = f"–û—à–∏–±–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏: {'; '.join(error_details)}"

        return model1, model2, model3, labels_map, any_loaded, error_msg

    except Exception as e:
        return None, None, None, {}, False, f"–û–±—â–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}"

# ===== –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô =====
model1, model2, model3, labels_map, models_loaded, error_msg = load_all_models()

# ===== –ó–ê–ì–û–õ–û–í–û–ö =====
st.markdown('<h1 class="main-header">üò∑ –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫ –Ω–∞ –ª–∏—Ü–µ</h1>', 
           unsafe_allow_html=True)
st.markdown("---")

# ===== SIDEBAR: –û–°–ù–û–í–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò =====
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –ø—Ä–æ–µ–∫—Ç–∞
    if st.checkbox("üìÅ –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞", True):
        st.write("**–¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è:**", os.getcwd())
        st.write("**–°–æ–¥–µ—Ä–∂–∏–º–æ–µ:**")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å —Ä–µ–∫—É—Ä—Å–∏–µ–π
        def list_files(startpath):
            for root, dirs, files in os.walk(startpath):
                level = root.replace(startpath, '').count(os.sep)
                indent = ' ' * 4 * level
                st.text(f'{indent}{os.path.basename(root)}/')
                subindent = ' ' * 4 * (level + 1)
                for f in files[:10]:  # –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 —Ñ–∞–π–ª–æ–≤
                    st.text(f'{subindent}{f}')
        
        list_files('.')
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    available_models = []
    if model1:
        available_models.append("HOG + SVM")
    if model2:
        available_models.append("Haar Cascade + RF")
    if model3:
        available_models.append("CNN (Deep Learning)")
    
    if available_models:
        model_choice = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
            ["–í—Å–µ –º–æ–¥–µ–ª–∏"] + available_models,
            help="–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"
        )
    else:
        model_choice = "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"
        st.error("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—ã–±–æ—Ä–∞")
    
    # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    confidence_threshold = st.slider(
        "–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:", 
        min_value=0.0, 
        max_value=1.0, 
        value=0.5, 
        step=0.05,
        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"
    )
    
    # –ö–Ω–æ–ø–∫–∞ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏
    if st.button("üîÑ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏"):
        st.cache_resource.clear()
        st.rerun()
    
    st.markdown("---")
    
    # –°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–µ–π
    st.markdown("### üìä –°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–µ–π")
    status_col1, status_col2, status_col3 = st.columns(3)
    with status_col1:
        st.metric("HOG+SVM", "‚úÖ" if model1 else "‚ùå", 
                 delta="–ó–∞–≥—Ä—É–∂–µ–Ω–∞" if model1 else "–ù–µ –Ω–∞–π–¥–µ–Ω")
    with status_col2:
        st.metric("Haar+RF", "‚úÖ" if model2 else "‚ùå",
                 delta="–ó–∞–≥—Ä—É–∂–µ–Ω–∞" if model2 else "–ù–µ –Ω–∞–π–¥–µ–Ω")
    with status_col3:
        st.metric("CNN", "‚úÖ" if model3 else "‚ùå",
                 delta="–ó–∞–≥—Ä—É–∂–µ–Ω–∞" if model3 else "–ù–µ –Ω–∞–π–¥–µ–Ω")

# ===== –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° =====

# –ï—Å–ª–∏ –Ω–µ—Ç –Ω–∏ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏
if not models_loaded:
    st.error("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏!")
    st.warning(error_msg)
    
    # –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    st.subheader("üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º—ã")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤
    existing, missing = check_files_exist()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**–ù–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã:**")
        if existing:
            for file in existing:
                st.success(f"‚úÖ {file}")
        else:
            st.error("‚ùå –§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    with col2:
        st.write("**–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∞–π–ª—ã:**")
        if missing:
            for file in missing:
                st.error(f"‚ùå {file}")
    
    # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
    st.info("""
    ## üöÄ –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:
    
    ### 1. **–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π:**
    ```
    model1_hog_svm.pkl
    model2_haar_rf.pkl  
    model3_cnn.h5
    labels_map.json (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    ```
    
    ### 2. **–ü–æ–º–µ—Å—Ç–∏—Ç–µ —Ñ–∞–π–ª—ã –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –ø–∞–ø–∫—É:**
    - –í—Å–µ —Ñ–∞–π–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ **–∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞** –∏–ª–∏ –≤ –ø–∞–ø–∫–µ **web_app/**
    - –ù–∞ Streamlit Cloud –ø—É—Ç—å –±—É–¥–µ—Ç –≤—ã–≥–ª—è–¥–µ—Ç—å —Ç–∞–∫:
      ```
      /mount/src/–≤–∞—à-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π/
      ‚îú‚îÄ‚îÄ app.py
      ‚îú‚îÄ‚îÄ model1_hog_svm.pkl
      ‚îú‚îÄ‚îÄ model2_haar_rf.pkl
      ‚îú‚îÄ‚îÄ model3_cnn.h5
      ‚îî‚îÄ‚îÄ requirements.txt
      ```
    
    ### 3. **–û–±–Ω–æ–≤–∏—Ç–µ requirements.txt:**
    ```txt
    streamlit
    tensorflow==2.15.0
    opencv-python-headless
    numpy
    Pillow
    scikit-learn
    ```
    
    ### 4. **–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ Streamlit Cloud**
    """)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    if st.checkbox("üìÇ –ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–ª–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–∞–π–ª–æ–≤"):
        st.write("**–í—Å–µ —Ñ–∞–π–ª—ã –∏ –ø–∞–ø–∫–∏:**")
        
        import pathlib
        path = pathlib.Path('.')
        
        for file_path in path.rglob('*'):
            if file_path.is_file():
                # –ü–æ–¥—Å–≤–µ—á–∏–≤–∞–µ–º —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π
                if 'model' in file_path.name.lower() or 'cnn' in file_path.name.lower():
                    st.success(f"üîç {file_path}")
                else:
                    st.text(f"   {file_path}")
    
    st.stop()

# ===== –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° (–µ—Å–ª–∏ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã) =====
st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {sum([1 for m in [model1, model2, model3] if m is not None])}/3")

# –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
col1, col2 = st.columns([1, 1], gap="large")

# ===== –õ–ï–í–ê–Ø –ö–û–õ–û–ù–ö–ê: –ó–ê–ì–†–£–ó–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø =====
with col1:
    st.header("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    
    upload_option = st.radio(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–±:",
        ["–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–º–µ—Ä—É"],
        horizontal=True
    )
    
    uploaded_file = None
    
    if upload_option == "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª":
        uploaded_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...", 
            type=['jpg', 'jpeg', 'png', 'bmp'],
            help="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: JPG, JPEG, PNG, BMP"
        )
    else:
        camera_image = st.camera_input("–°–¥–µ–ª–∞–π—Ç–µ —Ñ–æ—Ç–æ")
        if camera_image is not None:
            uploaded_file = camera_image

# ===== –ü–†–ê–í–ê–Ø –ö–û–õ–û–ù–ö–ê: –†–ï–ó–£–õ–¨–¢–ê–¢–´ =====
with col2:
    st.header("üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏")
    
    if uploaded_file is not None:
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = Image.open(uploaded_file)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –ª–µ–≤–æ–π –∫–æ–ª–æ–Ω–∫–µ
            with col1:
                st.image(image, caption='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_column_width=True)
                img_array = np.array(image)
                st.caption(f"–†–∞–∑–º–µ—Ä: {img_array.shape[1]}x{img_array.shape[0]} –ø–∏–∫—Å–µ–ª–µ–π")
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–µ–π
            if len(img_array.shape) == 2:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)
            elif img_array.shape[2] == 4:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2RGB)
            
            # –†–µ—Å–∞–π–∑ –¥–ª—è –º–æ–¥–µ–ª–∏
            img_resized = cv2.resize(img_array, (128, 128))
            img_input = np.expand_dims(img_resized, axis=0) / 255.0  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            
            # ===== –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø =====
            if model_choice == "–í—Å–µ –º–æ–¥–µ–ª–∏":
                st.subheader("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π")
                
                models = []
                if model1:
                    models.append((model1, "HOG + SVM", "üîµ", "#1f77b4"))
                if model2:
                    models.append((model2, "Haar Cascade + RF", "üü¢", "#2ca02c"))
                if model3:
                    models.append((model3, "CNN (Deep Learning)", "üî¥", "#d62728"))
                
                for model, name, icon, color in models:
                    with st.container():
                        st.markdown(f"### {icon} {name}")
                        
                        try:
                            pred_proba = model.predict_proba(img_input)[0]
                            
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª–∞—Å—Å
                            if len(pred_proba) > 2:
                                pred_class = np.argmax(pred_proba)
                            else:
                                pred_class = 1 if pred_proba[1] > 0.5 else 0
                            
                            confidence = pred_proba[pred_class] if len(pred_proba) > pred_class else pred_proba[1]
                            prediction = labels_map.get(pred_class, "–° –º–∞—Å–∫–æ–π" if pred_class == 1 else "–ë–µ–∑ –º–∞—Å–∫–∏")
                            
                            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                            result_col1, result_col2 = st.columns([2, 1])
                            with result_col1:
                                if confidence >= confidence_threshold:
                                    if prediction == "–° –º–∞—Å–∫–æ–π" or pred_class == 1:
                                        st.success(f"‚úÖ **{prediction}**")
                                    else:
                                        st.error(f"‚ùå **{prediction}**")
                                else:
                                    st.warning(f"‚ö†Ô∏è **{prediction}** (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)")
                            
                            with result_col2:
                                st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}")
                            
                            st.progress(float(confidence))
                            
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {str(e)[:100]}")
                        
                        st.markdown("---")
            
            elif model_choice in ["HOG + SVM", "Haar Cascade + RF", "CNN (Deep Learning)"]:
                # –û–¥–Ω–∞ –º–æ–¥–µ–ª—å
                model_map = {
                    "HOG + SVM": (model1, "üîµ"),
                    "Haar Cascade + RF": (model2, "üü¢"),
                    "CNN (Deep Learning)": (model3, "üî¥")
                }
                
                model, icon = model_map[model_choice]
                
                if model is None:
                    st.error(f"–ú–æ–¥–µ–ª—å {model_choice} –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                else:
                    with st.spinner(f'–û–±—Ä–∞–±–æ—Ç–∫–∞ {model_choice}...'):
                        try:
                            pred_proba = model.predict_proba(img_input)[0]
                            
                            if len(pred_proba) > 2:
                                pred_class = np.argmax(pred_proba)
                            else:
                                pred_class = 1 if pred_proba[1] > 0.5 else 0
                            
                            confidence = pred_proba[pred_class] if len(pred_proba) > pred_class else pred_proba[1]
                            prediction = labels_map.get(pred_class, "–° –º–∞—Å–∫–æ–π" if pred_class == 1 else "–ë–µ–∑ –º–∞—Å–∫–∏")
                            
                            # –ë–æ–ª—å—à–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                            st.markdown(f"## {icon} {prediction}")
                            
                            if confidence >= confidence_threshold:
                                if prediction == "–° –º–∞—Å–∫–æ–π" or pred_class == 1:
                                    st.success("‚úÖ –ú–∞—Å–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞!")
                                else:
                                    st.error("‚ùå –ú–∞—Å–∫–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞!")
                            else:
                                st.warning("‚ö†Ô∏è –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏")
                            
                            # –ú–µ—Ç—Ä–∏–∫–∏
                            col_a, col_b, col_c = st.columns(3)
                            
                            with col_a:
                                st.metric("–ö–ª–∞—Å—Å", prediction)
                            
                            with col_b:
                                st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}")
                            
                            with col_c:
                                status = "‚úÖ" if confidence >= confidence_threshold else "‚ö†Ô∏è"
                                st.metric("–°—Ç–∞—Ç—É—Å", status)
                            
                            st.progress(float(confidence))
                            
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {str(e)}")
        
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
    
    else:
        # –ö–æ–≥–¥–∞ –Ω–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –Ω–∞—á–∞–ª–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏")
        
        st.markdown("""
        ### üí° –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
        
        1. **–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ** —á–µ–ª–æ–≤–µ–∫–∞ (–ª–∏—Ü–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤–∏–¥–Ω–æ)
        2. **–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å** –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        3. **–ü–æ–ª—É—á–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç** –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–∫–∏
        """)

# ===== FOOTER =====
st.markdown("---")

with st.expander("üìã –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –¥–µ–ø–ª–æ—é"):
    st.markdown("""
    ## üìÅ –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è Streamlit Cloud:
    
    ```
    –≤–∞—à-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π/
    ‚îú‚îÄ‚îÄ app.py                    # –≠—Ç–æ—Ç —Ñ–∞–π–ª
    ‚îú‚îÄ‚îÄ model1_hog_svm.pkl       # HOG+SVM –º–æ–¥–µ–ª—å (.pkl)
    ‚îú‚îÄ‚îÄ model2_haar_rf.pkl       # Haar+RF –º–æ–¥–µ–ª—å (.pkl)
    ‚îú‚îÄ‚îÄ model3_cnn.h5            # CNN –º–æ–¥–µ–ª—å (.h5)
    ‚îú‚îÄ‚îÄ labels_map.json          # –§–∞–π–ª —Å –º–µ—Ç–∫–∞–º–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    ‚îî‚îÄ‚îÄ requirements.txt         # –°–ø–∏—Å–æ–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (–í–ê–ñ–ù–û!)
    ```
    
    ## üìù requirements.txt:
    ```txt
    streamlit==1.29.0
    tensorflow==2.15.0
    opencv-python-headless==4.8.1
    numpy==1.24.3
    Pillow==10.1.0
    scikit-learn==1.3.2
    ```
    
    ## üîß –ï—Å–ª–∏ —Ñ–∞–π–ª—ã –≤ –ø–æ–¥–ø–∞–ø–∫–µ web_app:
    - –õ–∏–±–æ –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç–µ —Ñ–∞–π–ª—ã –≤ –∫–æ—Ä–µ–Ω—å
    - –õ–∏–±–æ –∏–∑–º–µ–Ω–∏—Ç–µ –ø—É—Ç–∏ –≤ –∫–æ–¥–µ:
    ```python
    MODEL1_PATH = 'web_app/model1_hog_svm.pkl'
    ```
    """)

st.markdown("""
    <div style='text-align: center; color: gray; padding: 20px;'>
        <p>¬© 2024 Mask Detection System | model1_hog_svm.pkl, model2_haar_rf.pkl, model3_cnn.h5</p>
    </div>
""", unsafe_allow_html=True)
"""
Streamlit –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫
"""
import streamlit as st
import cv2
import numpy as np
from PIL import Image
import pickle
import tensorflow as tf
import json
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from src.config import MODEL1_PATH, MODEL2_PATH, MODEL3_PATH, LABELS_MAP_PATH

# ===== –ù–ê–°–¢–†–û–ô–ö–ê –°–¢–†–ê–ù–ò–¶–´ =====
st.set_page_config(
    page_title="Mask Detection System",
    page_icon="üò∑",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===== –ö–ê–°–¢–û–ú–ù–´–ï –°–¢–ò–õ–ò =====
st.markdown("""
<style>
.main-header {font-size:3.5rem; color:#1f77b4; text-align:center; margin-bottom:2rem; text-shadow:2px 2px 4px rgba(0,0,0,0.1);}
.stProgress > div > div > div > div {background-color: #1f77b4;}
div[data-testid="stMetricValue"] {font-size:1.5rem;}
</style>
""", unsafe_allow_html=True)

# ===== –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô =====
@st.cache_resource
def load_all_models():
    try:
        # –ú–æ–¥–µ–ª—å 1: HOG + SVM
        with open(MODEL1_PATH, 'rb') as f:
            model1 = pickle.load(f)
        
        # –ú–æ–¥–µ–ª—å 2: Haar + RF
        with open(MODEL2_PATH, 'rb') as f:
            model2 = pickle.load(f)
        
        # –ú–æ–¥–µ–ª—å 3: CNN
        model3 = tf.keras.models.load_model(MODEL3_PATH)

        # Labels map
        with open(LABELS_MAP_PATH, 'r') as f:
            labels_dict = json.load(f)
            labels_map = {int(k): v for k, v in labels_dict.items()}
        
        return model1, model2, model3, labels_map, True, None

    except FileNotFoundError as e:
        return None, None, None, None, False, f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}"
    except Exception as e:
        return None, None, None, None, False, f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}"

# ===== –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π =====
model1, model2, model3, labels_map, models_loaded, error_msg = load_all_models()

# ===== –ó–ê–ì–û–õ–û–í–û–ö =====
st.markdown('<h1 class="main-header">üò∑ –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫ –Ω–∞ –ª–∏—Ü–µ</h1>', unsafe_allow_html=True)
st.markdown("---")

# ===== SIDEBAR =====
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")

    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    model_choice = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
        ["–í—Å–µ –º–æ–¥–µ–ª–∏", "HOG + SVM", "Haar Cascade + RF", "CNN (Deep Learning)"]
    )

    # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    confidence_threshold = st.slider(
        "–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:",
        min_value=0.0, max_value=1.0, value=0.5, step=0.05
    )

    st.markdown("---")
    st.markdown("### üìä –û –º–æ–¥–µ–ª—è—Ö")
    with st.expander("üîµ HOG + SVM"):
        st.markdown("–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –º–µ—Ç–æ–¥: HOG + SVM")
    with st.expander("üü¢ Haar Cascade + RF"):
        st.markdown("–ì–∏–±—Ä–∏–¥–Ω—ã–π –º–µ—Ç–æ–¥: Haar Cascade + Random Forest")
    with st.expander("üî¥ CNN (Deep Learning)"):
        st.markdown("–°–≤–µ—Ä—Ç–æ—á–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å, Transfer Learning (MobileNetV2)")

# ===== –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° =====
if not models_loaded:
    st.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {error_msg}")
    st.stop()

col1, col2 = st.columns([1,1], gap="large")

# ===== –ó–ê–ì–†–£–ó–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø =====
with col1:
    st.header("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    upload_option = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–±:", ["–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–º–µ—Ä—É"], horizontal=True)
    uploaded_file = None
    if upload_option == "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª":
        uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...", type=['jpg','jpeg','png','bmp'])
    else:
        camera_image = st.camera_input("–°–¥–µ–ª–∞–π—Ç–µ —Ñ–æ—Ç–æ")
        if camera_image is not None:
            uploaded_file = camera_image
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_column_width=True)
        img_array = np.array(image)
        st.caption(f"–†–∞–∑–º–µ—Ä: {img_array.shape[1]}x{img_array.shape[0]}")

# ===== –†–ï–ó–£–õ–¨–¢–ê–¢–´ =====
with col2:
    st.header("üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏")
    if uploaded_file is not None:
        img_array = np.array(image)
        if len(img_array.shape) == 2:
            img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)
        elif img_array.shape[2] == 4:
            img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2RGB)
        img_resized = cv2.resize(img_array, (128,128))
        img_input = np.expand_dims(img_resized/255.0, axis=0)

        models_to_use = []
        if model_choice == "–í—Å–µ –º–æ–¥–µ–ª–∏":
            models_to_use = [(model1,"HOG + SVM"),(model2,"Haar Cascade + RF"),(model3,"CNN (Deep Learning)")]
        else:
            model_map = {"HOG + SVM": model1,"Haar Cascade + RF": model2,"CNN (Deep Learning)": model3}
            models_to_use = [(model_map[model_choice], model_choice)]

        for mdl, name in models_to_use:
            if mdl is None:
                st.warning(f"–ú–æ–¥–µ–ª—å {name} –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                continue
            st.subheader(f"{name}")
            pred_proba = None
            if name == "CNN (Deep Learning)":
                pred_proba = mdl.predict(img_input)[0]
                if pred_proba.shape[-1]==1:
                    pred_proba = np.column_stack([1-pred_proba, pred_proba])
            else:
                pred_proba = mdl.predict_proba(img_input)[0]

            pred_class = np.argmax(pred_proba)
            confidence = float(pred_proba[pred_class])
            prediction = labels_map[pred_class]

            if confidence >= confidence_threshold:
                if pred_class==1:
                    st.success(f"‚úÖ {prediction}")
                else:
                    st.error(f"‚ùå {prediction}")
            else:
                st.warning("‚ö†Ô∏è –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å")

            col_a, col_b = st.columns(2)
            with col_a:
                st.metric("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ", prediction)
            with col_b:
                st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}")

            st.progress(min(max(confidence,0.0),1.0))
    else:
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –Ω–∞—á–∞–ª–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏")

        
        st.markdown("""
        ### üí° –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
        
        1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ —á–µ–ª–æ–≤–µ–∫–∞ (—Å –ª–∏—Ü–æ–º)
        2. –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        3. –ü–æ–ª—É—á–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–∫–∏
        
        ### üì∏ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
        
        - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —á–µ—Ç–∫–∏–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
        - –õ–∏—Ü–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ö–æ—Ä–æ—à–æ –≤–∏–¥–Ω–æ
        - –ò–∑–±–µ–≥–∞–π—Ç–µ —Å–∏–ª—å–Ω—ã—Ö —Ç–µ–Ω–µ–π
        - –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: –ø–æ—Ä—Ç—Ä–µ—Ç–Ω–∞—è —Å—ä–µ–º–∫–∞
        """)


# ===== FOOTER =====
st.markdown("---")

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
with st.expander("‚ÑπÔ∏è –û —Å–∏—Å—Ç–µ–º–µ"):
    st.markdown("""
    ### –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫
    
    –≠—Ç–∞ —Å–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—Ä–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–∞ –∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:
    
    1. **–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è**
       - HOG + SVM
       - Haar Cascade + Random Forest
    
    2. **–ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ**
       - CNN —Å Transfer Learning (MobileNetV2)
    
    ### –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:
    - Python 3.8+
    - OpenCV
    - scikit-learn
    - TensorFlow/Keras
    - Streamlit
    """)
    
# Copyright
st.markdown("""
    <div style='text-align: center; color: gray; padding: 20px;'>
        <p>¬© 2024 Mask Detection System | –í—Å–µ –ø—Ä–∞–≤–∞ –∑–∞—â–∏—â–µ–Ω—ã</p>
    </div>
""", unsafe_allow_html=True)

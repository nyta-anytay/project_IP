"""
Streamlit –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫
"""
import streamlit as st
import cv2
import numpy as np
from PIL import Image
import pickle
import tensorflow as tf
from tensorflow import keras
import json
import os
import warnings
warnings.filterwarnings('ignore')

# ===== –ü–†–ê–í–ò–õ–¨–ù–´–ï –ü–£–¢–ò - –ú–û–î–ï–õ–ò –í –ü–ê–ü–ö–ï web/ =====
MODEL1_PATH = 'web/model1_hog_svm.pkl'    # –ü—É—Ç—å –∫ –ø–µ—Ä–≤–æ–π –º–æ–¥–µ–ª–∏
MODEL2_PATH = 'web/model2_haar_rf.pkl'    # –ü—É—Ç—å –∫–æ –≤—Ç–æ—Ä–æ–π –º–æ–¥–µ–ª–∏  
MODEL3_PATH = 'web/model3_cnn.h5'         # –ü—É—Ç—å –∫ —Ç—Ä–µ—Ç—å–µ–π –º–æ–¥–µ–ª–∏
LABELS_MAP_PATH = 'web/labels_map.json'   # –ü—É—Ç—å –∫ labels_map

# ===== –ù–ê–°–¢–†–û–ô–ö–ê –°–¢–†–ê–ù–ò–¶–´ =====
st.set_page_config(
    page_title="Mask Detection System",
    page_icon="üò∑",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===== –ö–ê–°–¢–û–ú–ù–´–ï –°–¢–ò–õ–ò =====
st.markdown("""
    <style>
    .main-header {
        font-size: 3.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .stProgress > div > div > div > div {
        background-color: #1f77b4;
    }
    div[data-testid="stMetricValue"] {
        font-size: 1.5rem;
    }
    </style>
""", unsafe_allow_html=True)

# ===== –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –§–ê–ô–õ–û–í =====
def check_files_exist():
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–µ–π –≤ –ø–∞–ø–∫–µ web/"""
    st.sidebar.subheader("üîç –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –≤ web/")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –ø–∞–ø–∫–∞ web/
    if not os.path.exists('web'):
        st.sidebar.error("‚ùå –ü–∞–ø–∫–∞ 'web/' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return [], ['web/' + f for f in ['model1_hog_svm.pkl', 'model2_haar_rf.pkl', 'model3_cnn.h5', 'labels_map.json']]
    
    files_needed = [MODEL1_PATH, MODEL2_PATH, MODEL3_PATH, LABELS_MAP_PATH]
    existing_files = []
    missing_files = []
    
    for file in files_needed:
        if os.path.exists(file):
            existing_files.append(file)
            size_kb = os.path.getsize(file) / 1024
            st.sidebar.success(f"‚úÖ {os.path.basename(file)} ({size_kb:.1f} KB)")
        else:
            missing_files.append(file)
            st.sidebar.error(f"‚ùå {os.path.basename(file)} - –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–∞–ø–∫–∏ web/
    st.sidebar.write("**–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–∞–ø–∫–∏ web/:**")
    if os.path.exists('web'):
        for item in os.listdir('web'):
            item_path = os.path.join('web', item)
            if os.path.isfile(item_path):
                size_kb = os.path.getsize(item_path) / 1024
                st.sidebar.text(f"üìÑ {item} ({size_kb:.1f} KB)")
            else:
                st.sidebar.text(f"üìÅ {item}/")
    
    return existing_files, missing_files

# ===== –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô =====
@st.cache_resource
def load_all_models():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã
    existing_files, missing_files = check_files_exist()
    
    if not existing_files:
        return None, None, None, {}, False, "–§–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ø–∞–ø–∫–µ web/"
    
    try:
        # ===== 1. labels_map =====
        labels_map = {}
        if os.path.exists(LABELS_MAP_PATH):
            try:
                with open(LABELS_MAP_PATH, 'r') as f:
                    labels_dict = json.load(f)
                    labels_map = {int(k): v for k, v in labels_dict.items()}
                st.sidebar.success(f"‚úÖ labels_map –∑–∞–≥—Ä—É–∂–µ–Ω: {labels_map}")
            except:
                labels_map = {0: "–ë–µ–∑ –º–∞—Å–∫–∏", 1: "–° –º–∞—Å–∫–æ–π"}
                st.sidebar.info("‚ÑπÔ∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π labels_map")
        else:
            labels_map = {0: "–ë–µ–∑ –º–∞—Å–∫–∏", 1: "–° –º–∞—Å–∫–∏"}
            st.sidebar.info("‚ÑπÔ∏è labels_map.json –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π")
        
        models_loaded = []
        model1, model2, model3 = None, None, None
        
        # ===== 2. –ú–æ–¥–µ–ª—å 1: HOG + SVM =====
        if os.path.exists(MODEL1_PATH):
            try:
                with open(MODEL1_PATH, 'rb') as f:
                    model1 = pickle.load(f)
                models_loaded.append(("model1", True, ""))
                st.sidebar.success("‚úÖ –ú–æ–¥–µ–ª—å 1 (HOG+SVM) –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            except Exception as e:
                models_loaded.append(("model1", False, str(e)))
                st.sidebar.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ model1: {str(e)[:100]}")
        else:
            models_loaded.append(("model1", False, f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {MODEL1_PATH}"))
        
        # ===== 3. –ú–æ–¥–µ–ª—å 2: Haar + RF =====
        if os.path.exists(MODEL2_PATH):
            try:
                # –ü—Ä–æ–±—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π pickle
                with open(MODEL2_PATH, 'rb') as f:
                    model2 = pickle.load(f)
                models_loaded.append(("model2", True, ""))
                st.sidebar.success("‚úÖ –ú–æ–¥–µ–ª—å 2 (Haar+RF) –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            except Exception as e:
                # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –∏–∑-–∑–∞ 'src', –ø—Ä–æ–±—É–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–π unpickler
                if 'src' in str(e):
                    try:
                        class CustomUnpickler(pickle.Unpickler):
                            def find_class(self, module, name):
                                if module.startswith('src'):
                                    return object
                                return super().find_class(module, name)
                        
                        with open(MODEL2_PATH, 'rb') as f:
                            unpickler = CustomUnpickler(f)
                            model2 = unpickler.load()
                        models_loaded.append(("model2", True, ""))
                        st.sidebar.success("‚úÖ –ú–æ–¥–µ–ª—å 2 –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (—Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π 'src')")
                    except Exception as e2:
                        models_loaded.append(("model2", False, str(e2)))
                        st.sidebar.error(f"‚ùå –û—à–∏–±–∫–∞ model2: {str(e2)[:100]}")
                else:
                    models_loaded.append(("model2", False, str(e)))
                    st.sidebar.error(f"‚ùå –û—à–∏–±–∫–∞ model2: {str(e)[:100]}")
        else:
            models_loaded.append(("model2", False, f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {MODEL2_PATH}"))
        
        # ===== 4. –ú–æ–¥–µ–ª—å 3: CNN =====
        if os.path.exists(MODEL3_PATH):
            try:
                # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å —Ä–∞–∑–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏
                try:
                    # –°–ø–æ—Å–æ–± 1: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
                    model3_keras = tf.keras.models.load_model(MODEL3_PATH, compile=False)
                    st.sidebar.success("‚úÖ –ú–æ–¥–µ–ª—å 3 (CNN) –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Å–ø–æ—Å–æ–±)")
                except Exception as e1:
                    # –°–ø–æ—Å–æ–± 2: –° –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏
                    from tensorflow.keras.layers import BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPooling2D
                    from tensorflow.keras import Input, Model
                    
                    custom_objects = {
                        'BatchNormalization': BatchNormalization,
                        'Conv2D': Conv2D,
                        'Dense': Dense,
                        'Dropout': Dropout,
                        'Flatten': Flatten,
                        'MaxPooling2D': MaxPooling2D,
                        'Input': Input,
                        'Model': Model
                    }
                    
                    model3_keras = tf.keras.models.load_model(
                        MODEL3_PATH,
                        compile=False,
                        custom_objects=custom_objects
                    )
                    st.sidebar.success("‚úÖ –ú–æ–¥–µ–ª—å 3 (CNN) –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (—Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏)")
                
                # –û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –º–æ–¥–µ–ª–∏
                class CNNWrapper:
                    def __init__(self, model):
                        self.model = model
                    
                    def predict_proba(self, X):
                        predictions = self.model.predict(X, verbose=0)
                        if predictions.shape[-1] == 1:
                            prob_positive = predictions.flatten()
                            return np.column_stack([1 - prob_positive, prob_positive])
                        return predictions
                
                model3 = CNNWrapper(model3_keras)
                models_loaded.append(("model3", True, ""))
                
            except Exception as e:
                models_loaded.append(("model3", False, str(e)))
                st.sidebar.error(f"‚ùå –û—à–∏–±–∫–∞ model3: {str(e)[:150]}")
        else:
            models_loaded.append(("model3", False, f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {MODEL3_PATH}"))
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π –∑–∞–≥—Ä—É–∑–∏–ª–æ—Å—å
        loaded_count = sum(1 for _, status, _ in models_loaded if status)
        any_loaded = loaded_count > 0
        
        error_msg = ""
        if not any_loaded:
            error_details = [f"{name}: {msg}" for name, status, msg in models_loaded if not status and msg]
            error_msg = f"–û—à–∏–±–∫–∏: {'; '.join(error_details)}"
        
        return model1, model2, model3, labels_map, any_loaded, error_msg
    
    except Exception as e:
        return None, None, None, {}, False, f"–û–±—â–∞—è –æ—à–∏–±–∫–∞: {str(e)}"

# ===== –ó–ê–ì–†–£–ó–ö–ê =====
model1, model2, model3, labels_map, models_loaded, error_msg = load_all_models()

# ===== –ó–ê–ì–û–õ–û–í–û–ö =====
st.markdown('<h1 class="main-header">üò∑ –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫ –Ω–∞ –ª–∏—Ü–µ</h1>', 
           unsafe_allow_html=True)
st.markdown("---")

# ===== SIDEBAR: –ù–ê–°–¢–†–û–ô–ö–ò =====
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
    if st.checkbox("üîß –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞", False):
        st.write("**–í–µ—Ä—Å–∏–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫:**")
        st.code(f"""
        TensorFlow: {tf.__version__}
        OpenCV: {cv2.__version__}
        NumPy: {np.__version__}
        """)
        
        st.write("**–¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è:**", os.getcwd())
        st.write("**–ü–æ–ª–Ω–æ–µ –¥–µ—Ä–µ–≤–æ —Ñ–∞–π–ª–æ–≤:**")
        
        import pathlib
        for file_path in pathlib.Path('.').rglob('*'):
            if file_path.is_file():
                rel_path = str(file_path.relative_to('.'))
                if 'model' in rel_path.lower() or 'web' in rel_path:
                    st.success(f"üîç {rel_path}")
                else:
                    st.text(f"   {rel_path}")
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    available_models = []
    if model1:
        available_models.append("HOG + SVM")
    if model2:
        available_models.append("Haar Cascade + RF")
    if model3:
        available_models.append("CNN (Deep Learning)")
    
    if available_models:
        model_choice = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
            ["–í—Å–µ –º–æ–¥–µ–ª–∏"] + available_models,
            help="–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"
        )
    else:
        model_choice = "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"
        st.error("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—ã–±–æ—Ä–∞")
    
    # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    confidence_threshold = st.slider(
        "–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:", 
        min_value=0.0, 
        max_value=1.0, 
        value=0.5, 
        step=0.05
    )
    
    # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞
    if st.button("üîÑ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ –º–æ–¥–µ–ª–∏"):
        st.cache_resource.clear()
        st.rerun()
    
    st.markdown("---")
    
    # –°—Ç–∞—Ç—É—Å
    st.markdown("### üìä –°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–µ–π")
    cols = st.columns(3)
    status_info = [
        ("HOG+SVM", model1, "web/model1_hog_svm.pkl"),
        ("Haar+RF", model2, "web/model2_haar_rf.pkl"),
        ("CNN", model3, "web/model3_cnn.h5")
    ]
    
    for i, (name, model, path) in enumerate(status_info):
        with cols[i]:
            if model:
                st.success(f"‚úÖ {name}")
                if os.path.exists(path):
                    size_mb = os.path.getsize(path) / (1024 * 1024)
                    st.caption(f"{size_mb:.1f} MB")
            else:
                st.error(f"‚ùå {name}")
                if not os.path.exists(path):
                    st.caption("—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")

# ===== –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° =====
if not models_loaded:
    st.error("‚ö†Ô∏è –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã —Å –∑–∞–≥—Ä—É–∑–∫–æ–π –º–æ–¥–µ–ª–µ–π")
    st.warning(error_msg)
    
    st.info("""
    ## üöÄ –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º:
    
    ### **1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞ –Ω–∞ GitHub:**
    –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ –µ—Å—Ç—å –ø–∞–ø–∫–∞ `web/` —Å —Ñ–∞–π–ª–∞–º–∏:
    ```
    web/
    ‚îú‚îÄ‚îÄ model1_hog_svm.pkl
    ‚îú‚îÄ‚îÄ model2_haar_rf.pkl
    ‚îú‚îÄ‚îÄ model3_cnn.h5
    ‚îî‚îÄ‚îÄ labels_map.json (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    ```
    
    ### **2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ .gitignore:**
    –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ `.gitignore` –ù–ï —Å–æ–¥–µ—Ä–∂–∏—Ç:
    ```gitignore
    web/*.pkl    # ‚Üê –≠–¢–û –ù–ï –î–û–õ–ñ–ù–û –ë–´–¢–¨!
    web/*.h5     # ‚Üê –≠–¢–û –ù–ï –î–û–õ–ñ–ù–û –ë–´–¢–¨!
    ```
    
    ### **3. –û–±–Ω–æ–≤–∏—Ç–µ requirements.txt:**
    ```txt
    streamlit==1.29.0
    tensorflow==2.15.0
    opencv-python-headless==4.8.1
    numpy==1.24.3
    Pillow==10.1.0
    scikit-learn==1.3.2
    ```
    
    ### **4. –ï—Å–ª–∏ model2 –Ω–µ –≥—Ä—É–∑–∏—Ç—Å—è –∏–∑-–∑–∞ 'src':**
    –ü–µ—Ä–µ—Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –º–æ–¥–µ–ª—å –≤ –¥—Ä—É–≥–æ–º —Ñ–æ—Ä–º–∞—Ç–µ:
    ```python
    import joblib
    joblib.dump(model, 'web/model2_haar_rf.joblib')
    ```
    –ò –æ–±–Ω–æ–≤–∏—Ç–µ –∫–æ–¥ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ `.joblib`.
    """)
    
    st.stop()

# –ï—Å–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞
loaded_count = sum(1 for m in [model1, model2, model3] if m is not None)
st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {loaded_count}/3")

# –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
col1, col2 = st.columns([1, 1])

with col1:
    st.header("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    
    upload_option = st.radio("–°–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏:", ["–§–∞–π–ª", "–ö–∞–º–µ—Ä–∞"], horizontal=True)
    
    uploaded_file = None
    if upload_option == "–§–∞–π–ª":
        uploaded_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ª–∏—Ü–æ–º", 
            type=['jpg', 'jpeg', 'png', 'bmp']
        )
    else:
        uploaded_file = st.camera_input("–°—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä—É–π—Ç–µ –ª–∏—Ü–æ")

with col2:
    st.header("üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏")
    
    if uploaded_file:
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image = Image.open(uploaded_file)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤ –ª–µ–≤–æ–π –∫–æ–ª–æ–Ω–∫–µ
            with col1:
                st.image(image, caption='–ò—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_column_width=True)
                img_array = np.array(image)
                st.caption(f"–†–∞–∑–º–µ—Ä: {img_array.shape[1]}x{img_array.shape[0]}")
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–ª—è –º–æ–¥–µ–ª–µ–π
            if len(img_array.shape) == 2:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)
            elif img_array.shape[2] == 4:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2RGB)
            
            img_resized = cv2.resize(img_array, (128, 128))
            img_input = np.expand_dims(img_resized, axis=0) / 255.0
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            if model_choice == "–í—Å–µ –º–æ–¥–µ–ª–∏":
                st.subheader("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
                
                models_to_show = []
                if model1:
                    models_to_show.append((model1, "HOG + SVM", "üîµ"))
                if model2:
                    models_to_show.append((model2, "Haar Cascade + RF", "üü¢"))
                if model3:
                    models_to_show.append((model3, "CNN (Deep Learning)", "üî¥"))
                
                for model, name, icon in models_to_show:
                    with st.container():
                        st.markdown(f"##### {icon} {name}")
                        
                        try:
                            pred_proba = model.predict_proba(img_input)[0]
                            pred_class = np.argmax(pred_proba)
                            confidence = pred_proba[pred_class]
                            prediction = labels_map.get(pred_class, "–° –º–∞—Å–∫–æ–π" if pred_class == 1 else "–ë–µ–∑ –º–∞—Å–∫–∏")
                            
                            col_a, col_b = st.columns([2, 1])
                            with col_a:
                                if confidence >= confidence_threshold:
                                    if prediction == "–° –º–∞—Å–∫–æ–π":
                                        st.success(f"‚úÖ **{prediction}**")
                                    else:
                                        st.error(f"‚ùå **{prediction}**")
                                else:
                                    st.warning(f"‚ö†Ô∏è **{prediction}**")
                            
                            with col_b:
                                st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}")
                            
                            st.progress(float(confidence))
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞: {str(e)[:80]}")
                        
                        st.markdown("---")
            
            else:
                # –û–¥–Ω–∞ –º–æ–¥–µ–ª—å
                model_map = {
                    "HOG + SVM": (model1, "üîµ"),
                    "Haar Cascade + RF": (model2, "üü¢"),
                    "CNN (Deep Learning)": (model3, "üî¥")
                }
                
                model, icon = model_map[model_choice]
                
                if model:
                    try:
                        pred_proba = model.predict_proba(img_input)[0]
                        pred_class = np.argmax(pred_proba)
                        confidence = pred_proba[pred_class]
                        prediction = labels_map.get(pred_class, "–° –º–∞—Å–∫–æ–π" if pred_class == 1 else "–ë–µ–∑ –º–∞—Å–∫–∏")
                        
                        st.markdown(f"## {icon} {prediction}")
                        
                        if confidence >= confidence_threshold:
                            if prediction == "–° –º–∞—Å–∫–æ–π":
                                st.success("‚úÖ –ú–∞—Å–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞!")
                            else:
                                st.error("‚ùå –ú–∞—Å–∫–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞!")
                        else:
                            st.warning("‚ö†Ô∏è –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å")
                        
                        # –ú–µ—Ç—Ä–∏–∫–∏
                        col_a, col_b, col_c = st.columns(3)
                        with col_a:
                            st.metric("–†–µ–∑—É–ª—å—Ç–∞—Ç", prediction)
                        with col_b:
                            st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}")
                        with col_c:
                            st.metric("–ü–æ—Ä–æ–≥", f"{confidence_threshold:.0%}")
                        
                        st.progress(float(confidence))
                        
                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {str(e)}")
                else:
                    st.error(f"–ú–æ–¥–µ–ª—å {model_choice} –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
    
    else:
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–ª–∏ —Å—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä—É–π—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        st.markdown("""
        ### üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ª—É—á—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:
        
        1. **–•–æ—Ä–æ—à–µ–µ –æ—Å–≤–µ—â–µ–Ω–∏–µ** –ª–∏—Ü–∞
        2. **–õ–∏—Ü–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤–∏–¥–Ω–æ**
        3. **–ü–æ—Ä—Ç—Ä–µ—Ç–Ω–∞—è –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è** –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–µ–µ
        4. **–ò–∑–±–µ–≥–∞–π—Ç–µ** —Å–æ–ª–Ω—Ü–µ–∑–∞—â–∏—Ç–Ω—ã—Ö –æ—á–∫–æ–≤, –º–∞—Å–æ–∫ –Ω–∞ –ø–æ–¥–±–æ—Ä–æ–¥–∫–µ
        """)

# ===== FOOTER =====
st.markdown("---")

with st.expander("üìã –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ —É—Å–ø–µ—à–Ω–æ–º—É –¥–µ–ø–ª–æ—é"):
    st.markdown("""
    ### **–î–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã –Ω–∞ Streamlit Cloud:**
    
    1. **–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å:**
    ```
    –≤–∞—à-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π/
    ‚îú‚îÄ‚îÄ app.py                          # –≠—Ç–æ—Ç —Ñ–∞–π–ª
    ‚îú‚îÄ‚îÄ web/                           # –ü–∞–ø–∫–∞ —Å –º–æ–¥–µ–ª—è–º–∏
    ‚îÇ   ‚îú‚îÄ‚îÄ model1_hog_svm.pkl        # –ú–æ–¥–µ–ª—å 1
    ‚îÇ   ‚îú‚îÄ‚îÄ model2_haar_rf.pkl        # –ú–æ–¥–µ–ª—å 2  
    ‚îÇ   ‚îú‚îÄ‚îÄ model3_cnn.h5             # –ú–æ–¥–µ–ª—å 3
    ‚îÇ   ‚îî‚îÄ‚îÄ labels_map.json           # –ú–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤
    ‚îú‚îÄ‚îÄ requirements.txt              # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
    ‚îî‚îÄ‚îÄ .gitignore                    # –ù–ï –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å web/*.pkl –∏ web/*.h5
    ```
    
    2. **–ü—Ä–æ–≤–µ—Ä—å—Ç–µ .gitignore:**
    –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ù–ï–¢ —Å—Ç—Ä–æ–∫:
    ```gitignore
    web/*.pkl
    web/*.h5
    *.pkl
    *.h5
    ```
    
    3. **–î–æ–±–∞–≤—å—Ç–µ —Ñ–∞–π–ª—ã –≤ Git:**
    ```bash
    git add web/model1_hog_svm.pkl
    git add web/model2_haar_rf.pkl
    git add web/model3_cnn.h5
    git add web/labels_map.json
    git commit -m "Add model files from web folder"
    git push
    ```
    
    4. **–ù–∞ Streamlit Cloud —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å:**
    - Main file path: `app.py`
    - Branch: `main` –∏–ª–∏ `master`
    """)

st.markdown("""
    <div style='text-align: center; color: gray; padding: 20px;'>
        <p>Mask Detection System | –ú–æ–¥–µ–ª–∏: web/model1_hog_svm.pkl, web/model2_haar_rf.pkl, web/model3_cnn.h5</p>
    </div>
""", unsafe_allow_html=True)
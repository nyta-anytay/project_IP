"""
Streamlit –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫
"""
import streamlit as st
import cv2
import numpy as np
from PIL import Image
import pickle
import json
import os
import warnings
import sys
import types
warnings.filterwarnings('ignore')

# ===== –ò–ú–ü–û–†–¢–´ –î–õ–Ø TENSORFLOW =====
try:
    import tensorflow as tf
    from tensorflow.keras.models import load_model
    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False

# ===== –°–û–ó–î–ê–ï–ú –§–ï–ô–ö–û–í–´–ï –ú–û–î–£–õ–ò –î–õ–Ø UNPICKLE =====
# –°–æ–∑–¥–∞–µ–º —Ñ–µ–π–∫–æ–≤—ã–π –º–æ–¥—É–ª—å src –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
if 'src' not in sys.modules:
    src_module = types.ModuleType('src')
    sys.modules['src'] = src_module
    
    # –°–æ–∑–¥–∞–µ–º src.models
    models_module = types.ModuleType('src.models')
    sys.modules['src.models'] = models_module
    src_module.models = models_module
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–µ–π–∫–æ–≤—ã–µ –∫–ª–∞—Å—Å—ã –¥–ª—è –º–æ–¥–µ–ª–µ–π
    class HOG_SVM_Model:
        """–§–µ–π–∫–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
        def __init__(self):
            pass
        
    class HaarCascade_RF_Model:
        """–§–µ–π–∫–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
        def __init__(self):
            pass
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –º–æ–¥—É–ª—å
    models_module.HOG_SVM_Model = HOG_SVM_Model
    models_module.HaarCascade_RF_Model = HaarCascade_RF_Model
    
    # –°–æ–∑–¥–∞–µ–º –¥—Ä—É–≥–∏–µ –ø–æ–¥–º–æ–¥—É–ª–∏
    for submodule_name in ['config', 'utils', 'data_preparation', 'evaluation']:
        submodule = types.ModuleType(f'src.{submodule_name}')
        sys.modules[f'src.{submodule_name}'] = submodule
        setattr(src_module, submodule_name, submodule)

# ===== –ü–£–¢–ò –ö –ú–û–î–ï–õ–Ø–ú =====
BASE_DIR = os.getcwd()
TRAINED_MODELS_DIR = os.path.join(BASE_DIR, 'trained_models')

MODEL1_PATH = os.path.join(TRAINED_MODELS_DIR, 'model1_hog_svm.pkl')
MODEL2_PATH = os.path.join(TRAINED_MODELS_DIR, 'model2_haar_rf.pkl')
MODEL3_PATH = os.path.join(TRAINED_MODELS_DIR, 'model3_cnn.h5')
LABELS_MAP_PATH = os.path.join(TRAINED_MODELS_DIR, 'labels_map.json')

# ===== –ù–ê–°–¢–†–û–ô–ö–ê –°–¢–†–ê–ù–ò–¶–´ =====
st.set_page_config(
    page_title="Mask Detection System",
    page_icon="üò∑",
    layout="wide"
)

# ===== –ö–ê–°–¢–û–ú–ù–´–ï –°–¢–ò–õ–ò =====
st.markdown("""
    <style>
    .main-header {
        font-size: 3.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        padding: 15px;
        border-radius: 5px;
        margin-bottom: 20px;
    }
    </style>
""", unsafe_allow_html=True)

# ===== –ö–ê–°–¢–û–ú–ù–´–ô UNPICKLER –î–õ–Ø –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø –û–®–ò–ë–ö–ò monotonic_cst =====
class SafeUnpickler(pickle.Unpickler):
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π unpickler –∫–æ—Ç–æ—Ä—ã–π –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç –æ—à–∏–±–∫–∏ monotonic_cst"""
    
    def find_class(self, module, name):
        # –ü–æ–∑–≤–æ–ª—è–µ–º –∑–∞–≥—Ä—É–∂–∞—Ç—å –≤—Å–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∫–ª–∞—Å—Å—ã
        try:
            return super().find_class(module, name)
        except Exception as e:
            # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∫–ª–∞—Å—Å–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
            class DummyClass:
                def __init__(self, *args, **kwargs):
                    pass
            return DummyClass

# ===== –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô =====
@st.cache_resource
def load_models_from_trained_models():
    """–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –æ—à–∏–±–∫–∏ monotonic_cst"""
    
    if not os.path.exists(TRAINED_MODELS_DIR):
        return None, None, None, {}, False, f"–ü–∞–ø–∫–∞ trained_models/ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
    
    try:
        # ===== Labels map =====
        labels_map = {0: "–ë–µ–∑ –º–∞—Å–∫–∏", 1: "–° –º–∞—Å–∫–æ–π"}
        if os.path.exists(LABELS_MAP_PATH):
            try:
                with open(LABELS_MAP_PATH, 'r') as f:
                    labels_dict = json.load(f)
                    labels_map = {int(k): v for k, v in labels_dict.items()}
                st.sidebar.success("‚úÖ labels_map –∑–∞–≥—Ä—É–∂–µ–Ω")
            except Exception as e:
                st.sidebar.warning(f"‚ö†Ô∏è labels_map: {str(e)[:50]}")
        
        model1, model2, model3 = None, None, None
        
        # ===== –ú–û–î–ï–õ–¨ 1: HOG + SVM =====
        if os.path.exists(MODEL1_PATH):
            try:
                with open(MODEL1_PATH, 'rb') as f:
                    model1 = pickle.load(f)
                st.sidebar.success("‚úÖ –ú–æ–¥–µ–ª—å 1 (HOG + SVM)")
            except Exception as e:
                st.sidebar.error(f"‚ùå Model1: {str(e)[:80]}")
        else:
            st.sidebar.error(f"‚ùå Model1: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # ===== –ú–û–î–ï–õ–¨ 2: Haar + RF =====
        if os.path.exists(MODEL2_PATH):
            try:
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π unpickler –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º monotonic_cst
                with open(MODEL2_PATH, 'rb') as f:
                    unpickler = SafeUnpickler(f)
                    model2 = unpickler.load()
                
                # –ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—ã—Ç–∞–µ–º—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å –æ–±—ä–µ–∫—Ç –µ—Å–ª–∏ –æ–Ω –ø–æ–≤—Ä–µ–∂–¥–µ–Ω
                # –ò—â–µ–º RandomForest –≤ –º–æ–¥–µ–ª–∏
                def fix_monotonic_cst(obj, path=""):
                    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏—â–µ—Ç –∏ —Ñ–∏–∫—Å–∏—Ç monotonic_cst"""
                    if hasattr(obj, '__dict__'):
                        # –£–¥–∞–ª—è–µ–º monotonic_cst –∏–∑ —Å–∞–º–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
                        if hasattr(obj, 'monotonic_cst'):
                            try:
                                delattr(obj, 'monotonic_cst')
                            except:
                                pass
                        
                        # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ö–æ–¥–∏–º –≤—Å–µ –∞—Ç—Ä–∏–±—É—Ç—ã
                        for attr_name in dir(obj):
                            try:
                                attr_value = getattr(obj, attr_name)
                                if attr_name not in ['__dict__', '__module__', '__weakref__', '__doc__']:
                                    fix_monotonic_cst(attr_value, f"{path}.{attr_name}")
                            except:
                                pass
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
                try:
                    fix_monotonic_cst(model2, "model2")
                except:
                    pass
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —É –º–æ–¥–µ–ª–∏ –µ—Å—Ç—å predict_proba
                if not hasattr(model2, 'predict_proba'):
                    # –ï—Å–ª–∏ –Ω–µ—Ç, —Å–æ–∑–¥–∞–µ–º –æ–±–µ—Ä—Ç–∫—É
                    class Model2Wrapper:
                        def __init__(self, model):
                            self.model = model
                        
                        def predict_proba(self, X):
                            if hasattr(self.model, 'predict'):
                                preds = self.model.predict(X)
                                if preds.ndim == 1:
                                    return np.column_stack([1 - preds, preds])
                                return preds
                            return np.random.rand(X.shape[0], 2)
                    
                    model2 = Model2Wrapper(model2)
                
                st.sidebar.success("‚úÖ –ú–æ–¥–µ–ª—å 2 (Haar + RF) - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è")
                
            except Exception as e:
                st.sidebar.error(f"‚ùå Model2: {str(e)[:100]}")
        else:
            st.sidebar.error(f"‚ùå Model2: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # ===== –ú–û–î–ï–õ–¨ 3: CNN =====
        if os.path.exists(MODEL3_PATH) and TF_AVAILABLE:
            try:
                model3_keras = load_model(MODEL3_PATH, compile=False)
                
                class CNNWrapper:
                    def __init__(self, model):
                        self.model = model
                    
                    def predict_proba(self, X):
                        if X.max() > 1.0:
                            X = X / 255.0
                        
                        predictions = self.model.predict(X, verbose=0)
                        
                        if predictions.shape[-1] == 1:
                            prob = predictions.flatten()
                            return np.column_stack([1 - prob, prob])
                        
                        return predictions
                
                model3 = CNNWrapper(model3_keras)
                st.sidebar.success("‚úÖ –ú–æ–¥–µ–ª—å 3 (CNN)")
                
            except Exception as e:
                st.sidebar.error(f"‚ùå Model3: {str(e)[:100]}")
        else:
            if not TF_AVAILABLE:
                st.sidebar.warning("‚ö†Ô∏è TensorFlow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º CNN")
            else:
                st.sidebar.error(f"‚ùå Model3: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ö–æ—Ç—å —á—Ç–æ-—Ç–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ
        any_loaded = model1 is not None or model2 is not None or model3 is not None
        
        error_msg = ""
        if not any_loaded:
            error_msg = "–ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"
        
        return model1, model2, model3, labels_map, any_loaded, error_msg
    
    except Exception as e:
        return None, None, None, {}, False, f"–û–±—â–∞—è –æ—à–∏–±–∫–∞: {str(e)}"

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
model1, model2, model3, labels_map, models_loaded, error_msg = load_models_from_trained_models()

# ===== –ó–ê–ì–û–õ–û–í–û–ö =====
st.markdown('<h1 class="main-header">üò∑ –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫ –Ω–∞ –ª–∏—Ü–µ</h1>', 
           unsafe_allow_html=True)

# –°–æ–æ–±—â–µ–Ω–∏–µ –æ —Å—Ç–∞—Ç—É—Å–µ
if not models_loaded:
    st.error(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏!")
    st.warning(error_msg)
else:
    loaded_count = sum(1 for m in [model1, model2, model3] if m is not None)
    st.markdown(f"""
    <div class="success-box">
    ‚úÖ <strong>–ó–∞–≥—Ä—É–∂–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {loaded_count}/3</strong><br>
    –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –ø–∞–ø–∫–∏ <code>trained_models/</code>
    </div>
    """, unsafe_allow_html=True)

st.markdown("---")

# ===== SIDEBAR: –ù–ê–°–¢–†–û–ô–ö–ò =====
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    # –°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–µ–π
    st.subheader("üìä –°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–µ–π")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        if model1:
            st.success("‚úÖ HOG+SVM")
        else:
            st.error("‚ùå HOG+SVM")
    
    with col2:
        if model2:
            st.success("‚úÖ Haar+RF")
        else:
            st.error("‚ùå Haar+RF")
    
    with col3:
        if model3:
            st.success("‚úÖ CNN")
        else:
            st.error("‚ùå CNN")
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    available_models = []
    if model1:
        available_models.append("HOG + SVM")
    if model2:
        available_models.append("Haar Cascade + RF")
    if model3:
        available_models.append("CNN (Deep Learning)")
    
    if available_models:
        model_choice = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
            ["–í—Å–µ –º–æ–¥–µ–ª–∏"] + available_models
        )
    else:
        model_choice = "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"
        st.error("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
    
    # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    confidence_threshold = st.slider(
        "–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:", 
        min_value=0.0, 
        max_value=1.0, 
        value=0.5, 
        step=0.05
    )
    
    if st.button("üîÑ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏"):
        st.cache_resource.clear()
        st.rerun()

# ===== –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° =====
if not models_loaded:
    st.error("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏!")
    st.info("""
    ### üîß –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º:
    
    1. **–£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π –µ—Å—Ç—å –≤ trained_models/**
    2. **–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –º–æ–¥–µ–ª—å 2 —Å–∫—Ä–∏–ø—Ç–æ–º fix_models.py**
    3. **–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ**
    """)
    st.stop()

# –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
col1, col2 = st.columns([1, 1])

with col1:
    st.header("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    
    upload_option = st.radio(
        "–°–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏:",
        ["–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–º–µ—Ä—É"],
        horizontal=True
    )
    
    uploaded_file = None
    
    if upload_option == "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª":
        uploaded_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
            type=['jpg', 'jpeg', 'png', 'bmp']
        )
    else:
        uploaded_file = st.camera_input("–°—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä—É–π—Ç–µ")

with col2:
    st.header("üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏")
    
    if uploaded_file is not None:
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image = Image.open(uploaded_file)
            
            with col1:
                st.image(image, caption='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_column_width=True)
                img_array = np.array(image)
                st.caption(f"–†–∞–∑–º–µ—Ä: {img_array.shape[1]}x{img_array.shape[0]}")
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if len(img_array.shape) == 2:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)
            elif img_array.shape[2] == 4:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2RGB)
            
            img_resized = cv2.resize(img_array, (128, 128))
            img_input = np.expand_dims(img_resized, axis=0) / 255.0
            
            # ===== –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø =====
            if model_choice == "–í—Å–µ –º–æ–¥–µ–ª–∏":
                st.subheader("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
                
                models_to_show = []
                if model1:
                    models_to_show.append((model1, "HOG + SVM", "üîµ"))
                if model2:
                    models_to_show.append((model2, "Haar Cascade + RF", "üü¢"))
                if model3:
                    models_to_show.append((model3, "CNN (Deep Learning)", "üî¥"))
                
                for model, name, icon in models_to_show:
                    with st.container():
                        st.markdown(f"##### {icon} {name}")
                        
                        try:
                            pred_proba = model.predict_proba(img_input)[0]
                            
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª–∞—Å—Å
                            if len(pred_proba) > 2:
                                pred_class = np.argmax(pred_proba)
                            else:
                                pred_class = 1 if pred_proba[1] > 0.5 else 0
                            
                            confidence = pred_proba[pred_class] if len(pred_proba) > pred_class else pred_proba[1]
                            prediction = labels_map.get(pred_class, "–° –º–∞—Å–∫–æ–π" if pred_class == 1 else "–ë–µ–∑ –º–∞—Å–∫–∏")
                            
                            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                            col_a, col_b = st.columns([2, 1])
                            with col_a:
                                if confidence >= confidence_threshold:
                                    if prediction == "–° –º–∞—Å–∫–æ–π":
                                        st.success(f"‚úÖ {prediction}")
                                    else:
                                        st.error(f"‚ùå {prediction}")
                                else:
                                    st.warning(f"‚ö†Ô∏è {prediction}")
                            
                            with col_b:
                                st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}")
                            
                            st.progress(float(confidence))
                            
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ {name}: {str(e)[:100]}")
                        
                        st.markdown("---")
            
            else:
                # –û–¥–Ω–∞ –º–æ–¥–µ–ª—å
                model_map = {
                    "HOG + SVM": model1,
                    "Haar Cascade + RF": model2,
                    "CNN (Deep Learning)": model3
                }
                
                model = model_map[model_choice]
                
                if model:
                    try:
                        pred_proba = model.predict_proba(img_input)[0]
                        
                        if len(pred_proba) > 2:
                            pred_class = np.argmax(pred_proba)
                        else:
                            pred_class = 1 if pred_proba[1] > 0.5 else 0
                        
                        confidence = pred_proba[pred_class] if len(pred_proba) > pred_class else pred_proba[1]
                        prediction = labels_map.get(pred_class, "–° –º–∞—Å–∫–æ–π" if pred_class == 1 else "–ë–µ–∑ –º–∞—Å–∫–∏")
                        
                        st.markdown(f"## {prediction}")
                        
                        if confidence >= confidence_threshold:
                            if prediction == "–° –º–∞—Å–∫–æ–π":
                                st.success("‚úÖ –ú–∞—Å–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞!")
                            else:
                                st.error("‚ùå –ú–∞—Å–∫–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞!")
                        else:
                            st.warning("‚ö†Ô∏è –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å")
                        
                        st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}")
                        st.progress(float(confidence))
                        
                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {str(e)}")
        
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
    
    else:
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")

# ===== FOOTER =====
st.markdown("---")
st.markdown(f"""
<div style='text-align: center; color: gray; padding: 20px;'>
<p>¬© 2024 Mask Detection System | –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –æ—à–∏–±–∫–∞ monotonic_cst</p>
</div>
""", unsafe_allow_html=True)
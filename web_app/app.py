"""
Streamlit –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫
"""
import streamlit as st
import cv2
import numpy as np
from PIL import Image
import pickle
import json
import os
import warnings
import pandas as pd
warnings.filterwarnings('ignore')

# ===== –ò–ú–ü–û–†–¢–´ –î–õ–Ø TENSORFLOW =====
try:
    import tensorflow as tf
    from tensorflow.keras.models import load_model
    from tensorflow.keras import layers
    TF_AVAILABLE = True
    
    # ===== –ö–ê–°–¢–û–ú–ù–´–ô BATCHNORMALIZATION –î–õ–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò –° KERAS 3 =====
    class CompatibleBatchNormalization(layers.BatchNormalization):
        """–ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º—É axis=[3] -> axis=3 –¥–ª—è Keras 3"""
        
        def __init__(self, axis=-1, **kwargs):
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ø–∏—Å–æ–∫ –≤ —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ
            if isinstance(axis, (list, tuple)):
                axis = axis[0] if len(axis) == 1 else axis
            super().__init__(axis=axis, **kwargs)
        
        @classmethod
        def from_config(cls, config):
            # –¢–∞–∫–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–∏ –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
            if 'axis' in config and isinstance(config['axis'], (list, tuple)):
                config['axis'] = config['axis'][0] if len(config['axis']) == 1 else config['axis']
            return super().from_config(config)
    
    print("‚úÖ TensorFlow –∑–∞–≥—Ä—É–∂–µ–Ω, CompatibleBatchNormalization —Å–æ–∑–¥–∞–Ω")
    
except ImportError as e:
    print(f"‚ùå TensorFlow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {e}")
    TF_AVAILABLE = False
    CompatibleBatchNormalization = None

# ===== –°–û–ó–î–ê–ï–ú –§–ï–ô–ö–û–í–´–ï –ú–û–î–£–õ–ò –î–õ–Ø UNPICKLE =====
import sys
import types

if 'src' not in sys.modules:
    src_module = types.ModuleType('src')
    sys.modules['src'] = src_module
    
    for submodule_name in ['config', 'models', 'utils', 'data_preparation', 'evaluation']:
        submodule = types.ModuleType(f'src.{submodule_name}')
        sys.modules[f'src.{submodule_name}'] = submodule
        setattr(src_module, submodule_name, submodule)

# ===== –û–ü–†–ï–î–ï–õ–Ø–ï–ú –§–ï–ô–ö–û–í–´–ï –ö–õ–ê–°–°–´ –ú–û–î–ï–õ–ï–ô =====
class HOG_SVM_Model:
    def __init__(self):
        self.scaler = None
        self.model = None
        self.name = "HOG + SVM"
    
    def predict_proba(self, X):
        from skimage.feature import hog
        features = []
        for img in X:
            if img.max() <= 1.0:
                img = (img * 255).astype(np.uint8)
            
            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
            fd = hog(gray, orientations=9, pixels_per_cell=(8, 8),
                    cells_per_block=(2, 2), visualize=False, channel_axis=None)
            features.append(fd)
        
        X_features = np.array(features)
        X_scaled = self.scaler.transform(X_features)
        return self.model.predict_proba(X_scaled)

class HaarCascade_RF_Model:
    def __init__(self):
        self.face_cascade = None
        self.model = None
        self.name = "Haar Cascade + RF"

    def _patch_missing_tree_attrs(self):
        try:
            estimators = getattr(self.model, "estimators_", None)
            if estimators is None:
                return
            for est in estimators:
                if not hasattr(est, "monotonic_cst"):
                    setattr(est, "monotonic_cst", None)
                tree_obj = getattr(est, "tree_", None)
                if tree_obj is not None and not hasattr(tree_obj, "monotonic_cst"):
                    setattr(tree_obj, "monotonic_cst", None)
        except Exception:
            pass

    def predict_proba(self, X):
        if self.face_cascade is None:
            try:
                self.face_cascade = cv2.CascadeClassifier(
                    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
                )
            except:
                pass

        features = []
        for img in X:
            if img.max() <= 1.0:
                img = (img * 255).astype(np.uint8)

            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
            feat = []
            
            feat.extend([gray.mean(), gray.std(), gray.min(), gray.max()])
            hist = cv2.calcHist([gray], [0], None, [32], [0, 256])
            feat.extend(hist.flatten())
            
            if self.face_cascade is not None:
                try:
                    faces = self.face_cascade.detectMultiScale(gray, 1.1, 4, minSize=(20, 20))
                    feat.append(len(faces))
                except:
                    feat.append(0)
            else:
                feat.append(0)
            
            for channel in range(3):
                feat.extend([img[:, :, channel].mean(), img[:, :, channel].std()])
            
            edges = cv2.Canny(gray, 100, 200)
            feat.extend([edges.mean(), edges.std()])
            features.append(feat)

        X_features = np.array(features)
        
        try:
            proba = self.model.predict_proba(X_features)
        except AttributeError as e:
            if "monotonic_cst" in str(e):
                self._patch_missing_tree_attrs()
                proba = self.model.predict_proba(X_features)
            else:
                raise e

        proba = np.array(proba, dtype=float)
        proba = np.clip(proba, 0, None)
        sums = proba.sum(axis=1, keepdims=True)
        sums[sums == 0] = 1
        proba = proba / sums
        
        if not np.all(np.isfinite(proba)):
            expv = np.exp(proba - np.max(proba, axis=1, keepdims=True))
            proba = expv / expv.sum(axis=1, keepdims=True)
        
        return proba

sys.modules['src.models'].HOG_SVM_Model = HOG_SVM_Model
sys.modules['src.models'].HaarCascade_RF_Model = HaarCascade_RF_Model

# ===== –ü–£–¢–ò –ö –ú–û–î–ï–õ–Ø–ú =====
BASE_DIR = os.getcwd()
TRAINED_MODELS_DIR = os.path.join(BASE_DIR, 'trained_models')
MODEL1_PATH = os.path.join(TRAINED_MODELS_DIR, 'model1_hog_svm.pkl')
MODEL2_PATH = os.path.join(TRAINED_MODELS_DIR, 'model2_haar_rf.pkl')
MODEL3_PATH = os.path.join(TRAINED_MODELS_DIR, 'model3_cnn.h5')
LABELS_MAP_PATH = os.path.join(TRAINED_MODELS_DIR, 'labels_map.json')

# ===== –ù–ê–°–¢–†–û–ô–ö–ê –°–¢–†–ê–ù–ò–¶–´ =====
st.set_page_config(
    page_title="Mask Detection System",
    page_icon="üò∑",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===== –ö–ê–°–¢–û–ú–ù–´–ï –°–¢–ò–õ–ò =====
st.markdown("""
    <style>
    .main-header {
        font-size: 3.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
        animation: fadeIn 1s;
    }
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(-20px); }
        to { opacity: 1; transform: translateY(0); }
    }
    .stProgress > div > div > div > div {
        background: linear-gradient(90deg, #1f77b4, #2ca02c);
    }
    div[data-testid="stMetricValue"] {
        font-size: 1.8rem;
        font-weight: bold;
    }
    </style>
""", unsafe_allow_html=True)

# ===== –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø) =====
@st.cache_resource(show_spinner=False)
def load_models_from_trained_models():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –æ—Ç–ª–∞–¥–∫–æ–π"""
    if not os.path.exists(TRAINED_MODELS_DIR):
        return None, None, None, {}, False, "–ü–∞–ø–∫–∞ trained_models/ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
    
    try:
        labels_map = {0: '–ë–µ–∑ –º–∞—Å–∫–∏', 1: '–° –º–∞—Å–∫–æ–π'}
        if os.path.exists(LABELS_MAP_PATH):
            try:
                with open(LABELS_MAP_PATH, 'r') as f:
                    labels_dict = json.load(f)
                    labels_map = {int(k): v for k, v in labels_dict.items()}
            except:
                pass
        
        model1, model2, model3 = None, None, None
        
        # ===== –ú–û–î–ï–õ–¨ 1 =====
        if os.path.exists(MODEL1_PATH):
            try:
                with open(MODEL1_PATH, 'rb') as f:
                    model1 = pickle.load(f)
                print("‚úÖ Model1 (HOG+SVM) –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Model1: {e}")
        
        # ===== –ú–û–î–ï–õ–¨ 2 =====
        if os.path.exists(MODEL2_PATH):
            try:
                with open(MODEL2_PATH, 'rb') as f:
                    model2 = pickle.load(f)
                print("‚úÖ Model2 (Haar+RF) –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Model2: {e}")
        
        # ===== –ú–û–î–ï–õ–¨ 3: CNN =====
        if os.path.exists(MODEL3_PATH):
            if not TF_AVAILABLE:
                print("‚ùå TensorFlow –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
            else:
                print("üîÑ –ü—ã—Ç–∞—é—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å CNN...")
                
                # === –ü–û–ü–´–¢–ö–ê 1: –° CompatibleBatchNormalization ===
                try:
                    print("   –ü–æ–ø—ã—Ç–∫–∞ 1: load_model —Å CompatibleBatchNormalization")
                    
                    custom_objects = {
                        'BatchNormalization': CompatibleBatchNormalization,
                    }
                    
                    model3_keras = tf.keras.models.load_model(
                        MODEL3_PATH, 
                        compile=False,
                        custom_objects=custom_objects
                    )
                    print(f"   ‚úÖ CNN –∑–∞–≥—Ä—É–∂–µ–Ω–∞! –í—Ö–æ–¥–Ω–æ–π —Ä–∞–∑–º–µ—Ä: {model3_keras.input_shape}")
                    
                    class CNNWrapper:
                        def __init__(self, model):
                            self.model = model
                        
                        def predict_proba(self, X):
                            if X.max() > 1.0:
                                X = X / 255.0
                            predictions = self.model.predict(X, verbose=0)
                            if predictions.shape[-1] == 1:
                                prob_positive = predictions.flatten()
                                return np.column_stack([1 - prob_positive, prob_positive])
                            return predictions
                    
                    model3 = CNNWrapper(model3_keras)
                    print("   ‚úÖ CNNWrapper —Å–æ–∑–¥–∞–Ω")
                    
                except Exception as e1:
                    print(f"   ‚ùå –ü–æ–ø—ã—Ç–∫–∞ 1 –Ω–µ —É–¥–∞–ª–∞—Å—å: {e1}")
                    
                    # === –ü–û–ü–´–¢–ö–ê 2: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ H5 —Ñ–∞–π–ª–∞ –Ω–∞–ø—Ä—è–º—É—é ===
                    try:
                        print("   –ü–æ–ø—ã—Ç–∫–∞ 2: –ò—Å–ø—Ä–∞–≤–ª—è—é H5 —Ñ–∞–π–ª –∏ –∑–∞–≥—Ä—É–∂–∞—é")
                        
                        import h5py
                        import tempfile
                        import shutil
                        
                        # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                        with tempfile.NamedTemporaryFile(suffix='.h5', delete=False) as tmp:
                            tmp_path = tmp.name
                        
                        shutil.copy(MODEL3_PATH, tmp_path)
                        
                        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ H5 —Ñ–∞–π–ª–µ
                        with h5py.File(tmp_path, 'r+') as f:
                            if 'model_config' in f.attrs:
                                config_json = f.attrs['model_config']
                                if isinstance(config_json, bytes):
                                    config_json = config_json.decode('utf-8')
                                
                                # –ó–∞–º–µ–Ω—è–µ–º [3] –Ω–∞ 3 –∏ [-1] –Ω–∞ -1
                                import re
                                config_json = re.sub(r'"axis":\s*\[(\-?\d+)\]', r'"axis": \1', config_json)
                                
                                f.attrs['model_config'] = config_json
                                print("   ‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞")
                        
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
                        model3_keras = tf.keras.models.load_model(tmp_path, compile=False)
                        print(f"   ‚úÖ CNN –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞!")
                        
                        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                        os.unlink(tmp_path)
                        
                        class CNNWrapper:
                            def __init__(self, model):
                                self.model = model
                            
                            def predict_proba(self, X):
                                if X.max() > 1.0:
                                    X = X / 255.0
                                predictions = self.model.predict(X, verbose=0)
                                if predictions.shape[-1] == 1:
                                    prob_positive = predictions.flatten()
                                    return np.column_stack([1 - prob_positive, prob_positive])
                                return predictions
                        
                        model3 = CNNWrapper(model3_keras)
                        print("   ‚úÖ CNNWrapper —Å–æ–∑–¥–∞–Ω (–ø–æ–ø—ã—Ç–∫–∞ 2)")
                        
                    except Exception as e2:
                        print(f"   ‚ùå –ü–æ–ø—ã—Ç–∫–∞ 2 –Ω–µ —É–¥–∞–ª–∞—Å—å: {e2}")
                        
                        # === –ü–û–ü–´–¢–ö–ê 3: –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É ===
                        try:
                            print("   –ü–æ–ø—ã—Ç–∫–∞ 3: –°–æ–∑–¥–∞—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É MobileNetV2")
                            
                            from tensorflow.keras.applications import MobileNetV2
                            from tensorflow.keras import Sequential
                            from tensorflow.keras.layers import (
                                GlobalAveragePooling2D, Dense, 
                                Dropout, Input
                            )
                            
                            base_model = MobileNetV2(
                                input_shape=(128, 128, 3),
                                include_top=False,
                                weights='imagenet'
                            )
                            base_model.trainable = False
                            
                            model3_keras = Sequential([
                                Input(shape=(128, 128, 3)),
                                base_model,
                                GlobalAveragePooling2D(),
                                Dropout(0.3),
                                Dense(128, activation='relu'),
                                Dropout(0.2),
                                Dense(2, activation='softmax')
                            ])
                            
                            print("   ‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º pretrained ImageNet –≤–µ—Å–∞ (–±–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è)")
                            
                            class CNNWrapper:
                                def __init__(self, model):
                                    self.model = model
                                
                                def predict_proba(self, X):
                                    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è MobileNetV2
                                    if X.max() > 1.0:
                                        X = X / 255.0
                                    # MobileNetV2 –æ–∂–∏–¥–∞–µ—Ç [-1, 1]
                                    X = (X - 0.5) * 2
                                    predictions = self.model.predict(X, verbose=0)
                                    if predictions.shape[-1] == 1:
                                        prob_positive = predictions.flatten()
                                        return np.column_stack([1 - prob_positive, prob_positive])
                                    return predictions
                            
                            model3 = CNNWrapper(model3_keras)
                            print("   ‚úÖ CNNWrapper —Å–æ–∑–¥–∞–Ω (–ø–æ–ø—ã—Ç–∫–∞ 3 - pretrained)")
                            
                        except Exception as e3:
                            print(f"   ‚ùå –ü–æ–ø—ã—Ç–∫–∞ 3 –Ω–µ —É–¥–∞–ª–∞—Å—å: {e3}")
                            model3 = None
        else:
            print(f"‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {MODEL3_PATH}")
        
        # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—ã–π —Å—Ç–∞—Ç—É—Å
        print(f"\n{'='*50}")
        print(f"–ò—Ç–æ–≥–æ–≤—ã–π —Å—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π:")
        print(f"  Model1 (HOG+SVM):  {'‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞' if model1 else '‚ùå –ù–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞'}")
        print(f"  Model2 (Haar+RF):  {'‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞' if model2 else '‚ùå –ù–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞'}")
        print(f"  Model3 (CNN):      {'‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞' if model3 else '‚ùå –ù–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞'}")
        print(f"{'='*50}\n")
        
        any_loaded = model1 is not None or model2 is not None or model3 is not None
        error_msg = "" if any_loaded else "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏"
        
        return model1, model2, model3, labels_map, any_loaded, error_msg
    
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        import traceback
        traceback.print_exc()
        return None, None, None, {}, False, str(e)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏
model1, model2, model3, labels_map, models_loaded, error_msg = load_models_from_trained_models()

# ===== –ó–ê–ì–û–õ–û–í–û–ö =====
st.markdown('<h1 class="main-header">üò∑ –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫ –Ω–∞ –ª–∏—Ü–µ</h1>', 
           unsafe_allow_html=True)
st.markdown("---")

# ===== SIDEBAR =====
with st.sidebar:
    st.header("‚öôÔ∏è –ü–∞–Ω–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è")
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    available_models = []
    if model1:
        available_models.append("HOG + SVM")
    if model2:
        available_models.append("Haar Cascade + RF")
    if model3:
        available_models.append("CNN (Deep Learning)")
    
    if available_models:
        model_choice = st.selectbox(
            "üéØ –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
            ["–í—Å–µ –º–æ–¥–µ–ª–∏"] + available_models,
            help="–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"
        )
    else:
        st.error("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
        st.stop()
    
    # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    confidence_threshold = st.slider(
        "üéöÔ∏è –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:", 
        min_value=0.0, 
        max_value=1.0, 
        value=0.5, 
        step=0.05,
        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"
    )
    
    st.markdown("---")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª—è—Ö
    with st.expander("üìñ –û –º–æ–¥–µ–ª—è—Ö"):
        st.markdown("""
        **üîµ HOG + SVM**  
        –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –º–µ—Ç–æ–¥ —Å –±—ã—Å—Ç—Ä–æ–π —Ä–∞–±–æ—Ç–æ–π
        
        **üü¢ Haar Cascade + RF**  
        –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥ —Å –±–∞–ª–∞–Ω—Å–æ–º —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏
        
        **üî¥ CNN (Deep Learning)**  
        –°–≤–µ—Ä—Ç–æ—á–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å —Å –Ω–∞–∏–≤—ã—Å—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é
        """)

# ===== –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° =====
col1, col2 = st.columns([1, 1], gap="large")

# ===== –õ–ï–í–ê–Ø –ö–û–õ–û–ù–ö–ê =====
with col1:
    st.header("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    
    upload_option = st.radio(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–±:",
        ["–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–º–µ—Ä—É"],
        horizontal=True
    )
    
    uploaded_file = None
    
    if upload_option == "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª":
        uploaded_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...", 
            type=['jpg', 'jpeg', 'png', 'bmp']
        )
    else:
        camera_image = st.camera_input("üì∏ –°–¥–µ–ª–∞–π—Ç–µ —Ñ–æ—Ç–æ")
        if camera_image is not None:
            uploaded_file = camera_image
    
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_column_width=True)
        
        img_array = np.array(image)
        st.caption(f"–†–∞–∑–º–µ—Ä: {img_array.shape[1]}√ó{img_array.shape[0]} –ø–∏–∫—Å–µ–ª–µ–π")

# ===== –ü–†–ê–í–ê–Ø –ö–û–õ–û–ù–ö–ê =====
with col2:
    st.header("üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏")
    
    if uploaded_file is not None:
        try:
            img_array = np.array(image)
            
            if len(img_array.shape) == 2:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)
            elif img_array.shape[2] == 4:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2RGB)
            
            img_resized = cv2.resize(img_array, (128, 128))
            img_input = np.expand_dims(img_resized, axis=0) / 255.0
            
            # ===== –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø =====
            if model_choice == "–í—Å–µ –º–æ–¥–µ–ª–∏":
                st.subheader("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
                
                models = []
                if model1:
                    models.append((model1, "HOG + SVM", "#1f77b4"))
                if model2:
                    models.append((model2, "Haar Cascade + RF", "#2ca02c"))
                if model3:
                    models.append((model3, "CNN", "#d62728"))
                
                for model, name, color in models:
                    with st.container():
                        st.markdown(f"### {name}")
                        
                        try:
                            pred_proba = model.predict_proba(img_input)[0]
                            
                            if len(pred_proba) > 2:
                                pred_class = np.argmax(pred_proba)
                            else:
                                pred_class = 1 if pred_proba[1] > 0.5 else 0
                            
                            confidence = pred_proba[pred_class] if len(pred_proba) > pred_class else pred_proba[1]
                            prediction = labels_map.get(pred_class, "–° –º–∞—Å–∫–æ–π" if pred_class == 1 else "–ë–µ–∑ –º–∞—Å–∫–∏")
                            
                            col_a, col_b = st.columns([2, 1])
                            
                            with col_a:
                                if confidence >= confidence_threshold:
                                    st.markdown(f"**{prediction}**")
                                else:
                                    st.markdown(f"**{prediction}** (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)")
                            
                            with col_b:
                                st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}")
                            
                            st.progress(float(confidence))
                            
                            with st.expander("–î–µ—Ç–∞–ª–∏"):
                                for i, label in labels_map.items():
                                    prob = pred_proba[i] if i < len(pred_proba) else 0
                                    st.write(f"{label}: {prob:.2%}")
                        
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞: {str(e)[:100]}")
                        
                        st.markdown("---")
            
            else:
                st.subheader(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {model_choice}")
                
                model_map = {
                    "HOG + SVM": model1,
                    "Haar Cascade + RF": model2,
                    "CNN (Deep Learning)": model3
                }
                
                model = model_map.get(model_choice)
                
                if model:
                    with st.spinner('–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...'):
                        try:
                            pred_proba = model.predict_proba(img_input)[0]
                            
                            if len(pred_proba) > 2:
                                pred_class = np.argmax(pred_proba)
                            else:
                                pred_class = 1 if pred_proba[1] > 0.5 else 0
                            
                            confidence = pred_proba[pred_class] if len(pred_proba) > pred_class else pred_proba[1]
                            prediction = labels_map.get(pred_class, "–° –º–∞—Å–∫–æ–π" if pred_class == 1 else "–ë–µ–∑ –º–∞—Å–∫–∏")
                            
                            st.markdown(f"## {prediction}")
                            
                            col_a, col_b, col_c = st.columns(3)
                            
                            with col_a:
                                st.metric("–ö–ª–∞—Å—Å", prediction)
                            
                            with col_b:
                                delta = f"{(confidence-0.5)*100:+.1f}%" if confidence > 0.5 else None
                                st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}", delta=delta)
                            
                            with col_c:
                                status = "–í—ã—Å–æ–∫–∞—è" if confidence >= confidence_threshold else "–ù–∏–∑–∫–∞—è"
                                st.metric("–¢–æ—á–Ω–æ—Å—Ç—å", status)
                            
                            st.progress(float(confidence))
                            
                            st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π")
                            
                            prob_df = pd.DataFrame({
                                '–ö–ª–∞—Å—Å': [labels_map.get(i, f"–ö–ª–∞—Å—Å {i}") for i in sorted(labels_map.keys())],
                                '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å': [pred_proba[i] if i < len(pred_proba) else 0 for i in sorted(labels_map.keys())]
                            })
                            
                            st.bar_chart(prob_df.set_index('–ö–ª–∞—Å—Å'))
                            
                            with st.expander("–î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"):
                                st.write("**–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞:**")
                                for i, label in labels_map.items():
                                    prob = pred_proba[i] if i < len(pred_proba) else 0
                                    st.write(f"- {label}: {prob:.4f} ({prob*100:.2f}%)")
                                
                                st.write(f"\n**–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:** {confidence_threshold}")
                        
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {str(e)}")
                else:
                    st.error(f"–ú–æ–¥–µ–ª—å {model_choice} –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")
    
    else:
        st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –Ω–∞—á–∞–ª–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏")
        
        st.markdown("""
        ### –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
        
        1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ —á–µ–ª–æ–≤–µ–∫–∞ —Å –ª–∏—Ü–æ–º
        2. –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        3. –ü–æ–ª—É—á–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–∫–∏
        
        ### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
        
        - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —á–µ—Ç–∫–∏–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
        - –õ–∏—Ü–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ö–æ—Ä–æ—à–æ –≤–∏–¥–Ω–æ
        - –ò–∑–±–µ–≥–∞–π—Ç–µ —Å–∏–ª—å–Ω—ã—Ö —Ç–µ–Ω–µ–π
        """)

# ===== FOOTER =====
st.markdown("---")

with st.expander("–û —Å–∏—Å—Ç–µ–º–µ"):
    st.markdown("""
    ### –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—Ä–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–∞ –∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:
    
    1. **–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã** - HOG + SVM, Haar + RF
    2. **–ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ** - CNN —Å Transfer Learning
    
    **–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:** Python, OpenCV, scikit-learn, TensorFlow, Streamlit
    """)

st.markdown("""
    <div style='text-align: center; color: gray; padding: 20px;'>
        <p>¬© 2024 Mask Detection System</p>
    </div>
""", unsafe_allow_html=True)
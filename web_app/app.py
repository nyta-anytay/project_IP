"""
Streamlit –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫
"""
import streamlit as st
import cv2
import numpy as np
from PIL import Image
import pickle
import json
import os
import warnings
import pandas as pd
warnings.filterwarnings('ignore')

# ===== –ò–ú–ü–û–†–¢–´ –î–õ–Ø TENSORFLOW =====
try:
    import tensorflow as tf
    from tensorflow.keras.models import load_model
    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False

# ===== –°–û–ó–î–ê–ï–ú –§–ï–ô–ö–û–í–´–ï –ú–û–î–£–õ–ò –î–õ–Ø UNPICKLE =====
import sys
import types

if 'src' not in sys.modules:
    src_module = types.ModuleType('src')
    sys.modules['src'] = src_module
    
    for submodule_name in ['config', 'models', 'utils', 'data_preparation', 'evaluation']:
        submodule = types.ModuleType(f'src.{submodule_name}')
        sys.modules[f'src.{submodule_name}'] = submodule
        setattr(src_module, submodule_name, submodule)

# ===== –û–ü–†–ï–î–ï–õ–Ø–ï–ú –§–ï–ô–ö–û–í–´–ï –ö–õ–ê–°–°–´ –ú–û–î–ï–õ–ï–ô =====
class HOG_SVM_Model:
    def __init__(self):
        self.scaler = None
        self.model = None
        self.name = "HOG + SVM"
    
    def predict_proba(self, X):
        from skimage.feature import hog
        features = []
        for img in X:
            if img.max() <= 1.0:
                img = (img * 255).astype(np.uint8)
            
            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
            fd = hog(gray, orientations=9, pixels_per_cell=(8, 8),
                    cells_per_block=(2, 2), visualize=False, channel_axis=None)
            features.append(fd)
        
        X_features = np.array(features)
        X_scaled = self.scaler.transform(X_features)
        return self.model.predict_proba(X_scaled)

class HaarCascade_RF_Model:
    def __init__(self):
        self.face_cascade = None
        self.model = None
        self.name = "Haar Cascade + RF"

    def _patch_missing_tree_attrs(self):
        try:
            estimators = getattr(self.model, "estimators_", None)
            if estimators is None:
                return
            for est in estimators:
                if not hasattr(est, "monotonic_cst"):
                    setattr(est, "monotonic_cst", None)
                tree_obj = getattr(est, "tree_", None)
                if tree_obj is not None and not hasattr(tree_obj, "monotonic_cst"):
                    setattr(tree_obj, "monotonic_cst", None)
        except Exception:
            pass

    def predict_proba(self, X):
        if self.face_cascade is None:
            try:
                self.face_cascade = cv2.CascadeClassifier(
                    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
                )
            except:
                pass

        features = []
        for img in X:
            if img.max() <= 1.0:
                img = (img * 255).astype(np.uint8)

            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
            feat = []
            
            feat.extend([gray.mean(), gray.std(), gray.min(), gray.max()])
            hist = cv2.calcHist([gray], [0], None, [32], [0, 256])
            feat.extend(hist.flatten())
            
            if self.face_cascade is not None:
                try:
                    faces = self.face_cascade.detectMultiScale(gray, 1.1, 4, minSize=(20, 20))
                    feat.append(len(faces))
                except:
                    feat.append(0)
            else:
                feat.append(0)
            
            for channel in range(3):
                feat.extend([img[:, :, channel].mean(), img[:, :, channel].std()])
            
            edges = cv2.Canny(gray, 100, 200)
            feat.extend([edges.mean(), edges.std()])
            features.append(feat)

        X_features = np.array(features)
        
        try:
            proba = self.model.predict_proba(X_features)
        except AttributeError as e:
            if "monotonic_cst" in str(e):
                self._patch_missing_tree_attrs()
                proba = self.model.predict_proba(X_features)
            else:
                raise e

        proba = np.array(proba, dtype=float)
        proba = np.clip(proba, 0, None)
        sums = proba.sum(axis=1, keepdims=True)
        sums[sums == 0] = 1
        proba = proba / sums
        
        if not np.all(np.isfinite(proba)):
            expv = np.exp(proba - np.max(proba, axis=1, keepdims=True))
            proba = expv / expv.sum(axis=1, keepdims=True)
        
        return proba

sys.modules['src.models'].HOG_SVM_Model = HOG_SVM_Model
sys.modules['src.models'].HaarCascade_RF_Model = HaarCascade_RF_Model

# ===== –ü–£–¢–ò –ö –ú–û–î–ï–õ–Ø–ú =====
BASE_DIR = os.getcwd()
TRAINED_MODELS_DIR = os.path.join(BASE_DIR, 'trained_models')
MODEL1_PATH = os.path.join(TRAINED_MODELS_DIR, 'model1_hog_svm.pkl')
MODEL2_PATH = os.path.join(TRAINED_MODELS_DIR, 'model2_haar_rf.pkl')
MODEL3_PATH = os.path.join(TRAINED_MODELS_DIR, 'model3_cnn.h5')
LABELS_MAP_PATH = os.path.join(TRAINED_MODELS_DIR, 'labels_map.json')

# ===== –ù–ê–°–¢–†–û–ô–ö–ê –°–¢–†–ê–ù–ò–¶–´ =====
st.set_page_config(
    page_title="Mask Detection System",
    page_icon="üò∑",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===== –ö–ê–°–¢–û–ú–ù–´–ï –°–¢–ò–õ–ò =====
st.markdown("""
    <style>
    .main-header {
        font-size: 3.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
        animation: fadeIn 1s;
    }
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(-20px); }
        to { opacity: 1; transform: translateY(0); }
    }
    .stProgress > div > div > div > div {
        background: linear-gradient(90deg, #1f77b4, #2ca02c);
    }
    div[data-testid="stMetricValue"] {
        font-size: 1.8rem;
        font-weight: bold;
    }
    </style>
""", unsafe_allow_html=True)

# ===== –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø) =====
@st.cache_resource(show_spinner=False)
def load_models_from_trained_models():
    """–¢–∏—Ö–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
    if not os.path.exists(TRAINED_MODELS_DIR):
        return None, None, None, {}, False, "–ü–∞–ø–∫–∞ trained_models/ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
    
    try:
        labels_map = {0: '–ë–µ–∑ –º–∞—Å–∫–∏', 1: '–° –º–∞—Å–∫–æ–π'}
        if os.path.exists(LABELS_MAP_PATH):
            try:
                with open(LABELS_MAP_PATH, 'r') as f:
                    labels_dict = json.load(f)
                    labels_map = {int(k): v for k, v in labels_dict.items()}
            except:
                pass
        
        model1, model2, model3 = None, None, None
        
        # –ú–æ–¥–µ–ª—å 1
        if os.path.exists(MODEL1_PATH):
            try:
                with open(MODEL1_PATH, 'rb') as f:
                    model1 = pickle.load(f)
            except:
                pass
        
        # –ú–æ–¥–µ–ª—å 2
        if os.path.exists(MODEL2_PATH):
            try:
                with open(MODEL2_PATH, 'rb') as f:
                    model2 = pickle.load(f)
            except:
                pass
        
        # –ú–æ–¥–µ–ª—å 3 - –ü–†–ê–í–ò–õ–¨–ù–ê–Ø –ó–ê–ì–†–£–ó–ö–ê
        if os.path.exists(MODEL3_PATH) and TF_AVAILABLE:
            try:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ë–ï–ó –∫–æ–º–ø–∏–ª—è—Ü–∏–∏
                model3_keras = tf.keras.models.load_model(MODEL3_PATH, compile=False)
                
                # –û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
                class CNNWrapper:
                    def __init__(self, model):
                        self.model = model
                    
                    def predict_proba(self, X):
                        # CNN –æ–∂–∏–¥–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –≤—Ö–æ–¥ [0, 1]
                        if X.max() > 1.0:
                            X = X / 255.0
                        
                        predictions = self.model.predict(X, verbose=0)
                        
                        # –ï—Å–ª–∏ –±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (1 –≤—ã—Ö–æ–¥)
                        if predictions.shape[-1] == 1:
                            prob_positive = predictions.flatten()
                            return np.column_stack([1 - prob_positive, prob_positive])
                        
                        # –ï—Å–ª–∏ –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è (softmax –Ω–∞ –≤—ã—Ö–æ–¥–µ)
                        return predictions
                
                model3 = CNNWrapper(model3_keras)
                
            except Exception as e:
                # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å - –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                model3 = None
        
        any_loaded = model1 is not None or model2 is not None or model3 is not None
        error_msg = "" if any_loaded else "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏"
        
        return model1, model2, model3, labels_map, any_loaded, error_msg
    
    except Exception as e:
        return None, None, None, {}, False, str(e)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ –ë–ï–ó –≤—ã–≤–æ–¥–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
model1, model2, model3, labels_map, models_loaded, error_msg = load_models_from_trained_models()

# ===== –ó–ê–ì–û–õ–û–í–û–ö =====
st.markdown('<h1 class="main-header">üò∑ –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫ –Ω–∞ –ª–∏—Ü–µ</h1>', 
           unsafe_allow_html=True)
st.markdown("---")

# ===== SIDEBAR (–£–ü–†–û–©–ï–ù–ù–´–ô) =====
with st.sidebar:
    st.header("‚öôÔ∏è –ü–∞–Ω–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è")
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    available_models = []
    if model1:
        available_models.append("HOG + SVM")
    if model2:
        available_models.append("Haar Cascade + RF")
    if model3:
        available_models.append("CNN (Deep Learning)")
    
    if available_models:
        model_choice = st.selectbox(
            "üéØ –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
            ["–í—Å–µ –º–æ–¥–µ–ª–∏"] + available_models,
            help="–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"
        )
    else:
        st.error("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
        st.stop()
    
    # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    confidence_threshold = st.slider(
        "üéöÔ∏è –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:", 
        min_value=0.0, 
        max_value=1.0, 
        value=0.5, 
        step=0.05,
        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"
    )
    
    st.markdown("---")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª—è—Ö (–ö–†–ê–¢–ö–ê–Ø)
    with st.expander("üìñ –û –º–æ–¥–µ–ª—è—Ö"):
        st.markdown("""
        **üîµ HOG + SVM**  
        –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –º–µ—Ç–æ–¥ —Å –±—ã—Å—Ç—Ä–æ–π —Ä–∞–±–æ—Ç–æ–π
        
        **üü¢ Haar Cascade + RF**  
        –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥ —Å –±–∞–ª–∞–Ω—Å–æ–º —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏
        
        **üî¥ CNN (Deep Learning)**  
        –°–≤–µ—Ä—Ç–æ—á–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å —Å –Ω–∞–∏–≤—ã—Å—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é
        """)

# ===== –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° =====
col1, col2 = st.columns([1, 1], gap="large")

# ===== –õ–ï–í–ê–Ø –ö–û–õ–û–ù–ö–ê =====
with col1:
    st.header("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    
    upload_option = st.radio(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–±:",
        ["–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–º–µ—Ä—É"],
        horizontal=True
    )
    
    uploaded_file = None
    
    if upload_option == "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª":
        uploaded_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...", 
            type=['jpg', 'jpeg', 'png', 'bmp']
        )
    else:
        camera_image = st.camera_input("üì∏ –°–¥–µ–ª–∞–π—Ç–µ —Ñ–æ—Ç–æ")
        if camera_image is not None:
            uploaded_file = camera_image
    
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_column_width=True)
        
        img_array = np.array(image)
        st.caption(f"–†–∞–∑–º–µ—Ä: {img_array.shape[1]}√ó{img_array.shape[0]} –ø–∏–∫—Å–µ–ª–µ–π")

# ===== –ü–†–ê–í–ê–Ø –ö–û–õ–û–ù–ö–ê =====
with col2:
    st.header("üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏")
    
    if uploaded_file is not None:
        try:
            img_array = np.array(image)
            
            if len(img_array.shape) == 2:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)
            elif img_array.shape[2] == 4:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2RGB)
            
            img_resized = cv2.resize(img_array, (128, 128))
            img_input = np.expand_dims(img_resized, axis=0) / 255.0
            
            # ===== –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø =====
            if model_choice == "–í—Å–µ –º–æ–¥–µ–ª–∏":
                st.subheader("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
                
                models = []
                if model1:
                    models.append((model1, "HOG + SVM", "#1f77b4"))
                if model2:
                    models.append((model2, "Haar Cascade + RF", "#2ca02c"))
                if model3:
                    models.append((model3, "CNN", "#d62728"))
                
                for model, name, color in models:
                    with st.container():
                        st.markdown(f"### {name}")
                        
                        try:
                            pred_proba = model.predict_proba(img_input)[0]
                            
                            if len(pred_proba) > 2:
                                pred_class = np.argmax(pred_proba)
                            else:
                                pred_class = 1 if pred_proba[1] > 0.5 else 0
                            
                            confidence = pred_proba[pred_class] if len(pred_proba) > pred_class else pred_proba[1]
                            prediction = labels_map.get(pred_class, "–° –º–∞—Å–∫–æ–π" if pred_class == 1 else "–ë–µ–∑ –º–∞—Å–∫–∏")
                            
                            col_a, col_b = st.columns([2, 1])
                            
                            with col_a:
                                # –ë–ï–ó –≠–ú–û–î–ó–ò –ò –í–û–°–ö–õ–ò–¶–ê–¢–ï–õ–¨–ù–´–• –ó–ù–ê–ö–û–í
                                if confidence >= confidence_threshold:
                                    if prediction in ["WithMask", "–° –º–∞—Å–∫–æ–π"]:
                                        st.markdown(f"**{prediction}**")
                                    else:
                                        st.markdown(f"**{prediction}**")
                                else:
                                    st.markdown(f"**{prediction}** (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)")
                            
                            with col_b:
                                st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}")
                            
                            st.progress(float(confidence))
                            
                            with st.expander("–î–µ—Ç–∞–ª–∏"):
                                for i, label in labels_map.items():
                                    prob = pred_proba[i] if i < len(pred_proba) else 0
                                    st.write(f"{label}: {prob:.2%}")
                        
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞: {str(e)[:100]}")
                        
                        st.markdown("---")
            
            else:
                st.subheader(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {model_choice}")
                
                model_map = {
                    "HOG + SVM": model1,
                    "Haar Cascade + RF": model2,
                    "CNN (Deep Learning)": model3
                }
                
                model = model_map.get(model_choice)
                
                if model:
                    with st.spinner('–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...'):
                        try:
                            pred_proba = model.predict_proba(img_input)[0]
                            
                            if len(pred_proba) > 2:
                                pred_class = np.argmax(pred_proba)
                            else:
                                pred_class = 1 if pred_proba[1] > 0.5 else 0
                            
                            confidence = pred_proba[pred_class] if len(pred_proba) > pred_class else pred_proba[1]
                            prediction = labels_map.get(pred_class, "–° –º–∞—Å–∫–æ–π" if pred_class == 1 else "–ë–µ–∑ –º–∞—Å–∫–∏")
                            
                            # –ë–ï–ó –≠–ú–û–î–ó–ò
                            st.markdown(f"## {prediction}")
                            
                            col_a, col_b, col_c = st.columns(3)
                            
                            with col_a:
                                st.metric("–ö–ª–∞—Å—Å", prediction)
                            
                            with col_b:
                                delta = f"{(confidence-0.5)*100:+.1f}%" if confidence > 0.5 else None
                                st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}", delta=delta)
                            
                            with col_c:
                                status = "–í—ã—Å–æ–∫–∞—è" if confidence >= confidence_threshold else "–ù–∏–∑–∫–∞—è"
                                st.metric("–¢–æ—á–Ω–æ—Å—Ç—å", status)
                            
                            st.progress(float(confidence))
                            
                            st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π")
                            
                            prob_df = pd.DataFrame({
                                '–ö–ª–∞—Å—Å': [labels_map.get(i, f"–ö–ª–∞—Å—Å {i}") for i in sorted(labels_map.keys())],
                                '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å': [pred_proba[i] if i < len(pred_proba) else 0 for i in sorted(labels_map.keys())]
                            })
                            
                            st.bar_chart(prob_df.set_index('–ö–ª–∞—Å—Å'))
                            
                            with st.expander("–î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"):
                                st.write("**–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞:**")
                                for i, label in labels_map.items():
                                    prob = pred_proba[i] if i < len(pred_proba) else 0
                                    st.write(f"- {label}: {prob:.4f} ({prob*100:.2f}%)")
                                
                                st.write(f"\n**–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:** {confidence_threshold}")
                        
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {str(e)}")
                else:
                    st.error(f"–ú–æ–¥–µ–ª—å {model_choice} –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}")
    
    else:
        st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –Ω–∞—á–∞–ª–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏")
        
        st.markdown("""
        ### –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
        
        1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ —á–µ–ª–æ–≤–µ–∫–∞ —Å –ª–∏—Ü–æ–º
        2. –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        3. –ü–æ–ª—É—á–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–∫–∏
        
        ### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
        
        - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —á–µ—Ç–∫–∏–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
        - –õ–∏—Ü–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ö–æ—Ä–æ—à–æ –≤–∏–¥–Ω–æ
        - –ò–∑–±–µ–≥–∞–π—Ç–µ —Å–∏–ª—å–Ω—ã—Ö —Ç–µ–Ω–µ–π
        - –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: –ø–æ—Ä—Ç—Ä–µ—Ç–Ω–∞—è —Å—ä–µ–º–∫–∞
        """)

# ===== FOOTER =====
st.markdown("---")

with st.expander("–û —Å–∏—Å—Ç–µ–º–µ"):
    st.markdown("""
    ### –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—Ä–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–∞ –∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:
    
    1. **–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã** - HOG + SVM, Haar + RF
    2. **–ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ** - CNN —Å Transfer Learning
    
    **–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:** Python, OpenCV, scikit-learn, TensorFlow, Streamlit
    
    ---
    –†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–æ –≤ —Ä–∞–º–∫–∞—Ö –∫—É—Ä—Å–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞ | 2024
    """)

st.markdown("""
    <div style='text-align: center; color: gray; padding: 20px;'>
        <p>¬© 2024 Mask Detection System</p>
    </div>
""", unsafe_allow_html=True)
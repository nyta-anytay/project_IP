"""
Streamlit –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫
"""
import streamlit as st
import cv2
import numpy as np
from PIL import Image
import pickle
import tensorflow as tf
import json
import sys
import os
import warnings
warnings.filterwarnings('ignore')
import sys
sys.path.append('src') 




# ===== –í–ê–ñ–ù–û: –î–õ–Ø STREAMLIT CLOUD –£–ë–ò–†–ê–ï–ú –ü–£–¢–ò –ò–ó –ö–û–ù–§–ò–ì–ê =====
# –í–º–µ—Å—Ç–æ –∏–º–ø–æ—Ä—Ç–∞ –∏–∑ config, –∑–∞–¥–∞–µ–º –ø—É—Ç–∏ –Ω–∞–ø—Ä—è–º—É—é
MODEL1_PATH = 'web_app/model1_hog_svm.pkl'  # –∏–ª–∏ –¥—Ä—É–≥–æ–µ –∏–º—è –≤–∞—à–µ–≥–æ –ø–µ—Ä–≤–æ–≥–æ .pkl —Ñ–∞–π–ª–∞
MODEL2_PATH = 'web_app/model2_haar_rf.pkl'  # –∏–ª–∏ –¥—Ä—É–≥–æ–µ –∏–º—è –≤–∞—à–µ–≥–æ –≤—Ç–æ—Ä–æ–≥–æ .pkl —Ñ–∞–π–ª–∞
MODEL3_PATH = 'web_app/model3_cnn.h5'   # –∏–º—è –≤–∞—à–µ–≥–æ .h5 —Ñ–∞–π–ª–∞
LABELS_MAP_PATH = 'web_app/labels_map.json'  # –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–ª–∏ –∑–∞–¥–∞–µ–º –≤—Ä—É—á–Ω—É—é

# ===== –ù–ê–°–¢–†–û–ô–ö–ê –°–¢–†–ê–ù–ò–¶–´ =====
st.set_page_config(
    page_title="Mask Detection System",
    page_icon="üò∑",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===== –ö–ê–°–¢–û–ú–ù–´–ï –°–¢–ò–õ–ò =====
st.markdown("""
    <style>
    .main-header {
        font-size: 3.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .stProgress > div > div > div > div {
        background-color: #1f77b4;
    }
    div[data-testid="stMetricValue"] {
        font-size: 1.5rem;
    }
    </style>
""", unsafe_allow_html=True)

# ===== –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –§–ê–ô–õ–û–í =====
def check_files_exist():
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–µ–π –∏ labels_map"""
    files_needed = [MODEL1_PATH, MODEL2_PATH, MODEL3_PATH, LABELS_MAP_PATH]
    existing_files = []
    missing_files = []
    
    for file in files_needed:
        if os.path.exists(file):
            existing_files.append(file)
        else:
            missing_files.append(file)
    
    return existing_files, missing_files

# ===== –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô –° –û–ë–†–ê–ë–û–¢–ö–û–ô –û–®–ò–ë–û–ö =====
@st.cache_resource
def load_all_models():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∏ labels_map"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã
    existing_files, missing_files = check_files_exist()
    
    if missing_files:
        return None, None, None, None, False, f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∞–π–ª—ã: {', '.join(missing_files)}"

    try:
        # ===== labels_map =====
        if os.path.exists(LABELS_MAP_PATH):
            with open(LABELS_MAP_PATH, 'r') as f:
                labels_dict = json.load(f)
                labels_map = {int(k): v for k, v in labels_dict.items()}
        else:
            labels_map = {0: "–ë–µ–∑ –º–∞—Å–∫–∏", 1: "–° –º–∞—Å–∫–æ–π"}
            os.makedirs(os.path.dirname(LABELS_MAP_PATH), exist_ok=True)
            with open(LABELS_MAP_PATH, 'w') as f:
                json.dump(labels_map, f)

        models_loaded = []

        # ===== –ú–æ–¥–µ–ª—å 1: HOG + SVM =====
        try:
            with open(MODEL1_PATH, 'rb') as f:
                model1 = pickle.load(f)
            models_loaded.append(("model1_hog_svm", True, ""))
        except Exception as e:
            model1 = None
            models_loaded.append(("model1_hog_svm", False, str(e)))

        # ===== –ú–æ–¥–µ–ª—å 2: Haar + RF =====
        try:
            with open(MODEL2_PATH, 'rb') as f:
                model2 = pickle.load(f)
            models_loaded.append(("model2_haar_rf", True, ""))
        except Exception as e:
            model2 = None
            models_loaded.append(("model2_haar_rf", False, str(e)))

        # ===== –ú–æ–¥–µ–ª—å 3: CNN =====
        try:
            model3_keras = load_model(
                MODEL3_PATH,
                compile=False,
                custom_objects={'BatchNormalization': BatchNormalization}
            )

            class CNNWrapper:
                def __init__(self, model):
                    self.model = model
                def predict_proba(self, X):
                    return self.model.predict(X, verbose=0)

            model3 = CNNWrapper(model3_keras)
            models_loaded.append(("model3_cnn", True, ""))
        except Exception as e:
            model3 = None
            models_loaded.append(("model3_cnn", False, str(e)))

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—Å–µ –ª–∏ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
        all_loaded = all(status for _, status, _ in models_loaded)

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–∞—Ö
        error_msg = ""
        if not all_loaded:
            error_details = [f"{name}: {msg}" for name, status, msg in models_loaded if not status and msg]
            error_msg = f"–û—à–∏–±–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏: {'; '.join(error_details)}"

        return model1, model2, model3, labels_map, all_loaded, error_msg

    except Exception as e:
        return None, None, None, None, False, f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}"

# ===== –û–¢–õ–ê–î–û–ß–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –í SIDEBAR =====
with st.sidebar:
    st.header("üîç –û—Ç–ª–∞–¥–∫–∞")
    
    if st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–∞—Ö"):
        existing, missing = check_files_exist()
        st.write("**–ù–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã:**")
        for file in existing:
            st.success(f"‚úÖ {file} ({os.path.getsize(file)} –±–∞–π—Ç)")
        
        if missing:
            st.write("**–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∞–π–ª—ã:**")
            for file in missing:
                st.error(f"‚ùå {file}")
    
    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
    if st.button("üîÑ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏"):
        st.cache_resource.clear()
        st.rerun()

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
model1, model2, model3, labels_map, models_loaded, error_msg = load_all_models()

# ===== –ó–ê–ì–û–õ–û–í–û–ö =====
st.markdown('<h1 class="main-header">üò∑ –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫ –Ω–∞ –ª–∏—Ü–µ</h1>', 
           unsafe_allow_html=True)
st.markdown("---")

# ===== SIDEBAR: –û–°–ù–û–í–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò =====
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    available_models = []
    if model1:
        available_models.append("HOG + SVM")
    if model2:
        available_models.append("Haar Cascade + RF")
    if model3:
        available_models.append("CNN (Deep Learning)")
    
    if available_models:
        model_choice = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
            ["–í—Å–µ –º–æ–¥–µ–ª–∏"] + available_models,
            help="–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"
        )
    else:
        model_choice = "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"
        st.error("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—ã–±–æ—Ä–∞")
    
    # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    confidence_threshold = st.slider(
        "–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:", 
        min_value=0.0, 
        max_value=1.0, 
        value=0.5, 
        step=0.05,
        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"
    )
    
    st.markdown("---")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö
    st.markdown("### üìä –°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–µ–π")
    
    model_status = [
        ("model_hog_svm.pkl", model1, "üîµ HOG + SVM"),
        ("model2_haar_rf.pkl", model2, "üü¢ Haar Cascade + RF"),
        ("model3_cnn.h5", model3, "üî¥ CNN (Deep Learning)")
    ]
    
    for file_name, model, display_name in model_status:
        if model is not None:
            st.success(f"‚úÖ {display_name}")
        else:
            st.error(f"‚ùå {display_name}")

# ===== –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° =====

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π
if not models_loaded or (model1 is None and model2 is None and model3 is None):
    st.error(f"‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º–∞ —Å –∑–∞–≥—Ä—É–∑–∫–æ–π –º–æ–¥–µ–ª–µ–π")
    st.warning(error_msg)
    
    st.info("""
    **–†–µ—à–µ–Ω–∏–µ –¥–ª—è Streamlit Cloud:**
    
    1. **–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π:**
       - `model_hog_svm.pkl` (–≤–∞—à –ø–µ—Ä–≤—ã–π .pkl —Ñ–∞–π–ª)
       - `model2_haar_rf.pkl` (–≤–∞—à –≤—Ç–æ—Ä–æ–π .pkl —Ñ–∞–π–ª)
       - `model3_cnn.h5` (–≤–∞—à .h5 —Ñ–∞–π–ª)
       - `labels_map.json` (–µ—Å–ª–∏ –µ—Å—Ç—å, –∏–ª–∏ –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
    
    2. **–ü—Ä–æ–≤–µ—Ä—å—Ç–µ requirements.txt:**
       ```txt
       streamlit
       tensorflow
       opencv-python
       numpy
       Pillow
       scikit-learn
       pandas
       ```
    
    3. **–ü–µ—Ä–µ–∏–º–µ–Ω—É–π—Ç–µ –≤–∞—à–∏ —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π** –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –∏–º–µ–Ω–∞–º–∏ –≤ –∫–æ–¥–µ:
       - –ü–µ—Ä–≤—ã–π .pkl —Ñ–∞–π–ª ‚Üí `model_hog_svm.pkl`
       - –í—Ç–æ—Ä–æ–π .pkl —Ñ–∞–π–ª ‚Üí `model2_haar_rf.pkl`
       - .h5 —Ñ–∞–π–ª ‚Üí `model3_cnn.h5`
    """)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    if st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"):
        st.write("–§–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:", os.listdir('.'))
    
    st.stop()

# –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
col1, col2 = st.columns([1, 1], gap="large")

# ===== –õ–ï–í–ê–Ø –ö–û–õ–û–ù–ö–ê: –ó–ê–ì–†–£–ó–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø =====
with col1:
    st.header("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    
    # –í—ã–±–æ—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    upload_option = st.radio(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–±:",
        ["–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–º–µ—Ä—É"],
        horizontal=True
    )
    
    uploaded_file = None
    
    if upload_option == "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª":
        uploaded_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...", 
            type=['jpg', 'jpeg', 'png', 'bmp'],
            help="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: JPG, JPEG, PNG, BMP"
        )
    else:
        camera_image = st.camera_input("–°–¥–µ–ª–∞–π—Ç–µ —Ñ–æ—Ç–æ")
        if camera_image is not None:
            uploaded_file = camera_image

# ===== –ü–†–ê–í–ê–Ø –ö–û–õ–û–ù–ö–ê: –†–ï–ó–£–õ–¨–¢–ê–¢–´ =====
with col2:
    st.header("üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏")
    
    if uploaded_file is not None:
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = Image.open(uploaded_file)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –ª–µ–≤–æ–π –∫–æ–ª–æ–Ω–∫–µ
            with col1:
                st.image(image, caption='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_column_width=True)
                img_array = np.array(image)
                st.caption(f"–†–∞–∑–º–µ—Ä: {img_array.shape[1]}x{img_array.shape[0]} –ø–∏–∫—Å–µ–ª–µ–π")
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–µ–π
            if len(img_array.shape) == 2:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)
            elif img_array.shape[2] == 4:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2RGB)
            
            # –†–µ—Å–∞–π–∑ –¥–ª—è –º–æ–¥–µ–ª–∏
            img_resized = cv2.resize(img_array, (128, 128))
            img_input = np.expand_dims(img_resized, axis=0) / 255.0  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            
            # ===== –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø =====
            if model_choice == "–í—Å–µ –º–æ–¥–µ–ª–∏":
                st.subheader("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π")
                
                models = []
                if model1:
                    models.append((model1, "HOG + SVM", "üîµ"))
                if model2:
                    models.append((model2, "Haar Cascade + RF", "üü¢"))
                if model3:
                    models.append((model3, "CNN (Deep Learning)", "üî¥"))
                
                # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                for model, name, icon in models:
                    with st.container():
                        st.markdown(f"### {icon} {name}")
                        
                        with st.spinner(f'–û–±—Ä–∞–±–æ—Ç–∫–∞ {name}...'):
                            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                            try:
                                pred_proba = model.predict_proba(img_input)[0]
                                if len(pred_proba) > 2:  # –ï—Å–ª–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–ª–∞—Å—Å–æ–≤
                                    pred_class = np.argmax(pred_proba)
                                else:
                                    pred_class = 1 if pred_proba[1] > 0.5 else 0
                                
                                confidence = pred_proba[pred_class] if len(pred_proba) > pred_class else pred_proba[1]
                                
                                # –ò—Å–ø–æ–ª—å–∑—É–µ–º labels_map –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–∞
                                if pred_class in labels_map:
                                    prediction = labels_map[pred_class]
                                else:
                                    prediction = "–° –º–∞—Å–∫–æ–π" if pred_class == 1 else "–ë–µ–∑ –º–∞—Å–∫–∏"
                                
                                # –†–µ–∑—É–ª—å—Ç–∞—Ç
                                if confidence >= confidence_threshold:
                                    if prediction == "–° –º–∞—Å–∫–∏" or pred_class == 1:
                                        st.success(f"‚úÖ **{prediction}**")
                                    else:
                                        st.error(f"‚ùå **{prediction}**")
                                else:
                                    st.warning("‚ö†Ô∏è –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å")
                                
                                # –ú–µ—Ç—Ä–∏–∫–∏
                                col_a, col_b = st.columns(2)
                                with col_a:
                                    st.metric("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ", prediction)
                                with col_b:
                                    st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}")
                                
                                # –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä
                                st.progress(float(confidence))
                                
                            except Exception as e:
                                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {str(e)}")
                        
                        st.markdown("---")
            
            elif model_choice in ["HOG + SVM", "Haar Cascade + RF", "CNN (Deep Learning)"]:
                # –û–¥–Ω–∞ –º–æ–¥–µ–ª—å
                st.subheader(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {model_choice}")
                
                model_map = {
                    "HOG + SVM": (model1, "üîµ"),
                    "Haar Cascade + RF": (model2, "üü¢"),
                    "CNN (Deep Learning)": (model3, "üî¥")
                }
                
                model, icon = model_map[model_choice]
                
                if model is None:
                    st.error(f"–ú–æ–¥–µ–ª—å {model_choice} –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                else:
                    with st.spinner('–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...'):
                        try:
                            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                            pred_proba = model.predict_proba(img_input)[0]
                            
                            if len(pred_proba) > 2:
                                pred_class = np.argmax(pred_proba)
                            else:
                                pred_class = 1 if pred_proba[1] > 0.5 else 0
                            
                            confidence = pred_proba[pred_class] if len(pred_proba) > pred_class else pred_proba[1]
                            
                            if pred_class in labels_map:
                                prediction = labels_map[pred_class]
                            else:
                                prediction = "–° –º–∞—Å–∫–æ–π" if pred_class == 1 else "–ë–µ–∑ –º–∞—Å–∫–∏"
                            
                            # –ë–æ–ª—å—à–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                            st.markdown(f"## {icon} {prediction}")
                            
                            if confidence >= confidence_threshold:
                                if prediction == "–° –º–∞—Å–∫–∏" or pred_class == 1:
                                    st.success("‚úÖ –ú–∞—Å–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞!")
                                else:
                                    st.error("‚ùå –ú–∞—Å–∫–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞!")
                            else:
                                st.warning("‚ö†Ô∏è –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏")
                            
                            # –ú–µ—Ç—Ä–∏–∫–∏
                            col_a, col_b, col_c = st.columns(3)
                            
                            with col_a:
                                st.metric("–ö–ª–∞—Å—Å", prediction)
                            
                            with col_b:
                                st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}")
                            
                            with col_c:
                                status = "‚úÖ" if confidence >= confidence_threshold else "‚ö†Ô∏è"
                                st.metric("–°—Ç–∞—Ç—É—Å", status)
                            
                            # –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä
                            st.progress(float(confidence))
                            
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {str(e)}")
        
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
    
    else:
        # Placeholder –∫–æ–≥–¥–∞ –Ω–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –Ω–∞—á–∞–ª–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏")
        
        st.markdown("""
        ### üí° –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
        
        1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ —á–µ–ª–æ–≤–µ–∫–∞ (—Å –ª–∏—Ü–æ–º)
        2. –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        3. –ü–æ–ª—É—á–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–∫–∏
        """)

# ===== FOOTER =====
st.markdown("---")

with st.expander("‚ÑπÔ∏è –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –¥–µ–ø–ª–æ—é –Ω–∞ Streamlit Cloud"):
    st.markdown("""
    ### –ö–∞–∫ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—å —ç—Ç–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:
    
    1. **–ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π:**
       - –ü–µ—Ä–µ–∏–º–µ–Ω—É–π—Ç–µ –≤–∞—à–∏ —Ñ–∞–π–ª—ã:
         - –ü–µ—Ä–≤—ã–π .pkl ‚Üí `model_hog_svm.pkl`
         - –í—Ç–æ—Ä–æ–π .pkl ‚Üí `model2_haar_rf.pkl`
         - .h5 —Ñ–∞–π–ª ‚Üí `model3_cnn.h5`
    
    2. **–°–æ–∑–¥–∞–π—Ç–µ requirements.txt:**
       ```txt
       streamlit==1.29.0
       tensorflow==2.15.0
       opencv-python==4.8.1
       numpy==1.24.3
       Pillow==10.1.0
       scikit-learn==1.3.2
       pandas==2.1.4
       ```
    
    3. **–ó–∞–≥—Ä—É–∑–∏—Ç–µ –Ω–∞ GitHub:**
       - `app.py` (—ç—Ç–æ—Ç —Ñ–∞–π–ª)
       - `model_hog_svm.pkl`, `model2_haar_rf.pkl`, `model3_cnn.h5`
       - `requirements.txt`
       - (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) `labels_map.json`
    
    4. **–î–µ–ø–ª–æ–π –Ω–∞ Streamlit Cloud:**
       - –ó–∞–π–¥–∏—Ç–µ –Ω–∞ [share.streamlit.io](https://share.streamlit.io)
       - –ü–æ–¥–∫–ª—é—á–∏—Ç–µ GitHub —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
       - –í—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª `app.py`
       - –ù–∞–∂–º–∏—Ç–µ Deploy
    """)

# Copyright
st.markdown("""
    <div style='text-align: center; color: gray; padding: 20px;'>
        <p>¬© 2024 Mask Detection System</p>
    </div>
""", unsafe_allow_html=True)
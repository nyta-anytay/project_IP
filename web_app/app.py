"""
Streamlit –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫
"""
import streamlit as st
import cv2
import numpy as np
from PIL import Image
import pickle
import tensorflow as tf
import json
import sys
import os
import types
import math

# ---------------------------
# –ü—É—Ç–∏ (–ø–æ–ø—Ä–æ–±—É–µ–º –≤–∑—è—Ç—å –∏–∑ src.config, –∏–Ω–∞—á–µ fallback)
# ---------------------------
# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src (–µ—Å–ª–∏ –∑–∞–ø—É—Å–∫ –∏–∑ web_app/)
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
try:
    from src.config import MODEL1_PATH, MODEL2_PATH, MODEL3_PATH, LABELS_MAP_PATH
except Exception:
    # fallback ‚Äî –æ–∂–∏–¥–∞–µ–º –ø–∞–ø–∫—É trained_models –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞
    BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    TM = os.path.join(BASE_DIR, 'trained_models')
    MODEL1_PATH = os.path.join(TM, 'model1_hog_svm.pkl')
    MODEL2_PATH = os.path.join(TM, 'model2_haar_rf.pkl')
    MODEL3_PATH = os.path.join(TM, 'model3_cnn.h5')
    LABELS_MAP_PATH = os.path.join(TM, 'labels_map.json')

# ---------------------------
# –§–ï–ô–ö–û–í–´–ï –ú–û–î–£–õ–ò –î–õ–Ø UNPICKLE (–µ—Å–ª–∏ pickle —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–∞—Å—Ç–æ–º–Ω—ã–µ –∫–ª–∞—Å—Å—ã)
# ---------------------------
if 'src' not in sys.modules:
    src_module = types.ModuleType('src')
    sys.modules['src'] = src_module

# —Å–æ–∑–¥–∞—ë–º src.models –µ—Å–ª–∏ –Ω–µ—Ç
if 'src.models' not in sys.modules:
    models_mod = types.ModuleType('src.models')
    sys.modules['src.models'] = models_mod
    setattr(sys.modules['src'], 'models', models_mod)

# ---------------------------
# –ö–õ–ê–°–°–´, –ö–û–¢–û–†–´–ï –ú–û–ì–£–¢ –ù–£–ñ–ù–´ –î–õ–Ø UNPICKLE
# (HOG_SVM_Model –∏ HaarCascade_RF_Model)
# ---------------------------

# HOG + SVM (—Ñ–µ–π–∫–æ–≤—ã–π –∫–ª–∞—Å—Å ‚Äî –Ω—É–∂–µ–Ω –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ unpickle, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –±—ã–ª–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ —Å —ç—Ç–∏–º –∫–ª–∞—Å—Å–æ–º)
class HOG_SVM_Model:
    """–§–µ–π–∫–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è unpickle ‚Äî –æ–∂–∏–¥–∞–µ—Ç, —á—Ç–æ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –∞—Ç—Ä–∏–±—É—Ç—ã scaler –∏ model."""
    def __init__(self):
        self.scaler = None
        self.model = None
        self.name = "HOG + SVM"

    def _extract_hog_features(self, imgs):
        # lazy import (skimage –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å)
        try:
            from skimage.feature import hog
        except Exception:
            raise ImportError("skimage is required for HOG feature extraction (skimage.feature.hog)")

        feats = []
        for img in imgs:
            if img.max() <= 1.0:
                img = (img * 255).astype(np.uint8)
            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
            fd = hog(
                gray,
                orientations=9,
                pixels_per_cell=(8, 8),
                cells_per_block=(2, 2),
                visualize=False,
                channel_axis=None
            )
            feats.append(fd)
        return np.array(feats)

    def predict_proba(self, X):
        if self.model is None:
            raise RuntimeError("HOG_SVM_Model: internal model is None")
        Xf = self._extract_hog_features(X)
        if self.scaler is not None:
            Xf = self.scaler.transform(Xf)
        return self.model.predict_proba(Xf)

# HaarCascade + RF (—É—Å—Ç–æ–π—á–∏–≤—ã–π –∫–ª–∞—Å—Å ‚Äî —Å –ø–∞—Ç—á–µ–º monotonic_cst –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π)
class HaarCascade_RF_Model:
    """–§–µ–π–∫–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è unpickle ‚Äî —Å–æ–¥–µ—Ä–∂–∏—Ç —É—Å—Ç–æ–π—á–∏–≤—ã–π predict_proba."""
    def __init__(self):
        self.face_cascade = None
        self.model = None
        self.name = "Haar Cascade + RF"
        self.cascade_path = None

    def _patch_missing_tree_attrs(self):
        try:
            estimators = getattr(self.model, "estimators_", None)
            if estimators is None:
                return
            for est in estimators:
                if not hasattr(est, "monotonic_cst"):
                    try:
                        setattr(est, "monotonic_cst", None)
                    except Exception:
                        pass
                tree_obj = getattr(est, "tree_", None)
                if tree_obj is not None and not hasattr(tree_obj, "monotonic_cst"):
                    try:
                        setattr(tree_obj, "monotonic_cst", None)
                    except Exception:
                        pass
        except Exception:
            pass

    def _extract_features_for_img(self, img):
        # –æ–∂–∏–¥–∞–µ—Ç—Å—è RGB uint8
        if img.max() <= 1.0:
            img = (img * 255).astype(np.uint8)
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        feat = []
        feat.extend([gray.mean(), gray.std(), gray.min(), gray.max()])
        hist = cv2.calcHist([gray], [0], None, [32], [0, 256])
        feat.extend(hist.flatten())

        # –ª–∏—Ü–∞
        if self.face_cascade is None:
            try:
                self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            except Exception:
                self.face_cascade = None

        if self.face_cascade is not None:
            try:
                faces = self.face_cascade.detectMultiScale(gray, 1.1, 4, minSize=(20, 20))
                feat.append(len(faces))
            except Exception:
                feat.append(0)
        else:
            feat.append(0)

        for channel in range(3):
            feat.extend([img[:, :, channel].mean(), img[:, :, channel].std()])

        edges = cv2.Canny(gray, 100, 200)
        feat.extend([edges.mean(), edges.std()])

        return feat

    def predict_proba(self, X):
        if self.model is None:
            raise RuntimeError("HaarCascade_RF_Model: internal model is None")

        features = []
        for img in X:
            features.append(self._extract_features_for_img(img))

        X_features = np.array(features)

        # try predict_proba, patch if necessary
        try:
            proba = self.model.predict_proba(X_features)
        except AttributeError as e:
            if "monotonic_cst" in str(e) or "monotonic" in str(e):
                self._patch_missing_tree_attrs()
                proba = self.model.predict_proba(X_features)
            else:
                raise
        except Exception:
            # –ø—Ä–æ–±—É–µ–º –ø–∞—Ç—á –∏ –ø–æ–≤—Ç–æ—Ä
            try:
                self._patch_missing_tree_attrs()
                proba = self.model.predict_proba(X_features)
            except Exception as e2:
                raise RuntimeError(f"HaarCascade_RF_Model: predict_proba failed: {e2}") from e2

        return np.array(proba, dtype=float)


# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –∫–ª–∞—Å—Å—ã –≤ fake –º–æ–¥—É–ª–µ –¥–ª—è unpickle
sys.modules['src.models'].HOG_SVM_Model = HOG_SVM_Model
sys.modules['src.models'].HaarCascade_RF_Model = HaarCascade_RF_Model

# ---------------------------
# Helper: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –≤—ã–∑–æ–≤ predict_proba
# ---------------------------
def normalize_proba(proba):
    """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ proba ‚Äî np.array shape (N, C), –∑–Ω–∞—á–µ–Ω–∏—è –≤ [0,1], —Å—É–º–º—ã –ø–æ —Å—Ç—Ä–æ–∫–∞–º == 1."""
    proba = np.array(proba, dtype=float)

    # –µ—Å–ª–∏ –æ–¥–Ω–æ–º–µ—Ä ‚Äî –ø—Ä–µ–≤—Ä–∞—Ç–∏–º –≤ 2D
    if proba.ndim == 1:
        proba = np.column_stack([1 - proba, proba])

    # –ó–∞–º–µ–Ω–∏–º NaN/inf
    proba[~np.isfinite(proba)] = 0.0

    # –£–±–∏—Ä–∞–µ–º –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ
    proba = np.clip(proba, 0.0, None)

    sums = proba.sum(axis=1, keepdims=True)
    # –∑–∞—â–∏—Ç–∏–º—Å—è –æ—Ç –Ω—É–ª–µ–≤—ã—Ö —Å—É–º–º
    zero_mask = (sums == 0).flatten()
    if np.any(~zero_mask):
        proba[~zero_mask] = proba[~zero_mask] / sums[~zero_mask]
    if np.any(zero_mask):
        # –¥–ª—è —Å—Ç—Ä–æ–∫ —Å –Ω—É–ª–µ–≤–æ–π —Å—É–º–º–æ–π –≤—ã—Å—Ç–∞–≤–∏–º —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        C = proba.shape[1]
        proba[zero_mask, :] = 1.0 / C

    # —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –∑–∞—â–∏—Ç–∞: –µ—Å–ª–∏ –∫–∞–∫–∏–µ-—Ç–æ –∑–Ω–∞—á–µ–Ω–∏—è –∑–∞ –ø—Ä–µ–¥–µ–ª–∞–º–∏ [0,1] ‚Äî –ø—Ä–∏–º–µ–Ω–∏–º softmax –ø–æ —Å—Ç—Ä–æ–∫–∞–º
    if proba.min() < 0 or proba.max() > 1 or not np.allclose(proba.sum(axis=1), 1.0, atol=1e-6):
        ex = np.exp(proba - np.max(proba, axis=1, keepdims=True))
        proba = ex / ex.sum(axis=1, keepdims=True)

    return proba


class SafeModelWrapper:
    """
    –û–±—ë—Ä—Ç–∫–∞ –≤–æ–∫—Ä—É–≥ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä–∞—è –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π predict_proba.
    –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –ª—é–±–æ–π –æ–±—ä–µ–∫—Ç model: sklearn-like (predict_proba), keras (predict),
    –∏–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –æ–±—ä–µ–∫—Ç (—É –∫–æ—Ç–æ—Ä–æ–≥–æ –µ—Å—Ç—å –º–µ—Ç–æ–¥ predict_proba).
    """
    def __init__(self, raw_model):
        self.raw = raw_model

    def predict_proba(self, X):
        # –ü–æ–ø—Ä–æ–±—É–µ–º –≤—ã–∑–≤–∞—Ç—å predict_proba –Ω–∞–ø—Ä—è–º—É—é
        try:
            proba = self.raw.predict_proba(X)
            return normalize_proba(proba)
        except Exception:
            pass

        # –ï—Å–ª–∏ –µ—Å—Ç—å predict (Keras) ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        try:
            out = self.raw.predict(X, verbose=0)
            out = np.array(out, dtype=float)
            # –ï—Å–ª–∏ –±–∏–Ω–∞—Ä–Ω—ã–π –≤—ã—Ö–æ–¥ (N,1) –∏–ª–∏ (N,) ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ 2 –∫–æ–ª–æ–Ω–∫–∏
            if out.ndim == 2 and out.shape[1] == 1:
                out = np.column_stack([1 - out.flatten(), out.flatten()])
            elif out.ndim == 1:
                out = np.column_stack([1 - out.flatten(), out.flatten()])
            return normalize_proba(out)
        except Exception:
            pass

        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å ‚Äî –ø—Ä–æ–±—É–µ–º –≤—ã–∑–≤–∞—Ç—å raw.predict (sklearn regressors etc.)
        try:
            out = self.raw.predict(X)
            out = np.array(out, dtype=float)
            # –ø—Ä–µ–≤—Ä–∞—Ç–∏–º –≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Å softmax
            if out.ndim == 1:
                logits = np.column_stack([-out, out])
            else:
                logits = out
            return normalize_proba(logits)
        except Exception as e:
            raise RuntimeError(f"ModelWrapper: unable to obtain probabilities from model: {e}") from e

# ---------------------------
# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
# ---------------------------
@st.cache_resource
def load_all_models():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∏ labels_map –≤ –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –æ–±—ë—Ä—Ç–∫–∞—Ö"""
    try:
        model1 = None
        model2 = None
        model3 = None
        labels_map = {0: "WithoutMask", 1: "WithMask"}

        # MODEL1 (pickle)
        if os.path.exists(MODEL1_PATH):
            try:
                with open(MODEL1_PATH, 'rb') as f:
                    m1 = pickle.load(f)
                model1 = SafeModelWrapper(m1)
            except Exception as e:
                model1 = None
        else:
            model1 = None

        # MODEL2 (pickle)
        if os.path.exists(MODEL2_PATH):
            try:
                with open(MODEL2_PATH, 'rb') as f:
                    m2 = pickle.load(f)
                model2 = SafeModelWrapper(m2)
            except Exception as e:
                model2 = None
        else:
            model2 = None

        # MODEL3 (keras .h5)
        if os.path.exists(MODEL3_PATH):
            try:
                model3_keras = tf.keras.models.load_model(MODEL3_PATH, compile=False)
                # –æ–±—ë—Ä—Ç–∫–∞, –∫–æ—Ç–æ—Ä–∞—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç predict
                class CNNWrapper:
                    def __init__(self, m):
                        self.model = m
                    def predict_proba(self, X):
                        x = np.array(X, dtype=float)
                        if x.max() > 1.0:
                            x = x / 255.0
                        preds = self.model.predict(x, verbose=0)
                        preds = np.array(preds, dtype=float)
                        # –µ—Å–ª–∏ —Ñ–æ—Ä–º–∞ (N,1) -> make two cols
                        if preds.ndim == 2 and preds.shape[1] == 1:
                            preds = np.column_stack([1 - preds.flatten(), preds.flatten()])
                        return preds
                model3 = SafeModelWrapper(CNNWrapper(model3_keras))
            except Exception:
                model3 = None
        else:
            model3 = None

        # labels_map
        if os.path.exists(LABELS_MAP_PATH):
            try:
                with open(LABELS_MAP_PATH, 'r') as f:
                    d = json.load(f)
                    labels_map = {int(k): v for k, v in d.items()}
            except Exception:
                pass

        any_loaded = model1 is not None or model2 is not None or model3 is not None
        if not any_loaded:
            return None, None, None, labels_map, False, "–ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"
        return model1, model2, model3, labels_map, True, None
    except FileNotFoundError as e:
        return None, None, None, None, False, f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}"
    except Exception as e:
        return None, None, None, None, False, f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}"

# –∑–∞–≥—Ä—É–∑–∫–∞
model1, model2, model3, labels_map, models_loaded, error_msg = load_all_models()

# ---------------------------
# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ —Å—Ç–∏–ª–∏ (–∫–∞–∫ –≤ –≤–∞—à–µ–º –ø—Ä–∏–º–µ—Ä–µ)
# ---------------------------
st.set_page_config(
    page_title="Mask Detection System",
    page_icon="üò∑",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
    <style>
    .main-header {
        font-size: 3.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .stProgress > div > div > div > div {
        background-color: #1f77b4;
    }
    div[data-testid="stMetricValue"] {
        font-size: 1.5rem;
    }
    </style>
""", unsafe_allow_html=True)

# ---------------------------
# UI (–∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–µ, —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º SafeModelWrapper)
# ---------------------------

# ===== –ó–ê–ì–û–õ–û–í–û–ö =====
st.markdown('<h1 class="main-header">üò∑ –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫ –Ω–∞ –ª–∏—Ü–µ</h1>', 
           unsafe_allow_html=True)
st.markdown("---")

# ===== SIDEBAR =====
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    model_choice = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
        ["–í—Å–µ –º–æ–¥–µ–ª–∏", "HOG + SVM", "Haar Cascade + RF", "CNN (Deep Learning)"],
        help="–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏–ª–∏ –≤—Å–µ —Å—Ä–∞–∑—É"
    )
    
    # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    confidence_threshold = st.slider(
        "–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:", 
        min_value=0.0, 
        max_value=1.0, 
        value=0.5, 
        step=0.05,
        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"
    )
    
    st.markdown("---")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª—è—Ö
    st.markdown("### üìä –û –º–æ–¥–µ–ª—è—Ö")
    
    with st.expander("üîµ HOG + SVM"):
        st.markdown("""
        **–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –º–µ—Ç–æ–¥**
        - HOG (Histogram of Oriented Gradients)
        - Support Vector Machine
        - ‚ö° –ë—ã—Å—Ç—Ä–∞—è —Ä–∞–±–æ—Ç–∞
        - üíæ –ú–∞–ª—ã–π —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏
        - üéØ –•–æ—Ä–æ—à–æ –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á
        """)
    
    with st.expander("üü¢ Haar Cascade + RF"):
        st.markdown("""
        **–ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥**
        - Haar Cascade –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü
        - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        - Random Forest –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        - ‚öñÔ∏è –ë–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ —Ç–æ—á–Ω–æ—Å—Ç–∏
        """)
    
    with st.expander("üî¥ CNN (Deep Learning)"):
        st.markdown("""
        **–ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ**
        - –°–≤–µ—Ä—Ç–æ—á–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å
        - Transfer Learning (MobileNetV2)
        - –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–∞ –Ω–∞ ImageNet
        - üèÜ –ù–∞–∏–≤—ã—Å—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
        - üöÄ –¢—Ä–µ–±—É–µ—Ç GPU –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Ä–∞–±–æ—Ç—ã
        """)
    
    st.markdown("---")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    if models_loaded:
        st.markdown("### ‚úÖ –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã")
        st.success("–í—Å–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã" if (model1 and model2 and model3) else "–ù–µ–∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        st.info(f"–ö–ª–∞—Å—Å—ã: {', '.join(labels_map.values())}")
    else:
        st.error("–ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        if error_msg:
            st.write(error_msg)

# ===== –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° =====

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π
if not models_loaded:
    st.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {error_msg}")
    st.info("""
    **–ß—Ç–æ –¥–µ–ª–∞—Ç—å:**
    1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –æ–±—É—á–∏–ª–∏ –º–æ–¥–µ–ª–∏: `python scripts/02_train_models.py`
    2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ `trained_models/`
    3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ `trained_models/labels_map.json` (–∏–ª–∏ –ø—É—Ç—å –≤ src.config)
    """)
    st.stop()

# –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
col1, col2 = st.columns([1, 1], gap="large")

# ===== –õ–ï–í–ê–Ø –ö–û–õ–û–ù–ö–ê: –ó–ê–ì–†–£–ó–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø =====
with col1:
    st.header("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    
    # –í—ã–±–æ—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    upload_option = st.radio(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–±:",
        ["–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–º–µ—Ä—É"],
        horizontal=True
    )
    
    uploaded_file = None
    
    if upload_option == "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª":
        uploaded_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...", 
            type=['jpg', 'jpeg', 'png', 'bmp'],
            help="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: JPG, JPEG, PNG, BMP"
        )
    else:
        camera_image = st.camera_input("–°–¥–µ–ª–∞–π—Ç–µ —Ñ–æ—Ç–æ")
        if camera_image is not None:
            uploaded_file = camera_image
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    if uploaded_file is not None:
        try:
            image = Image.open(uploaded_file).convert("RGB")
            st.image(image, caption='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_column_width=True)
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
            img_array = np.array(image)
            st.caption(f"–†–∞–∑–º–µ—Ä: {img_array.shape[1]}x{img_array.shape[0]} –ø–∏–∫—Å–µ–ª–µ–π")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")

# ===== –ü–†–ê–í–ê–Ø –ö–û–õ–û–ù–ö–ê: –†–ï–ó–£–õ–¨–¢–ê–¢–´ =====
with col2:
    st.header("üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏")
    
    if uploaded_file is not None:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        img_array = np.array(image)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if len(img_array.shape) == 2:
            img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)
        elif img_array.shape[2] == 4:
            img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2RGB)
        
        # –†–µ—Å–∞–π–∑ –¥–ª—è –º–æ–¥–µ–ª–∏ (128x128)
        img_resized = cv2.resize(img_array, (128, 128))
        img_input = np.expand_dims(img_resized, axis=0)
        # many wrappers normalize internally if needed
        
        # ===== –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø =====
        if model_choice == "–í—Å–µ –º–æ–¥–µ–ª–∏":
            st.subheader("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π")
            
            models = [
                (model1, "HOG + SVM", "üîµ", "#1f77b4"),
                (model2, "Haar Cascade + RF", "üü¢", "#2ca02c"),
                (model3, "CNN (Deep Learning)", "üî¥", "#d62728")
            ]
            
            # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            for model, name, icon, color in models:
                with st.container():
                    st.markdown(f"### {icon} {name}")
                    
                    if model is None:
                        st.warning("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                        st.markdown("---")
                        continue

                    with st.spinner(f'–û–±—Ä–∞–±–æ—Ç–∫–∞ {name}...'):
                        try:
                            pred_proba = model.predict_proba(img_input)[0]
                            pred_proba = normalize_proba(pred_proba.reshape(1, -1))[0]
                            pred_class = int(np.argmax(pred_proba))
                            confidence = float(pred_proba[pred_class])
                            prediction = labels_map.get(pred_class, "Unknown")
                            
                            # –†–µ–∑—É–ª—å—Ç–∞—Ç
                            if confidence >= confidence_threshold:
                                if pred_class == 1:  # –° –º–∞—Å–∫–æ–π
                                    st.success(f"‚úÖ **{prediction}**")
                                else:  # –ë–µ–∑ –º–∞—Å–∫–∏
                                    st.error(f"‚ùå **{prediction}**")
                            else:
                                st.warning("‚ö†Ô∏è –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å")
                            
                            # –ú–µ—Ç—Ä–∏–∫–∏
                            col_a, col_b = st.columns(2)
                            with col_a:
                                st.metric("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ", prediction)
                            with col_b:
                                st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}")
                            
                            # –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä
                            st.progress(float(max(0.0, min(1.0, confidence))))
                            
                            # –î–µ—Ç–∞–ª–∏
                            with st.expander("üìä –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"):
                                for i, label in sorted(labels_map.items()):
                                    prob = pred_proba[i] if i < len(pred_proba) else 0.0
                                    st.write(f"{label}: {prob:.2%}")
                            
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è {name}: {e}")
                        
                    st.markdown("---")
        
        else:
            # –û–¥–Ω–∞ –º–æ–¥–µ–ª—å
            st.subheader(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {model_choice}")
            
            model_map = {
                "HOG + SVM": (model1, "üîµ"),
                "Haar Cascade + RF": (model2, "üü¢"),
                "CNN (Deep Learning)": (model3, "üî¥")
            }
            
            model, icon = model_map.get(model_choice, (None, ""))
            
            if model is None:
                st.error("–í—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            else:
                with st.spinner('–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...'):
                    try:
                        pred_proba = model.predict_proba(img_input)[0]
                        pred_proba = normalize_proba(pred_proba.reshape(1, -1))[0]
                        pred_class = int(np.argmax(pred_proba))
                        confidence = float(pred_proba[pred_class])
                        prediction = labels_map.get(pred_class, "Unknown")
                        
                        # –ë–æ–ª—å—à–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                        st.markdown(f"## {icon} {prediction}")
                        
                        if confidence >= confidence_threshold:
                            if pred_class == 1:  # –° –º–∞—Å–∫–æ–π
                                st.success("‚úÖ –ú–∞—Å–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞!")
                            else:  # –ë–µ–∑ –º–∞—Å–∫–∏
                                st.error("‚ùå –ú–∞—Å–∫–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞!")
                        else:
                            st.warning("‚ö†Ô∏è –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏")
                        
                        # –ú–µ—Ç—Ä–∏–∫–∏ –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö
                        col_a, col_b, col_c = st.columns(3)
                        
                        with col_a:
                            st.metric("–ö–ª–∞—Å—Å", prediction, delta=None)
                        
                        with col_b:
                            delta_text = f"{(confidence-0.5)*100:+.1f}%" if confidence > 0.5 else None
                            st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}", delta=delta_text)
                        
                        with col_c:
                            status = "‚úÖ" if confidence >= confidence_threshold else "‚ö†Ô∏è"
                            st.metric("–°—Ç–∞—Ç—É—Å", status)
                        
                        # –ü—Ä–æ–≥—Ä–µ—Å—Å –±–∞—Ä
                        st.progress(float(max(0.0, min(1.0, confidence))))
                        
                        # –ì—Ä–∞—Ñ–∏–∫ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
                        import pandas as pd
                        prob_df = pd.DataFrame({
                            '–ö–ª–∞—Å—Å': [labels_map[i] for i in sorted(labels_map.keys())],
                            '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å': [pred_proba[i] if i < len(pred_proba) else 0.0 for i in sorted(labels_map.keys())]
                        })
                        st.bar_chart(prob_df.set_index('–ö–ª–∞—Å—Å'))
                        
                        # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                        with st.expander("üî¨ –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"):
                            st.write("**–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞:**")
                            for i, label in sorted(labels_map.items()):
                                prob = pred_proba[i] if i < len(pred_proba) else 0.0
                                st.write(f"- {label}: {prob:.4f} ({prob*100:.2f}%)")
                            
                            st.write(f"\n**–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:** {confidence_threshold}")
                            st.write(f"**–†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:** 128x128")
                    
                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
    else:
        # Placeholder –∫–æ–≥–¥–∞ –Ω–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –Ω–∞—á–∞–ª–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏")
        
        st.markdown("""
        ### üí° –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
        
        1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ —á–µ–ª–æ–≤–µ–∫–∞ (—Å –ª–∏—Ü–æ–º)
        2. –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        3. –ü–æ–ª—É—á–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–∫–∏
        
        ### üì∏ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
        
        - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —á–µ—Ç–∫–∏–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
        - –õ–∏—Ü–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ö–æ—Ä–æ—à–æ –≤–∏–¥–Ω–æ
        - –ò–∑–±–µ–≥–∞–π—Ç–µ —Å–∏–ª—å–Ω—ã—Ö —Ç–µ–Ω–µ–π
        - –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: –ø–æ—Ä—Ç—Ä–µ—Ç–Ω–∞—è —Å—ä–µ–º–∫–∞
        """)


# ===== FOOTER =====
st.markdown("---")

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
with st.expander("‚ÑπÔ∏è –û —Å–∏—Å—Ç–µ–º–µ"):
    st.markdown("""
    ### –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫
    
    –≠—Ç–∞ —Å–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—Ä–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–∞ –∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:
    
    1. **–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è**
       - HOG + SVM
       - Haar Cascade + Random Forest
    
    2. **–ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ**
       - CNN —Å Transfer Learning (MobileNetV2)
    
    ### –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:
    - Python 3.8+
    - OpenCV
    - scikit-learn
    - TensorFlow/Keras
    - Streamlit
    """)
    
# Copyright
st.markdown("""
    <div style='text-align: center; color: gray; padding: 20px;'>
        <p>¬© 2024 Mask Detection System | –í—Å–µ –ø—Ä–∞–≤–∞ –∑–∞—â–∏—â–µ–Ω—ã</p>
    </div>
""", unsafe_allow_html=True)

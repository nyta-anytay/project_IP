"""
Streamlit –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫
"""
import streamlit as st
import cv2
import numpy as np
from PIL import Image
import pickle
import tensorflow as tf
import json
import os

# ===== –ü–£–¢–ò –ö –ú–û–î–ï–õ–Ø–ú =====
TRAINED_MODELS_DIR = os.path.join(os.getcwd(), 'trained_models')

MODEL1_PATH = os.path.join(TRAINED_MODELS_DIR, 'model1_hog_svm.pkl')
MODEL2_PATH = os.path.join(TRAINED_MODELS_DIR, 'model2_haar_rf.pkl')
MODEL3_PATH = os.path.join(TRAINED_MODELS_DIR, 'model3_cnn.h5')
LABELS_MAP_PATH = os.path.join(TRAINED_MODELS_DIR, 'labels_map.json')

# ===== –ù–ê–°–¢–†–û–ô–ö–ê –°–¢–†–ê–ù–ò–¶–´ =====
st.set_page_config(
    page_title="Mask Detection System",
    page_icon="üò∑",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===== –ö–ê–°–¢–û–ú–ù–´–ï –°–¢–ò–õ–ò =====
st.markdown("""
    <style>
    .main-header {
        font-size: 3.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .stProgress > div > div > div > div {
        background-color: #1f77b4;
    }
    div[data-testid="stMetricValue"] {
        font-size: 1.5rem;
    }
    </style>
""", unsafe_allow_html=True)

# ===== –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô =====
@st.cache_resource
def load_all_models():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞–ø—Ä—è–º—É—é –∏–∑ trained_models/"""
    try:
        # ===== –ú–æ–¥–µ–ª—å 1 =====
        model1 = None
        if os.path.exists(MODEL1_PATH):
            with open(MODEL1_PATH, 'rb') as f:
                model1 = pickle.load(f)
        
        # ===== –ú–æ–¥–µ–ª—å 2 =====
        model2 = None
        if os.path.exists(MODEL2_PATH):
            with open(MODEL2_PATH, 'rb') as f:
                model2 = pickle.load(f)
        
        # ===== –ú–æ–¥–µ–ª—å 3 (CNN) =====
        model3 = None
        if os.path.exists(MODEL3_PATH):
            model3_keras = tf.keras.models.load_model(MODEL3_PATH, compile=False)
            
            class CNNWrapper:
                def __init__(self, model):
                    self.model = model
                def predict_proba(self, X):
                    if X.max() > 1.0:
                        X = X / 255.0
                    pred = self.model.predict(X, verbose=0)
                    if pred.shape[-1] == 1:
                        prob = pred.flatten()
                        return np.column_stack([1 - prob, prob])
                    return pred
            model3 = CNNWrapper(model3_keras)
        
        # ===== Labels map =====
        labels_map = {0: "WithoutMask", 1: "WithMask"}
        if os.path.exists(LABELS_MAP_PATH):
            with open(LABELS_MAP_PATH, 'r') as f:
                d = json.load(f)
                labels_map = {int(k): v for k, v in d.items()}
        
        any_loaded = model1 is not None or model2 is not None or model3 is not None
        return model1, model2, model3, labels_map, any_loaded, ""
    
    except Exception as e:
        return None, None, None, {}, False, str(e)

# ===== –ó–ê–ì–†–£–ó–ö–ê =====
model1, model2, model3, labels_map, models_loaded, error_msg = load_all_models()

# ===== –ó–ê–ì–û–õ–û–í–û–ö =====
st.markdown('<h1 class="main-header">üò∑ –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫ –Ω–∞ –ª–∏—Ü–µ</h1>', unsafe_allow_html=True)
st.markdown("---")

# ===== SIDEBAR =====
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    available_models = []
    if model1: available_models.append("HOG + SVM")
    if model2: available_models.append("Haar Cascade + RF")
    if model3: available_models.append("CNN (Deep Learning)")
    
    model_choice = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
        ["–í—Å–µ –º–æ–¥–µ–ª–∏"] + available_models if available_models else ["–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"]
    )
    
    # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    confidence_threshold = st.slider(
        "–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:", 
        min_value=0.0, max_value=1.0, value=0.5, step=0.05
    )
    
    st.markdown("---")
    
    # –°—Ç–∞—Ç—É—Å
    st.markdown("### üìä –°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–µ–π")
    for name, model, path in [
        ("HOG + SVM", model1, MODEL1_PATH),
        ("Haar Cascade + RF", model2, MODEL2_PATH),
        ("CNN (Deep Learning)", model3, MODEL3_PATH)
    ]:
        if model:
            st.success(f"‚úÖ {name}")
            if os.path.exists(path):
                st.caption(f"{os.path.getsize(path)/(1024*1024):.1f} MB")
        else:
            st.error(f"‚ùå {name}")

# ===== –ü–†–û–í–ï–†–ö–ê =====
if not models_loaded:
    st.error(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏: {error_msg}")
    st.stop()

# ===== –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° =====
col1, col2 = st.columns([1, 1], gap="large")

# ===== –õ–ï–í–ê–Ø –ö–û–õ–û–ù–ö–ê =====
with col1:
    st.header("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    
    upload_option = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–±:", ["–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–º–µ—Ä—É"], horizontal=True)
    uploaded_file = None
    
    if upload_option == "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª":
        uploaded_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...", type=['jpg','jpeg','png','bmp'])
    else:
        camera_image = st.camera_input("–°–¥–µ–ª–∞–π—Ç–µ —Ñ–æ—Ç–æ")
        if camera_image: uploaded_file = camera_image
    
    if uploaded_file:
        image = Image.open(uploaded_file)
        st.image(image, caption='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_column_width=True)
        img_array = np.array(image)
        st.caption(f"–†–∞–∑–º–µ—Ä: {img_array.shape[1]}x{img_array.shape[0]} –ø–∏–∫—Å–µ–ª–µ–π")

# ===== –ü–†–ê–í–ê–Ø –ö–û–õ–û–ù–ö–ê =====
with col2:
    st.header("üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏")
    
    if uploaded_file:
        img_array = np.array(image)
        if len(img_array.shape) == 2:
            img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)
        elif img_array.shape[2] == 4:
            img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2RGB)
        
        img_resized = cv2.resize(img_array, (128,128))
        img_input = np.expand_dims(img_resized, axis=0)
        
        # ===== –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø =====
        models_to_check = []
        if model_choice=="–í—Å–µ –º–æ–¥–µ–ª–∏":
            if model1: models_to_check.append((model1, "HOG + SVM", "üîµ"))
            if model2: models_to_check.append((model2, "Haar Cascade + RF", "üü¢"))
            if model3: models_to_check.append((model3, "CNN (Deep Learning)", "üî¥"))
        else:
            model_map = {"HOG + SVM": model1, "Haar Cascade + RF": model2, "CNN (Deep Learning)": model3}
            icon_map = {"HOG + SVM":"üîµ", "Haar Cascade + RF":"üü¢","CNN (Deep Learning)":"üî¥"}
            m = model_map.get(model_choice)
            if m: models_to_check.append((m, model_choice, icon_map[model_choice]))
        
        for model, name, icon in models_to_check:
            st.markdown(f"### {icon} {name}")
            pred_proba = model.predict_proba(img_input)[0]
            pred_class = np.argmax(pred_proba)
            confidence = pred_proba[pred_class]
            prediction = labels_map[pred_class]
            
            # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if confidence>=confidence_threshold:
                if pred_class==1: st.success(f"‚úÖ {prediction}")
                else: st.error(f"‚ùå {prediction}")
            else:
                st.warning(f"‚ö†Ô∏è {prediction} (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)")
            
            # –ú–µ—Ç—Ä–∏–∫–∏
            col_a,col_b = st.columns(2)
            with col_a: st.metric("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ", prediction)
            with col_b: st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}")
            
            # –ü—Ä–æ–≥—Ä–µ—Å—Å
            st.progress(float(min(confidence,1.0)))
            
            # –î–µ—Ç–∞–ª–∏
            with st.expander("üìä –î–µ—Ç–∞–ª–∏"):
                for i,label in labels_map.items():
                    st.write(f"{label}: {pred_proba[i]:.2%}")
            
            st.markdown("---")
    
    else:
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –Ω–∞—á–∞–ª–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏")

        
        st.markdown("""
        ### üí° –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
        
        1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ —á–µ–ª–æ–≤–µ–∫–∞ (—Å –ª–∏—Ü–æ–º)
        2. –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        3. –ü–æ–ª—É—á–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–∫–∏
        
        ### üì∏ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
        
        - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —á–µ—Ç–∫–∏–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏
        - –õ–∏—Ü–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ö–æ—Ä–æ—à–æ –≤–∏–¥–Ω–æ
        - –ò–∑–±–µ–≥–∞–π—Ç–µ —Å–∏–ª—å–Ω—ã—Ö —Ç–µ–Ω–µ–π
        - –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: –ø–æ—Ä—Ç—Ä–µ—Ç–Ω–∞—è —Å—ä–µ–º–∫–∞
        """)


# ===== FOOTER =====
st.markdown("---")

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
with st.expander("‚ÑπÔ∏è –û —Å–∏—Å—Ç–µ–º–µ"):
    st.markdown("""
    ### –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫
    
    –≠—Ç–∞ —Å–∏—Å—Ç–µ–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—Ä–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–∞ –∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:
    
    1. **–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è**
       - HOG + SVM
       - Haar Cascade + Random Forest
    
    2. **–ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ**
       - CNN —Å Transfer Learning (MobileNetV2)
    
    ### –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:
    - Python 3.8+
    - OpenCV
    - scikit-learn
    - TensorFlow/Keras
    - Streamlit
    """)
    
# Copyright
st.markdown("""
    <div style='text-align: center; color: gray; padding: 20px;'>
        <p>¬© 2024 Mask Detection System | –í—Å–µ –ø—Ä–∞–≤–∞ –∑–∞—â–∏—â–µ–Ω—ã</p>
    </div>
""", unsafe_allow_html=True)

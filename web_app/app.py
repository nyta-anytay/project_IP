"""
Streamlit –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫
"""
import streamlit as st
import cv2
import numpy as np
from PIL import Image
import pickle
from tensorflow.keras.models import load_model
from tensorflow.keras.layers import BatchNormalization
import json
import os
import warnings
warnings.filterwarnings('ignore')

# ===== –ü–£–¢–ò –ö –§–ê–ô–õ–ê–ú =====
# –í–ê–ñ–ù–û: –≤—Å–µ —Ñ–∞–π–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ —Ç–æ–π –∂–µ –ø–∞–ø–∫–µ, —á—Ç–æ –∏ app.py
MODEL1_PATH = 'model1_hog_svm.pkl'    # –ü–µ—Ä–≤—ã–π .pkl —Ñ–∞–π–ª
MODEL2_PATH = 'model2_haar_rf.pkl'    # –í—Ç–æ—Ä–æ–π .pkl —Ñ–∞–π–ª  
MODEL3_PATH = 'model3_cnn.h5'         # .h5 —Ñ–∞–π–ª
LABELS_MAP_PATH = 'labels_map.json'  # JSON —Å –º–µ—Ç–∫–∞–º–∏

# ===== –ù–ê–°–¢–†–û–ô–ö–ê –°–¢–†–ê–ù–ò–¶–´ =====
st.set_page_config(
    page_title="Mask Detection System",
    page_icon="üò∑",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===== –ö–ê–°–¢–û–ú–ù–´–ï –°–¢–ò–õ–ò =====
st.markdown("""
    <style>
    .main-header {
        font-size: 3.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .stProgress > div > div > div > div {
        background-color: #1f77b4;
    }
    div[data-testid="stMetricValue"] {
        font-size: 1.5rem;
    }
    </style>
""", unsafe_allow_html=True)

# ===== –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –§–ê–ô–õ–û–í =====
def check_files_exist():
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–µ–π –∏ labels_map"""
    files_needed = [MODEL1_PATH, MODEL2_PATH, MODEL3_PATH, LABELS_MAP_PATH]
    existing_files = []
    missing_files = []
    
    for file in files_needed:
        if os.path.exists(file):
            existing_files.append(file)
        else:
            missing_files.append(file)
    
    return existing_files, missing_files

# ===== –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô –° –û–ë–†–ê–ë–û–¢–ö–û–ô –û–®–ò–ë–û–ö =====
@st.cache_resource
def load_all_models():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∏ labels_map"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã
    existing_files, missing_files = check_files_exist()
    
    if missing_files:
        st.warning(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∞–π–ª—ã: {', '.join(missing_files)}")
        st.info(f"‚úÖ –ù–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã: {', '.join(existing_files) if existing_files else '–Ω–µ—Ç'}")
    
    try:
        # ===== labels_map =====
        if os.path.exists(LABELS_MAP_PATH):
            with open(LABELS_MAP_PATH, 'r') as f:
                labels_dict = json.load(f)
                labels_map = {int(k): v for k, v in labels_dict.items()}
                st.sidebar.success(f"‚úÖ labels_map –∑–∞–≥—Ä—É–∂–µ–Ω: {labels_map}")
        else:
            labels_map = {0: "–ë–µ–∑ –º–∞—Å–∫–∏", 1: "–° –º–∞—Å–∫–æ–π"}
            st.sidebar.info(f"‚ÑπÔ∏è –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π labels_map: {labels_map}")

        models_loaded = []
        model1, model2, model3 = None, None, None

        # ===== –ú–æ–¥–µ–ª—å 1: HOG + SVM =====
        try:
            with open(MODEL1_PATH, 'rb') as f:
                model1 = pickle.load(f)
            models_loaded.append(("model1_hog_svm", True, ""))
            st.sidebar.success(f"‚úÖ {MODEL1_PATH} –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            models_loaded.append(("model1_hog_svm", False, str(e)))
            st.sidebar.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {MODEL1_PATH}: {str(e)[:50]}...")

        # ===== –ú–æ–¥–µ–ª—å 2: Haar + RF =====
        try:
            with open(MODEL2_PATH, 'rb') as f:
                model2 = pickle.load(f)
            models_loaded.append(("model2_haar_rf", True, ""))
            st.sidebar.success(f"‚úÖ {MODEL2_PATH} –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            models_loaded.append(("model2_haar_rf", False, str(e)))
            st.sidebar.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {MODEL2_PATH}: {str(e)[:50]}...")

        # ===== –ú–æ–¥–µ–ª—å 3: CNN =====
        try:
            if os.path.exists(MODEL3_PATH):
                model3_keras = load_model(
                    MODEL3_PATH,
                    compile=False,
                    custom_objects={'BatchNormalization': BatchNormalization}
                )
                
                class CNNWrapper:
                    def __init__(self, model):
                        self.model = model
                    def predict_proba(self, X):
                        return self.model.predict(X, verbose=0)
                
                model3 = CNNWrapper(model3_keras)
                models_loaded.append(("model3_cnn", True, ""))
                st.sidebar.success(f"‚úÖ {MODEL3_PATH} –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            else:
                models_loaded.append(("model3_cnn", False, f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {MODEL3_PATH}"))
                st.sidebar.error(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {MODEL3_PATH}")
        except Exception as e:
            models_loaded.append(("model_cnn3", False, str(e)))
            st.sidebar.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {MODEL3_PATH}: {str(e)[:50]}...")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å
        any_loaded = any(status for _, status, _ in models_loaded)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–∞—Ö
        error_msg = ""
        if not any_loaded:
            error_details = [f"{name}: {msg}" for name, status, msg in models_loaded if not status and msg]
            error_msg = f"–û—à–∏–±–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏: {'; '.join(error_details)}"

        return model1, model2, model3, labels_map, any_loaded, error_msg

    except Exception as e:
        return None, None, None, {}, False, f"–û–±—â–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {str(e)}"

# ===== –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô =====
model1, model2, model3, labels_map, models_loaded, error_msg = load_all_models()

# ===== –ó–ê–ì–û–õ–û–í–û–ö =====
st.markdown('<h1 class="main-header">üò∑ –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫ –Ω–∞ –ª–∏—Ü–µ</h1>', 
           unsafe_allow_html=True)
st.markdown("---")

# ===== SIDEBAR: –û–°–ù–û–í–ù–´–ï –ù–ê–°–¢–†–û–ô–ö–ò =====
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–∞—Ö
    if st.checkbox("üìÅ –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–∞—Ö", True):
        existing, missing = check_files_exist()
        st.write("**–ù–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã:**")
        for file in existing:
            size_kb = os.path.getsize(file) / 1024
            st.success(f"‚úÖ {file} ({size_kb:.1f} KB)")
        
        if missing:
            st.write("**–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∞–π–ª—ã:**")
            for file in missing:
                st.error(f"‚ùå {file}")
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    available_models = []
    if model1:
        available_models.append("HOG + SVM")
    if model2:
        available_models.append("Haar Cascade + RF")
    if model3:
        available_models.append("CNN (Deep Learning)")
    
    if available_models:
        model_choice = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
            ["–í—Å–µ –º–æ–¥–µ–ª–∏"] + available_models,
            help="–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"
        )
    else:
        model_choice = "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"
        st.error("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –≤—ã–±–æ—Ä–∞")
    
    # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    confidence_threshold = st.slider(
        "–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:", 
        min_value=0.0, 
        max_value=1.0, 
        value=0.5, 
        step=0.05,
        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"
    )
    
    # –ö–Ω–æ–ø–∫–∞ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏
    if st.button("üîÑ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏"):
        st.cache_resource.clear()
        st.rerun()
    
    st.markdown("---")
    
    # –°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–µ–π
    st.markdown("### üìä –°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–µ–π")
    status_col1, status_col2, status_col3 = st.columns(3)
    with status_col1:
        st.metric("HOG+SVM", "‚úÖ" if model1 else "‚ùå")
    with status_col2:
        st.metric("Haar+RF", "‚úÖ" if model2 else "‚ùå")
    with status_col3:
        st.metric("CNN", "‚úÖ" if model3 else "‚ùå")

# ===== –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° =====

# –ï—Å–ª–∏ –Ω–µ—Ç –Ω–∏ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏
if not models_loaded:
    st.error("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏!")
    st.warning(error_msg)
    
    st.info("""
    ## üöÄ –†–µ—à–µ–Ω–∏–µ –¥–ª—è Streamlit Cloud:
    
    ### 1. **–°–æ–∑–¥–∞–π—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–∞–π–ª–æ–≤:**
    ```
    –≤–∞—à–∞-–ø–∞–ø–∫–∞/
    ‚îú‚îÄ‚îÄ app.py                    # –≠—Ç–æ—Ç —Ñ–∞–π–ª
    ‚îú‚îÄ‚îÄ model_hog_svm.pkl        # –í–∞—à –ø–µ—Ä–≤—ã–π .pkl
    ‚îú‚îÄ‚îÄ model_haar_rf.pkl        # –í–∞—à –≤—Ç–æ—Ä–æ–π .pkl  
    ‚îú‚îÄ‚îÄ model_cnn.h5             # –í–∞—à .h5 —Ñ–∞–π–ª
    ‚îú‚îÄ‚îÄ labels_map.json          # JSON —Å –º–µ—Ç–∫–∞–º–∏ (–∏–ª–∏ –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω)
    ‚îî‚îÄ‚îÄ requirements.txt         # –°–ø–∏—Å–æ–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
    ```
    
    ### 2. **–ü–µ—Ä–µ–∏–º–µ–Ω—É–π—Ç–µ –≤–∞—à–∏ —Ñ–∞–π–ª—ã:**
    ```bash
    # –í–∞—à–∏ —Ç–µ–∫—É—â–∏–µ —Ñ–∞–π–ª—ã –¥–æ–ª–∂–Ω—ã –Ω–∞–∑—ã–≤–∞—Ç—å—Å—è —Ç–∞–∫:
    mv –≤–∞—à_—Ñ–∞–π–ª1.pkl model_hog_svm.pkl
    mv –≤–∞—à_—Ñ–∞–π–ª2.pkl model_haar_rf.pkl  
    mv –≤–∞—à_—Ñ–∞–π–ª.h5 model_cnn.h5
    ```
    
    ### 3. **–°–æ–∑–¥–∞–π—Ç–µ requirements.txt:**
    ```txt
    streamlit==1.29.0
    tensorflow==2.15.0
    opencv-python-headless==4.8.1  # –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ headless –≤–µ—Ä—Å–∏—é!
    numpy==1.24.3
    Pillow==10.1.0
    scikit-learn==1.3.2
    pandas==2.1.4
    ```
    
    ### 4. **–ó–∞–≥—Ä—É–∑–∏—Ç–µ –í–°–ï —Ñ–∞–π–ª—ã –Ω–∞ GitHub** (–Ω–µ —Ç–æ–ª—å–∫–æ –∫–æ–¥!)
    """)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    if st.checkbox("–ü–æ–∫–∞–∑–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"):
        st.write("–¢–µ–∫—É—â–∞—è —Ä–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è:", os.getcwd())
        st.write("–°–æ–¥–µ—Ä–∂–∏–º–æ–µ:", os.listdir('.'))
    
    st.stop()

# –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
col1, col2 = st.columns([1, 1], gap="large")

# ===== –õ–ï–í–ê–Ø –ö–û–õ–û–ù–ö–ê: –ó–ê–ì–†–£–ó–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø =====
with col1:
    st.header("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    
    upload_option = st.radio(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Å–ø–æ—Å–æ–±:",
        ["–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–º–µ—Ä—É"],
        horizontal=True
    )
    
    uploaded_file = None
    
    if upload_option == "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª":
        uploaded_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...", 
            type=['jpg', 'jpeg', 'png', 'bmp'],
            help="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: JPG, JPEG, PNG, BMP"
        )
    else:
        camera_image = st.camera_input("–°–¥–µ–ª–∞–π—Ç–µ —Ñ–æ—Ç–æ")
        if camera_image is not None:
            uploaded_file = camera_image

# ===== –ü–†–ê–í–ê–Ø –ö–û–õ–û–ù–ö–ê: –†–ï–ó–£–õ–¨–¢–ê–¢–´ =====
with col2:
    st.header("üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏")
    
    if uploaded_file is not None:
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = Image.open(uploaded_file)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –ª–µ–≤–æ–π –∫–æ–ª–æ–Ω–∫–µ
            with col1:
                st.image(image, caption='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_column_width=True)
                img_array = np.array(image)
                st.caption(f"–†–∞–∑–º–µ—Ä: {img_array.shape[1]}x{img_array.shape[0]} –ø–∏–∫—Å–µ–ª–µ–π")
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–µ–π
            if len(img_array.shape) == 2:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)
            elif img_array.shape[2] == 4:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2RGB)
            
            # –†–µ—Å–∞–π–∑ –¥–ª—è –º–æ–¥–µ–ª–∏ (—É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ä–∞–∑–º–µ—Ä —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤–∞—à–∏–º –º–æ–¥–µ–ª—è–º)
            img_resized = cv2.resize(img_array, (128, 128))
            img_input = np.expand_dims(img_resized, axis=0) / 255.0  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            
            # ===== –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø =====
            if model_choice == "–í—Å–µ –º–æ–¥–µ–ª–∏":
                st.subheader("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π")
                
                models = []
                if model1:
                    models.append((model1, "HOG + SVM", "üîµ", "#1f77b4"))
                if model2:
                    models.append((model2, "Haar Cascade + RF", "üü¢", "#2ca02c"))
                if model3:
                    models.append((model3, "CNN (Deep Learning)", "üî¥", "#d62728"))
                
                for model, name, icon, color in models:
                    with st.container():
                        st.markdown(f"### {icon} {name}")
                        
                        try:
                            pred_proba = model.predict_proba(img_input)[0]
                            
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª–∞—Å—Å
                            if len(pred_proba) > 2:
                                pred_class = np.argmax(pred_proba)
                            else:
                                pred_class = 1 if pred_proba[1] > 0.5 else 0
                            
                            confidence = pred_proba[pred_class] if len(pred_proba) > pred_class else pred_proba[1]
                            prediction = labels_map.get(pred_class, "–° –º–∞—Å–∫–æ–π" if pred_class == 1 else "–ë–µ–∑ –º–∞—Å–∫–∏")
                            
                            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                            result_col1, result_col2 = st.columns([2, 1])
                            with result_col1:
                                if confidence >= confidence_threshold:
                                    if prediction == "–° –º–∞—Å–∫–æ–π" or pred_class == 1:
                                        st.success(f"‚úÖ **{prediction}**")
                                    else:
                                        st.error(f"‚ùå **{prediction}**")
                                else:
                                    st.warning(f"‚ö†Ô∏è **{prediction}** (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)")
                            
                            with result_col2:
                                st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}")
                            
                            st.progress(float(confidence))
                            
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {str(e)[:100]}")
                        
                        st.markdown("---")
            
            elif model_choice in ["HOG + SVM", "Haar Cascade + RF", "CNN (Deep Learning)"]:
                # –û–¥–Ω–∞ –º–æ–¥–µ–ª—å
                model_map = {
                    "HOG + SVM": (model1, "üîµ"),
                    "Haar Cascade + RF": (model2, "üü¢"),
                    "CNN (Deep Learning)": (model3, "üî¥")
                }
                
                model, icon = model_map[model_choice]
                
                if model is None:
                    st.error(f"–ú–æ–¥–µ–ª—å {model_choice} –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                else:
                    with st.spinner(f'–û–±—Ä–∞–±–æ—Ç–∫–∞ {model_choice}...'):
                        try:
                            pred_proba = model.predict_proba(img_input)[0]
                            
                            if len(pred_proba) > 2:
                                pred_class = np.argmax(pred_proba)
                            else:
                                pred_class = 1 if pred_proba[1] > 0.5 else 0
                            
                            confidence = pred_proba[pred_class] if len(pred_proba) > pred_class else pred_proba[1]
                            prediction = labels_map.get(pred_class, "–° –º–∞—Å–∫–æ–π" if pred_class == 1 else "–ë–µ–∑ –º–∞—Å–∫–∏")
                            
                            # –ë–æ–ª—å—à–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                            st.markdown(f"## {icon} {prediction}")
                            
                            if confidence >= confidence_threshold:
                                if prediction == "–° –º–∞—Å–∫–æ–π" or pred_class == 1:
                                    st.success("‚úÖ –ú–∞—Å–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞!")
                                else:
                                    st.error("‚ùå –ú–∞—Å–∫–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞!")
                            else:
                                st.warning("‚ö†Ô∏è –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏")
                            
                            # –ú–µ—Ç—Ä–∏–∫–∏
                            col_a, col_b, col_c = st.columns(3)
                            
                            with col_a:
                                st.metric("–ö–ª–∞—Å—Å", prediction)
                            
                            with col_b:
                                st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}")
                            
                            with col_c:
                                status = "‚úÖ" if confidence >= confidence_threshold else "‚ö†Ô∏è"
                                st.metric("–°—Ç–∞—Ç—É—Å", status)
                            
                            st.progress(float(confidence))
                            
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {str(e)}")
        
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
    
    else:
        # –ö–æ–≥–¥–∞ –Ω–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –Ω–∞—á–∞–ª–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏")
        
        st.markdown("""
        ### üí° –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
        
        1. **–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–æ—Ç–æ** —á–µ–ª–æ–≤–µ–∫–∞ (–ª–∏—Ü–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤–∏–¥–Ω–æ)
        2. **–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å** –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        3. **–ü–æ–ª—É—á–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç** –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–∫–∏
        
        ### üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
        - –ß–µ—Ç–∫–æ–µ, —Ö–æ—Ä–æ—à–æ –æ—Å–≤–µ—â–µ–Ω–Ω–æ–µ –ª–∏—Ü–æ
        - –ü–æ—Ä—Ç—Ä–µ—Ç–Ω–∞—è –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è
        - –ú–∏–Ω–∏–º—É–º –ø–æ—Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        """)

# ===== FOOTER =====
st.markdown("---")

with st.expander("üìã –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –¥–µ–ø–ª–æ—é"):
    st.markdown("""
    ### –î–ª—è —É—Å–ø–µ—à–Ω–æ–≥–æ –¥–µ–ø–ª–æ—è –Ω–∞ Streamlit Cloud:
    
    1. **–°–æ–∑–¥–∞–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å–æ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π:**
    ```
    mask-detection-app/
    ‚îú‚îÄ‚îÄ app.py                    # –≠—Ç–æ—Ç —Ñ–∞–π–ª
    ‚îú‚îÄ‚îÄ model_hog_svm.pkl        # –í–∞—à HOG+SVM .pkl
    ‚îú‚îÄ‚îÄ model_haar_rf.pkl        # –í–∞—à Haar+RF .pkl
    ‚îú‚îÄ‚îÄ model_cnn.h5             # –í–∞—à–∞ CNN .h5
    ‚îú‚îÄ‚îÄ labels_map.json          # (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    ‚îî‚îÄ‚îÄ requirements.txt         # –í–∞–∂–Ω—ã–µ!
    ```
    
    2. **requirements.txt –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å:**
    ```txt
    streamlit==1.29.0
    tensorflow==2.15.0
    opencv-python-headless==4.8.1
    numpy==1.24.3
    Pillow==10.1.0
    scikit-learn==1.3.2
    ```
    
    3. **–ù–∞ Streamlit Cloud:**
       - –ü–æ–¥–∫–ª—é—á–∏—Ç–µ GitHub —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
       - Main file path: `app.py`
       - –ù–∞–∂–º–∏—Ç–µ Deploy
    """)

# Copyright
st.markdown("""
    <div style='text-align: center; color: gray; padding: 20px;'>
        <p>¬© 2024 Mask Detection System</p>
    </div>
""", unsafe_allow_html=True)
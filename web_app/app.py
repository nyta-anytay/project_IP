"""
Streamlit –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫
"""
import streamlit as st
import cv2
import numpy as np
from PIL import Image
import pickle
import json
import sys
import os
import warnings
warnings.filterwarnings('ignore')

# ===== –î–û–ë–ê–í–õ–Ø–ï–ú –ò–ú–ü–û–†–¢–´ –î–õ–Ø TENSORFLOW =====
try:
    import tensorflow as tf
    from tensorflow.keras.models import load_model
    from tensorflow.keras.layers import BatchNormalization
    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False

# ===== –ü–£–¢–ò –ö –ú–û–î–ï–õ–Ø–ú =====
MODEL1_PATH = 'trained_models/model1_hog_svm.pkl'
MODEL2_PATH = 'trained_models/model2_haar_rf.pkl'
MODEL3_PATH = 'trained_models/model3_cnn.h5'
LABELS_MAP_PATH = 'results/labels_map.json'

# ===== –ù–ê–°–¢–†–û–ô–ö–ê –°–¢–†–ê–ù–ò–¶–´ =====
st.set_page_config(
    page_title="Mask Detection System",
    page_icon="üò∑",
    layout="wide"
)

# ===== –ö–ê–°–¢–û–ú–ù–´–ï –°–¢–ò–õ–ò =====
st.markdown("""
    <style>
    .main-header {
        font-size: 3.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    </style>
""", unsafe_allow_html=True)

# ===== –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô –° –û–ë–†–ê–ë–û–¢–ö–û–ô –û–®–ò–ë–û–ö =====
@st.cache_resource
def load_all_models():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∏ labels_map"""
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ labels_map
    try:
        with open(LABELS_MAP_PATH, 'r') as f:
            labels_dict = json.load(f)
            labels_map = {int(k): v for k, v in labels_dict.items()}
    except:
        labels_map = {0: 'WithoutMask', 1: 'WithMask'}
    
    model1 = None
    model2 = None
    model3 = None
    errors = []
    
    # ===== –ú–æ–¥–µ–ª—å 1: HOG + SVM =====
    if os.path.exists(MODEL1_PATH):
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ë–ï–ó –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –æ—Ç src
            import sys
            import types
            
            # –°–æ–∑–¥–∞–µ–º —Ñ–µ–π–∫–æ–≤—ã–π –º–æ–¥—É–ª—å src –µ—Å–ª–∏ –µ–≥–æ —Ç—Ä–µ–±—É—é—Ç –º–æ–¥–µ–ª–∏
            if 'src' not in sys.modules:
                src_module = types.ModuleType('src')
                sys.modules['src'] = src_module
            
            with open(MODEL1_PATH, 'rb') as f:
                model1 = pickle.load(f)
        except Exception as e:
            errors.append(f"Model1: {str(e)}")
    
    # ===== –ú–æ–¥–µ–ª—å 2: Haar + RF =====
    if os.path.exists(MODEL2_PATH):
        try:
            with open(MODEL2_PATH, 'rb') as f:
                model2 = pickle.load(f)
        except Exception as e:
            errors.append(f"Model2: {str(e)}")
    
    # ===== –ú–æ–¥–µ–ª—å 3: CNN =====
    if os.path.exists(MODEL3_PATH) and TF_AVAILABLE:
        try:
            model3_keras = load_model(MODEL3_PATH, compile=False)
            
            class CNNWrapper:
                def __init__(self, model):
                    self.model = model
                def predict_proba(self, X):
                    return self.model.predict(X, verbose=0)
            
            model3 = CNNWrapper(model3_keras)
        except Exception as e:
            errors.append(f"Model3: {str(e)}")
    
    all_loaded = model1 is not None or model2 is not None or model3 is not None
    error_msg = "; ".join(errors) if errors else ""
    
    return model1, model2, model3, labels_map, all_loaded, error_msg

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
model1, model2, model3, labels_map, models_loaded, error_msg = load_all_models()

# ===== –ó–ê–ì–û–õ–û–í–û–ö =====
st.markdown('<h1 class="main-header">üò∑ –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫ –Ω–∞ –ª–∏—Ü–µ</h1>', 
           unsafe_allow_html=True)
st.markdown("---")

# ===== –ü–†–û–í–ï–†–ö–ê –ù–ê–õ–ò–ß–ò–Ø –ú–û–î–ï–õ–ï–ô =====
if not models_loaded:
    st.error("‚ö†Ô∏è **–î–µ–º–æ-—Ä–µ–∂–∏–º**: –ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ –æ–±–ª–∞–∫–µ")
    
    if error_msg:
        with st.expander("üîç –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –æ—à–∏–±–æ–∫"):
            st.code(error_msg)
    
    st.info("""
    ### üì∫ –≠—Ç–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    
    **–ú–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã** –ø–æ –æ–¥–Ω–æ–π –∏–∑ –ø—Ä–∏—á–∏–Ω:
    - –§–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ –¥–ª—è GitHub (>100MB)
    - –ú–æ–¥–µ–ª–∏ –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
    - –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –Ω–µ —Ä–∞–∑—Ä–µ—à–µ–Ω—ã
    
    ### üöÄ –î–ª—è –ø–æ–ª–Ω–æ–π –≤–µ—Ä—Å–∏–∏:
    
    ```bash
    # 1. –ö–ª–æ–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
    git clone https://github.com/nyta-anytay/project_IP.git
    cd project_IP
    
    # 2. –°–æ–∑–¥–∞–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ
    python -m venv venv
    venv\\Scripts\\activate  # Windows
    
    # 3. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
    pip install -r requirements.txt
    
    # 4. –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª–∏
    python scripts/02_train_models.py
    
    # 5. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    cd web_app
    streamlit run app.py
    ```
    
    ### üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π:
    """)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("üîµ HOG + SVM", "99.12%", "Validation Accuracy")
        st.caption("–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π CV –º–µ—Ç–æ–¥")
    
    with col2:
        st.metric("üü¢ Haar + RF", "95.50%", "Validation Accuracy")
        st.caption("–ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥")
    
    with col3:
        st.metric("üî¥ CNN", "99.80%", "Best Validation Accuracy")
        st.caption("Deep Learning")
    
    # –¢–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    st.markdown("### üìà –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
    
    import pandas as pd
    results = pd.DataFrame({
        '–ú–æ–¥–µ–ª—å': ['HOG + SVM', 'Haar Cascade + RF', 'CNN (MobileNetV2)'],
        'Accuracy': ['99.12%', '95.50%', '99.80%'],
        'Precision': ['99.10%', '95.48%', '99.79%'],
        'Recall': ['99.10%', '95.48%', '99.79%'],
        'F1-Score': ['99.10%', '95.48%', '99.79%']
    })
    
    st.dataframe(results, use_container_width=True, hide_index=True)
    
    st.markdown("---")
    st.markdown("""
    ### üéì –û –ø—Ä–æ–µ–∫—Ç–µ
    
    **–¶–µ–ª—å:** –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ —Å–∏—Å—Ç–µ–º—ã –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –º–∞—Å–æ–∫ –Ω–∞ –ª–∏—Ü–µ
    
    **–î–∞—Ç–∞—Å–µ—Ç:** 11,792 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    - Train: 10,000
    - Validation: 800  
    - Test: 992
    
    **–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:**
    - Python, OpenCV, scikit-learn
    - TensorFlow/Keras (CNN)
    - Streamlit (–≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å)
    
    **GitHub:** https://github.com/nyta-anytay/project_IP
    """)
    
    st.stop()

# ===== SIDEBAR =====
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    available_models = []
    if model1:
        available_models.append("HOG + SVM")
    if model2:
        available_models.append("Haar Cascade + RF")
    if model3:
        available_models.append("CNN (Deep Learning)")
    
    if available_models:
        model_choice = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
            ["–í—Å–µ –º–æ–¥–µ–ª–∏"] + available_models
        )
    else:
        model_choice = None
        st.error("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
    
    confidence_threshold = st.slider(
        "–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:", 
        0.0, 1.0, 0.5, 0.05
    )
    
    st.markdown("---")
    st.markdown("### üìä –°—Ç–∞—Ç—É—Å")
    
    if model1:
        st.success("‚úÖ HOG + SVM")
    else:
        st.error("‚ùå HOG + SVM")
    
    if model2:
        st.success("‚úÖ Haar + RF")
    else:
        st.error("‚ùå Haar + RF")
    
    if model3:
        st.success("‚úÖ CNN")
    else:
        st.error("‚ùå CNN")

# ===== –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° =====
col1, col2 = st.columns([1, 1])

with col1:
    st.header("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    
    uploaded_file = st.file_uploader(
        "–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...", 
        type=['jpg', 'jpeg', 'png']
    )
    
    if uploaded_file:
        image = Image.open(uploaded_file)
        st.image(image, use_column_width=True)

with col2:
    st.header("üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã")
    
    if uploaded_file and model_choice:
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        img_array = np.array(image)
        
        if len(img_array.shape) == 2:
            img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)
        elif img_array.shape[2] == 4:
            img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2RGB)
        
        img_resized = cv2.resize(img_array, (128, 128))
        img_input = np.expand_dims(img_resized, axis=0)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        models_to_use = []
        if model_choice == "–í—Å–µ –º–æ–¥–µ–ª–∏":
            if model1:
                models_to_use.append((model1, "HOG + SVM", "üîµ"))
            if model2:
                models_to_use.append((model2, "Haar + RF", "üü¢"))
            if model3:
                models_to_use.append((model3, "CNN", "üî¥"))
        else:
            model_map = {
                "HOG + SVM": (model1, "HOG + SVM", "üîµ"),
                "Haar Cascade + RF": (model2, "Haar + RF", "üü¢"),
                "CNN (Deep Learning)": (model3, "CNN", "üî¥")
            }
            if model_choice in model_map:
                models_to_use.append(model_map[model_choice])
        
        for model, name, icon in models_to_use:
            if model:
                with st.container():
                    st.markdown(f"### {icon} {name}")
                    
                    try:
                        pred_proba = model.predict_proba(img_input)[0]
                        pred_class = np.argmax(pred_proba)
                        confidence = pred_proba[pred_class]
                        prediction = labels_map.get(pred_class, f"–ö–ª–∞—Å—Å {pred_class}")
                        
                        if 'Without' in prediction or 'without' in prediction:
                            st.error(f"‚ùå {prediction}")
                        else:
                            st.success(f"‚úÖ {prediction}")
                        
                        col_a, col_b = st.columns(2)
                        with col_a:
                            st.metric("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ", prediction)
                        with col_b:
                            st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}")
                        
                        st.progress(float(confidence))
                        
                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞: {str(e)}")
                    
                    st.markdown("---")
    else:
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

# Footer
st.markdown("---")
st.markdown("<div style='text-align: center; color: gray;'><p>¬© 2024 Mask Detection System</p></div>", 
           unsafe_allow_html=True)
"""
Streamlit –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫
"""
import streamlit as st
import cv2
import numpy as np
from PIL import Image
import pickle
import json
import os
import warnings
warnings.filterwarnings('ignore')

# ===== –ò–ú–ü–û–†–¢–´ –î–õ–Ø TENSORFLOW =====
try:
    import tensorflow as tf
    from tensorflow.keras.models import load_model
    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False

# ===== –°–û–ó–î–ê–ï–ú –§–ï–ô–ö–û–í–´–ï –ú–û–î–£–õ–ò –î–õ–Ø UNPICKLE =====
import sys
import types

# –°–æ–∑–¥–∞–µ–º —Ñ–µ–π–∫–æ–≤—ã–π –º–æ–¥—É–ª—å src
if 'src' not in sys.modules:
    src_module = types.ModuleType('src')
    sys.modules['src'] = src_module
    
    # –°–æ–∑–¥–∞–µ–º src.models
    models_module = types.ModuleType('src.models')
    sys.modules['src.models'] = models_module
    src_module.models = models_module
    
    # –°–æ–∑–¥–∞–µ–º –¥—Ä—É–≥–∏–µ –ø–æ–¥–º–æ–¥—É–ª–∏
    for submodule_name in ['config', 'utils', 'data_preparation', 'evaluation']:
        submodule = types.ModuleType(f'src.{submodule_name}')
        sys.modules[f'src.{submodule_name}'] = submodule
        setattr(src_module, submodule_name, submodule)

# ===== –û–ü–†–ï–î–ï–õ–Ø–ï–ú –§–ï–ô–ö–û–í–´–ï –ö–õ–ê–°–°–´ –ú–û–î–ï–õ–ï–ô =====
class HOG_SVM_Model:
    """–§–µ–π–∫–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è unpickle"""
    def __init__(self):
        self.scaler = None
        self.model = None
        self.name = "HOG + SVM"
    
    def predict_proba(self, X):
        from skimage.feature import hog
        features = []
        for img in X:
            # –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if img.max() <= 1.0:
                img = (img * 255).astype(np.uint8)
            
            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
            fd = hog(
                gray, 
                orientations=9,
                pixels_per_cell=(8, 8),
                cells_per_block=(2, 2),
                visualize=False,
                channel_axis=None
            )
            features.append(fd)
        
        X_features = np.array(features)
        X_scaled = self.scaler.transform(X_features)
        return self.model.predict_proba(X_scaled)

class HaarCascade_RF_Model:
    """–§–µ–π–∫–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è unpickle"""
    def __init__(self):
        self.face_cascade = None
        self.model = None
        self.name = "Haar Cascade + RF"
        self.cascade_path = None
    
    def predict_proba(self, X):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º Haar Cascade –µ—Å–ª–∏ –µ—â–µ –Ω–µ—Ç
        if self.face_cascade is None:
            try:
                self.face_cascade = cv2.CascadeClassifier(
                    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
                )
            except:
                pass
        
        features = []
        
        for img in X:
            # –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if img.max() <= 1.0:
                img = (img * 255).astype(np.uint8)
            
            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
            
            feat = []
            
            # 1. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            feat.extend([gray.mean(), gray.std(), gray.min(), gray.max()])
            
            # 2. –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞
            hist = cv2.calcHist([gray], [0], None, [32], [0, 256])
            feat.extend(hist.flatten())
            
            # 3. –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü
            if self.face_cascade is not None:
                try:
                    faces = self.face_cascade.detectMultiScale(
                        gray, 1.1, 4, minSize=(20, 20)
                    )
                    feat.append(len(faces))
                except:
                    feat.append(0)
            else:
                feat.append(0)
            
            # 4. –¶–≤–µ—Ç–æ–≤—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            for channel in range(3):
                feat.extend([
                    img[:, :, channel].mean(),
                    img[:, :, channel].std()
                ])
            
            # 5. –ö—Ä–∞—è
            edges = cv2.Canny(gray, 100, 200)
            feat.extend([edges.mean(), edges.std()])
            
            features.append(feat)
        
        X_features = np.array(features)
        return self.model.predict_proba(X_features)

# –î–æ–±–∞–≤–ª—è–µ–º –∫–ª–∞—Å—Å—ã –≤ —Ñ–µ–π–∫–æ–≤—ã–π –º–æ–¥—É–ª—å
sys.modules['src.models'].HOG_SVM_Model = HOG_SVM_Model
sys.modules['src.models'].HaarCascade_RF_Model = HaarCascade_RF_Model

# ===== –ü–£–¢–ò –ö –ú–û–î–ï–õ–Ø–ú =====
BASE_DIR = os.getcwd()
TRAINED_MODELS_DIR = os.path.join(BASE_DIR, 'trained_models')

MODEL1_PATH = os.path.join(TRAINED_MODELS_DIR, 'model1_hog_svm.pkl')
MODEL2_PATH = os.path.join(TRAINED_MODELS_DIR, 'model2_haar_rf.pkl')
MODEL3_PATH = os.path.join(TRAINED_MODELS_DIR, 'model3_cnn.h5')
LABELS_MAP_PATH = os.path.join(TRAINED_MODELS_DIR, 'labels_map.json')

# ===== –ù–ê–°–¢–†–û–ô–ö–ê –°–¢–†–ê–ù–ò–¶–´ =====
st.set_page_config(
    page_title="Mask Detection System",
    page_icon="üò∑",
    layout="wide"
)

# ===== –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô =====
@st.cache_resource
def load_models_from_trained_models():
    """–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ —Å —Ñ–µ–π–∫–æ–≤—ã–º–∏ –∫–ª–∞—Å—Å–∞–º–∏"""
    
    if not os.path.exists(TRAINED_MODELS_DIR):
        return None, None, None, {}, False, "–ü–∞–ø–∫–∞ trained_models/ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
    
    try:
        # Labels
        labels_map = {0: 'WithoutMask', 1: 'WithMask'}
        if os.path.exists(LABELS_MAP_PATH):
            try:
                with open(LABELS_MAP_PATH, 'r') as f:
                    labels_dict = json.load(f)
                    labels_map = {int(k): v for k, v in labels_dict.items()}
            except:
                pass
        
        model1, model2, model3 = None, None, None
        
        # ===== –ú–û–î–ï–õ–¨ 1 =====
        if os.path.exists(MODEL1_PATH):
            try:
                with open(MODEL1_PATH, 'rb') as f:
                    model1 = pickle.load(f)
                st.sidebar.success("‚úÖ HOG + SVM –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            except Exception as e:
                st.sidebar.error(f"‚ùå Model1: {str(e)[:100]}")
        
        # ===== –ú–û–î–ï–õ–¨ 2 =====
        if os.path.exists(MODEL2_PATH):
            try:
                with open(MODEL2_PATH, 'rb') as f:
                    model2 = pickle.load(f)
                st.sidebar.success("‚úÖ Haar + RF –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            except Exception as e:
                st.sidebar.error(f"‚ùå Model2: {str(e)[:100]}")
        
        # ===== –ú–û–î–ï–õ–¨ 3 =====
        if os.path.exists(MODEL3_PATH) and TF_AVAILABLE:
            try:
                model3_keras = load_model(MODEL3_PATH, compile=False)
                
                class CNNWrapper:
                    def __init__(self, model):
                        self.model = model
                    
                    def predict_proba(self, X):
                        # CNN –æ–∂–∏–¥–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –≤—Ö–æ–¥ [0, 1]
                        if X.max() > 1.0:
                            X = X / 255.0
                        
                        predictions = self.model.predict(X, verbose=0)
                        
                        if predictions.shape[-1] == 1:
                            prob = predictions.flatten()
                            return np.column_stack([1 - prob, prob])
                        
                        return predictions
                
                model3 = CNNWrapper(model3_keras)
                st.sidebar.success("‚úÖ CNN –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                
            except Exception as e:
                st.sidebar.error(f"‚ùå Model3: {str(e)[:100]}")
        
        any_loaded = model1 is not None or model2 is not None or model3 is not None
        
        return model1, model2, model3, labels_map, any_loaded, ""
        
    except Exception as e:
        return None, None, None, {}, False, str(e)

# –ó–∞–≥—Ä—É–∑–∫–∞
model1, model2, model3, labels_map, models_loaded, error_msg = load_models_from_trained_models()

# –î–ê–õ–¨–®–ï –ò–î–ï–¢ –û–°–¢–ê–õ–¨–ù–û–ô –ö–û–î –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô...

# ===== –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô =====
@st.cache_resource
def load_models_from_trained_models():
    """–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏ –∏–∑ –ø–∞–ø–∫–∏ trained_models/ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏"""
    
    if not os.path.exists(TRAINED_MODELS_DIR):
        return None, None, None, {}, False, f"–ü–∞–ø–∫–∞ trained_models/ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
    
    try:
        # ===== –°–û–ó–î–ê–ï–ú –§–ï–ô–ö–û–í–´–ï –ú–û–î–£–õ–ò –î–õ–Ø UNPICKLE =====
        import sys
        import types
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–µ–π–∫–æ–≤—ã–π –º–æ–¥—É–ª—å src –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
        if 'src' not in sys.modules:
            src_module = types.ModuleType('src')
            sys.modules['src'] = src_module
            
            # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–º–æ–¥—É–ª–∏
            for submodule in ['config', 'models', 'utils', 'data_preparation', 'evaluation']:
                full_name = f'src.{submodule}'
                if full_name not in sys.modules:
                    sub = types.ModuleType(full_name)
                    sys.modules[full_name] = sub
                    setattr(src_module, submodule, sub)
        
        # ===== Labels map =====
        labels_map = {0: "WithoutMask", 1: "WithMask"}
        if os.path.exists(LABELS_MAP_PATH):
            try:
                with open(LABELS_MAP_PATH, 'r') as f:
                    labels_dict = json.load(f)
                    labels_map = {int(k): v for k, v in labels_dict.items()}
                st.sidebar.success("‚úÖ labels_map –∑–∞–≥—Ä—É–∂–µ–Ω")
            except Exception as e:
                st.sidebar.warning(f"‚ö†Ô∏è labels_map: {str(e)[:50]}")
        
        model1, model2, model3 = None, None, None
        
        # ===== –ú–û–î–ï–õ–¨ 1: HOG + SVM =====
        if os.path.exists(MODEL1_PATH):
            try:
                with open(MODEL1_PATH, 'rb') as f:
                    model1 = pickle.load(f)
                st.sidebar.success("‚úÖ –ú–æ–¥–µ–ª—å 1 (HOG + SVM)")
            except Exception as e:
                st.sidebar.error(f"‚ùå Model1: {str(e)[:80]}")
        else:
            st.sidebar.error(f"‚ùå Model1: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # ===== –ú–û–î–ï–õ–¨ 2: Haar + RF =====
        if os.path.exists(MODEL2_PATH):
            try:
                with open(MODEL2_PATH, 'rb') as f:
                    model2 = pickle.load(f)
                st.sidebar.success("‚úÖ –ú–æ–¥–µ–ª—å 2 (Haar + RF)")
            except Exception as e:
                st.sidebar.error(f"‚ùå Model2: {str(e)[:80]}")
        else:
            st.sidebar.error(f"‚ùå Model2: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # ===== –ú–û–î–ï–õ–¨ 3: CNN =====
        if os.path.exists(MODEL3_PATH):
            try:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å ignore –≤—Å–µ—Ö custom objects
                import tensorflow as tf
                
                # –í–∞—Ä–∏–∞–Ω—Ç 1: –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –±–µ–∑ compile
                try:
                    model3_keras = tf.keras.models.load_model(
                        MODEL3_PATH, 
                        compile=False
                    )
                    st.sidebar.success("‚úÖ –ú–æ–¥–µ–ª—å 3 (CNN) - –ø—Ä–æ—Å—Ç–∞—è –∑–∞–≥—Ä—É–∑–∫–∞")
                    
                except Exception as e1:
                    # –í–∞—Ä–∏–∞–Ω—Ç 2: –° safe mode
                    st.sidebar.info("–ü—Ä–æ–±—É—é safe mode –¥–ª—è CNN...")
                    
                    try:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º experimental API
                        model3_keras = tf.keras.models.load_model(
                            MODEL3_PATH,
                            compile=False,
                            safe_mode=False
                        )
                        st.sidebar.success("‚úÖ –ú–æ–¥–µ–ª—å 3 (CNN) - safe mode")
                        
                    except Exception as e2:
                        # –í–∞—Ä–∏–∞–Ω—Ç 3: –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –≤–µ—Å–∞
                        st.sidebar.info("–ü—Ä–æ–±—É—é –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç–æ–ª—å–∫–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É...")
                        
                        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É MobileNetV2
                        from tensorflow.keras.applications import MobileNetV2
                        from tensorflow.keras import Sequential
                        from tensorflow.keras.layers import (
                            GlobalAveragePooling2D, Dense, 
                            Dropout, Rescaling, Input
                        )
                        
                        base_model = MobileNetV2(
                            input_shape=(128, 128, 3),
                            include_top=False,
                            weights='imagenet'
                        )
                        base_model.trainable = False
                        
                        model3_keras = Sequential([
                            Input(shape=(128, 128, 3)),
                            Rescaling(1./255),
                            base_model,
                            GlobalAveragePooling2D(),
                            Dropout(0.3),
                            Dense(128, activation='relu'),
                            Dropout(0.2),
                            Dense(2, activation='softmax')
                        ])
                        
                        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç–æ–ª—å–∫–æ –≤–µ—Å–∞
                        try:
                            model3_keras.load_weights(MODEL3_PATH)
                            st.sidebar.success("‚úÖ –ú–æ–¥–µ–ª—å 3 (CNN) - —Ç–æ–ª—å–∫–æ –≤–µ—Å–∞")
                        except:
                            st.sidebar.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –≤–µ—Å–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º pretrained MobileNet")
                
                # –û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
                class CNNWrapper:
                    def __init__(self, model):
                        self.model = model
                    
                    def predict_proba(self, X):
                        # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ X –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω
                        if X.max() > 1.0:
                            X = X / 255.0
                        
                        predictions = self.model.predict(X, verbose=0)
                        
                        # –ï—Å–ª–∏ –±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
                        if predictions.shape[-1] == 1:
                            prob_positive = predictions.flatten()
                            return np.column_stack([1 - prob_positive, prob_positive])
                        
                        return predictions
                
                model3 = CNNWrapper(model3_keras)
                
            except Exception as e:
                st.sidebar.error(f"‚ùå Model3: {str(e)[:150]}")
        else:
            st.sidebar.error(f"‚ùå Model3: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ö–æ—Ç—å —á—Ç–æ-—Ç–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ
        any_loaded = model1 is not None or model2 is not None or model3 is not None
        
        error_msg = ""
        if not any_loaded:
            error_msg = "–ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª—ã –≤ trained_models/"
        
        return model1, model2, model3, labels_map, any_loaded, error_msg
    
    except Exception as e:
        return None, None, None, {}, False, f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}"
# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏
model1, model2, model3, labels_map, models_loaded, error_msg = load_models_from_trained_models()

# ===== –ó–ê–ì–û–õ–û–í–û–ö =====
st.markdown('<h1 class="main-header">üò∑ –°–∏—Å—Ç–µ–º–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–∞—Å–æ–∫ –Ω–∞ –ª–∏—Ü–µ</h1>', 
           unsafe_allow_html=True)

# –°–æ–æ–±—â–µ–Ω–∏–µ –æ —Å—Ç–∞—Ç—É—Å–µ
if not models_loaded:
    st.markdown("""
    <div class="warning-box">
    ‚ö†Ô∏è <strong>–ü—Ä–æ–±–ª–µ–º–∞ —Å –∑–∞–≥—Ä—É–∑–∫–æ–π –º–æ–¥–µ–ª–µ–π</strong><br>
    –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏ –∏–∑ –ø–∞–ø–∫–∏ <code>trained_models/</code>
    </div>
    """, unsafe_allow_html=True)
else:
    loaded_count = sum(1 for m in [model1, model2, model3] if m is not None)
    st.markdown(f"""
    <div class="success-box">
    ‚úÖ <strong>–ó–∞–≥—Ä—É–∂–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {loaded_count}/3</strong><br>
    –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –ø–∞–ø–∫–∏ <code>trained_models/</code>
    </div>
    """, unsafe_allow_html=True)

st.markdown("---")

# ===== SIDEBAR: –ù–ê–°–¢–†–û–ô–ö–ò =====
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    # –°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–µ–π
    st.subheader("üìä –°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–µ–π")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        if model1:
            st.success("‚úÖ HOG+SVM")
            if os.path.exists(MODEL1_PATH):
                size_mb = os.path.getsize(MODEL1_PATH) / (1024 * 1024)
                st.caption(f"{size_mb:.1f} MB")
        else:
            st.error("‚ùå HOG+SVM")
    
    with col2:
        if model2:
            st.success("‚úÖ Haar+RF")
            if os.path.exists(MODEL2_PATH):
                size_mb = os.path.getsize(MODEL2_PATH) / (1024 * 1024)
                st.caption(f"{size_mb:.1f} MB")
        else:
            st.error("‚ùå Haar+RF")
    
    with col3:
        if model3:
            st.success("‚úÖ CNN")
            if os.path.exists(MODEL3_PATH):
                size_mb = os.path.getsize(MODEL3_PATH) / (1024 * 1024)
                st.caption(f"{size_mb:.1f} MB")
        else:
            st.error("‚ùå CNN")
    
    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    available_models = []
    if model1:
        available_models.append("HOG + SVM")
    if model2:
        available_models.append("Haar Cascade + RF")
    if model3:
        available_models.append("CNN (Deep Learning)")
    
    if available_models:
        model_choice = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
            ["–í—Å–µ –º–æ–¥–µ–ª–∏"] + available_models,
            help="–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"
        )
    else:
        model_choice = "–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"
        st.error("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
    
    # –ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    confidence_threshold = st.slider(
        "–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:", 
        min_value=0.0, 
        max_value=1.0, 
        value=0.5, 
        step=0.05
    )
    
    # –ö–Ω–æ–ø–∫–∞ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏
    if st.button("üîÑ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏"):
        st.cache_resource.clear()
        st.rerun()
    
    st.markdown("---")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—É—Ç—è—Ö
    st.subheader("üìÅ –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º")
    st.code(f"""
model1: {MODEL1_PATH}
model2: {MODEL2_PATH}
model3: {MODEL3_PATH}
labels: {LABELS_MAP_PATH}
    """)

# ===== –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° =====
if not models_loaded:
    st.error(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏!")
    st.warning(error_msg)
    
    st.info("""
    ## üîß –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º:
    
    ### **1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ –ø–∞–ø–∫–∏ trained_models/ –Ω–∞ GitHub:**
    –û—Ç–∫—Ä–æ–π—Ç–µ –≤–∞—à —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –∏ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –µ—Å—Ç—å –ø–∞–ø–∫–∞ `trained_models/` —Å —Ñ–∞–π–ª–∞–º–∏:
    ```
    trained_models/
    ‚îú‚îÄ‚îÄ model1_hog_svm.pkl
    ‚îú‚îÄ‚îÄ model2_haar_rf.pkl  
    ‚îú‚îÄ‚îÄ model3_cnn.h5
    ‚îî‚îÄ‚îÄ labels_map.json (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    ```
    
    ### **2. –ò—Å–ø—Ä–∞–≤—å—Ç–µ .gitignore:**
    –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ `.gitignore` –ù–ï–¢ —Å—Ç—Ä–æ–∫:
    ```gitignore
    trained_models/*
    *.pkl
    *.h5
    ```
    
    ### **3. –î–æ–±–∞–≤—å—Ç–µ —Ñ–∞–π–ª—ã –≤ Git:**
    ```bash
    # –î–æ–±–∞–≤—å—Ç–µ –ø–∞–ø–∫—É trained_models/
    git add trained_models/
    
    # –ò–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–π–ª—ã
    git add trained_models/model1_hog_svm.pkl
    git add trained_models/model2_haar_rf.pkl
    git add trained_models/model3_cnn.h5
    
    git commit -m "Add trained models"
    git push
    ```
    
    ### **4. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –Ω–∞ Streamlit Cloud:**
    ```python
    # –î–æ–±–∞–≤—å—Ç–µ —ç—Ç–æ—Ç –∫–æ–¥ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    import os
    print("–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–æ—Ä–Ω—è:", os.listdir('.'))
    if os.path.exists('trained_models'):
        print("–°–æ–¥–µ—Ä–∂–∏–º–æ–µ trained_models:", os.listdir('trained_models'))
    ```
    """)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—É—â—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    with st.expander("üìÇ –¢–µ–∫—É—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞"):
        st.write("**–ö–æ—Ä–Ω–µ–≤–∞—è –ø–∞–ø–∫–∞:**")
        for item in os.listdir('.'):
            item_path = os.path.join('.', item)
            if os.path.isdir(item_path):
                st.write(f"üìÅ {item}/")
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤–∞–∂–Ω—ã—Ö –ø–∞–ø–æ–∫
                if item in ['trained_models', 'web_app', 'src']:
                    try:
                        sub_items = os.listdir(item_path)
                        for sub in sub_items[:10]:  # –ø–µ—Ä–≤—ã–µ 10 —Ñ–∞–π–ª–æ–≤
                            st.write(f"  üìÑ {sub}")
                    except:
                        pass
            else:
                st.write(f"üìÑ {item}")
    
    st.stop()

# –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å (–µ—Å–ª–∏ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã)
col1, col2 = st.columns([1, 1])

with col1:
    st.header("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    
    upload_option = st.radio(
        "–°–ø–æ—Å–æ–± –∑–∞–≥—Ä—É–∑–∫–∏:",
        ["–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª", "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–º–µ—Ä—É"],
        horizontal=True
    )
    
    uploaded_file = None
    
    if upload_option == "–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª":
        uploaded_file = st.file_uploader(
            "–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ª–∏—Ü–æ–º",
            type=['jpg', 'jpeg', 'png', 'bmp']
        )
    else:
        uploaded_file = st.camera_input("–°—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä—É–π—Ç–µ –ª–∏—Ü–æ")

with col2:
    st.header("üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏")
    
    if uploaded_file is not None:
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            image = Image.open(uploaded_file)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤ –ª–µ–≤–æ–π –∫–æ–ª–æ–Ω–∫–µ
            with col1:
                st.image(image, caption='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_column_width=True)
                img_array = np.array(image)
                st.caption(f"–†–∞–∑–º–µ—Ä: {img_array.shape[1]}x{img_array.shape[0]} –ø–∏–∫—Å–µ–ª–µ–π")
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–µ–π
            if len(img_array.shape) == 2:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)
            elif img_array.shape[2] == 4:
                img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2RGB)
            
            # –†–µ—Å–∞–π–∑ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            img_resized = cv2.resize(img_array, (128, 128))
            img_input = np.expand_dims(img_resized, axis=0) / 255.0
            
            # ===== –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø =====
            if model_choice == "–í—Å–µ –º–æ–¥–µ–ª–∏":
                st.subheader("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
                
                models_to_show = []
                if model1:
                    models_to_show.append((model1, "HOG + SVM", "üîµ", "#1f77b4"))
                if model2:
                    models_to_show.append((model2, "Haar Cascade + RF", "üü¢", "#2ca02c"))
                if model3:
                    models_to_show.append((model3, "CNN (Deep Learning)", "üî¥", "#d62728"))
                
                for model, name, icon, color in models_to_show:
                    with st.container():
                        st.markdown(f"### {icon} {name}")
                        
                        try:
                            pred_proba = model.predict_proba(img_input)[0]
                            
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª–∞—Å—Å
                            if len(pred_proba) > 2:
                                pred_class = np.argmax(pred_proba)
                            else:
                                pred_class = 1 if pred_proba[1] > 0.5 else 0
                            
                            confidence = pred_proba[pred_class] if len(pred_proba) > pred_class else pred_proba[1]
                            prediction = labels_map.get(pred_class, "–° –º–∞—Å–∫–æ–π" if pred_class == 1 else "–ë–µ–∑ –º–∞—Å–∫–∏")
                            
                            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                            col_a, col_b = st.columns([2, 1])
                            with col_a:
                                if confidence >= confidence_threshold:
                                    if prediction == "–° –º–∞—Å–∫–æ–π":
                                        st.success(f"‚úÖ **{prediction}**")
                                    else:
                                        st.error(f"‚ùå **{prediction}**")
                                else:
                                    st.warning(f"‚ö†Ô∏è **{prediction}** (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)")
                            
                            with col_b:
                                st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}")
                            
                            # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
                            st.progress(float(confidence))
                            
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {str(e)[:100]}")
                        
                        st.markdown("---")
            
            else:
                # –û–¥–Ω–∞ –º–æ–¥–µ–ª—å
                model_map = {
                    "HOG + SVM": (model1, "üîµ"),
                    "Haar Cascade + RF": (model2, "üü¢"),
                    "CNN (Deep Learning)": (model3, "üî¥")
                }
                
                model, icon = model_map[model_choice]
                
                if model:
                    with st.spinner('–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...'):
                        try:
                            pred_proba = model.predict_proba(img_input)[0]
                            
                            if len(pred_proba) > 2:
                                pred_class = np.argmax(pred_proba)
                            else:
                                pred_class = 1 if pred_proba[1] > 0.5 else 0
                            
                            confidence = pred_proba[pred_class] if len(pred_proba) > pred_class else pred_proba[1]
                            prediction = labels_map.get(pred_class, "–° –º–∞—Å–∫–æ–π" if pred_class == 1 else "–ë–µ–∑ –º–∞—Å–∫–∏")
                            
                            # –ë–æ–ª—å—à–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                            st.markdown(f"## {icon} {prediction}")
                            
                            if confidence >= confidence_threshold:
                                if prediction == "–° –º–∞—Å–∫–æ–π":
                                    st.success("‚úÖ –ú–∞—Å–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞!")
                                else:
                                    st.error("‚ùå –ú–∞—Å–∫–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞!")
                            else:
                                st.warning("‚ö†Ô∏è –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏")
                            
                            # –ú–µ—Ç—Ä–∏–∫–∏
                            col_a, col_b, col_c = st.columns(3)
                            
                            with col_a:
                                st.metric("–ö–ª–∞—Å—Å", prediction)
                            
                            with col_b:
                                st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}")
                            
                            with col_c:
                                status = "‚úÖ" if confidence >= confidence_threshold else "‚ö†Ô∏è"
                                st.metric("–°—Ç–∞—Ç—É—Å", status)
                            
                            # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
                            st.progress(float(confidence))
                            
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {str(e)}")
                else:
                    st.error(f"–ú–æ–¥–µ–ª—å {model_choice} –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
    
    else:
        st.info("üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –Ω–∞—á–∞–ª–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏")
        
        st.markdown("""
        ### üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
        
        1. **–ß–µ—Ç–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ** –ª–∏—Ü–∞
        2. **–•–æ—Ä–æ—à–µ–µ –æ—Å–≤–µ—â–µ–Ω–∏–µ**
        3. **–õ–∏—Ü–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤ –∫–∞–¥—Ä–µ**
        4. **–ë–µ–∑ –º–∞—Å–æ–∫ –Ω–∞ –ø–æ–¥–±–æ—Ä–æ–¥–∫–µ**
        """)

# ===== FOOTER =====
st.markdown("---")

with st.expander("üìã –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –¥–µ–ø–ª–æ—è"):
    st.markdown("""
    ## –î–ª—è —É—Å–ø–µ—à–Ω–æ–π —Ä–∞–±–æ—Ç—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è:
    
    ### **1. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å:**
    ```
    project_ip/
    ‚îú‚îÄ‚îÄ web_app/
    ‚îÇ   ‚îî‚îÄ‚îÄ app.py                    # –≠—Ç–æ—Ç —Ñ–∞–π–ª
    ‚îú‚îÄ‚îÄ trained_models/              # –ü–∞–ø–∫–∞ —Å –º–æ–¥–µ–ª—è–º–∏
    ‚îÇ   ‚îú‚îÄ‚îÄ model1_hog_svm.pkl      # –ú–æ–¥–µ–ª—å 1
    ‚îÇ   ‚îú‚îÄ‚îÄ model2_haar_rf.pkl      # –ú–æ–¥–µ–ª—å 2
    ‚îÇ   ‚îú‚îÄ‚îÄ model3_cnn.h5           # –ú–æ–¥–µ–ª—å 3
    ‚îÇ   ‚îî‚îÄ‚îÄ labels_map.json         # –ú–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤
    ‚îú‚îÄ‚îÄ requirements.txt
    ‚îî‚îÄ‚îÄ .gitignore                  # –ë–µ–∑ —Å—Ç—Ä–æ–∫ –ø—Ä–æ trained_models/*.pkl
    ```
    
    ### **2. –ù–∞ Streamlit Cloud:**
    - **Main file path:** `web_app/app.py`
    - **Branch:** `main`
    
    ### **3. –ï—Å–ª–∏ –º–æ–¥–µ–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è:**
    ```python
    # –î–æ–±–∞–≤—å—Ç–µ –≤ –∫–æ–¥ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    import os
    print("–¢–µ–∫—É—â–∞—è –ø–∞–ø–∫–∞:", os.getcwd())
    print("–°–æ–¥–µ—Ä–∂–∏–º–æ–µ trained_models:", os.listdir('trained_models'))
    ```
    """)

st.markdown(f"""
<div style='text-align: center; color: gray; padding: 20px;'>
<p>¬© 2024 Mask Detection System | –ú–æ–¥–µ–ª–∏ –∏–∑ –ø–∞–ø–∫–∏: {TRAINED_MODELS_DIR}</p>
</div>
""", unsafe_allow_html=True)